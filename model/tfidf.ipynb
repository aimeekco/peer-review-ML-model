{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pre.get_label(layer)\n",
    "corpus = pre.create_sentence_list(1)\n",
    "from nltk.stem import SnowballStemmer \n",
    "\n",
    "st = SnowballStemmer(\"english\")\n",
    "text = pre.norm_corpus\n",
    "\n",
    "output = []\n",
    "for sentence in text:\n",
    "    output.append(' '.join([st.stem(word) for word in sentence.split()]))\n",
    "fileid=pre.fileid\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., max_features=1500, use_idf=False, lowercase=True, ngram_range=(1,2), analyzer=u'word', smooth_idf=False)\n",
    "tv_matrix = tv.fit_transform(output)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "print(len(tv_matrix))\n",
    "print(label)\n",
    "print(pre.norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = []\n",
    "new_tv = []\n",
    "new_fileid = []\n",
    "new_corpus = []\n",
    "length = len(tv_matrix)\n",
    "for i in range(length):\n",
    "    for j in range(len(label[i])):\n",
    "        new_label.append(label[i][j])\n",
    "        new_tv.append(tv_matrix[i])\n",
    "        new_fileid.append(fileid[i])\n",
    "        new_corpus.append(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_rows = len(new_tv)\n",
    "num_cols = len(new_tv[0])\n",
    "modified_tv = []\n",
    "padding = np.zeros(num_cols, dtype=int)\n",
    "\n",
    "for i in range(num_rows):\n",
    "    if i == 0:\n",
    "        x = np.append(padding, new_tv[0])\n",
    "        x = np.append(x, new_tv[1])\n",
    "        modified_tv.append(x)\n",
    "        \n",
    "    elif i == (num_rows - 1):\n",
    "        x = np.append(new_tv[num_rows - 2], new_tv[num_rows - 1])\n",
    "        x = np.append(x, padding)\n",
    "        modified_tv.append(x)\n",
    "        \n",
    "    else: \n",
    "        x = np.append(new_tv[i - 1], new_tv[i])\n",
    "        x = np.append(x, new_tv[i + 1])\n",
    "        modified_tv.append(x)\n",
    "        \n",
    "df_tfidf = pre.pd.DataFrame(pre.np.round(modified_tv, 10))\n",
    "df_tfidf['tag'] = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_df = df_tfidf[df_tfidf.columns[:-1]]\n",
    "X = X_df.to_numpy()\n",
    "y = df_tfidf['tag']\n",
    "print(np.unique(df_tfidf['tag']))\n",
    "class_names = np.unique(df_tfidf['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, shuffle = False)\n",
    "y_train = y_train.reset_index()['tag'].tolist()\n",
    "print(X_train.shape)\n",
    "print(len(y_train))\n",
    "print(length)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "logmodel = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "logmodel.fit(X_train, y_train)\n",
    "y_pred = logmodel.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                  (\"Normlaized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(logmodel, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "    \n",
    "def heatconmat(y_true, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cbar=False, cmap='gist_earth_r', yticklabels=sorted(y_test.unique()))\n",
    "    plt.show()\n",
    "    print(classification_report(y_true, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                  (\"Normlaized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt', class_weight='balanced_subsample')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                    (\"Normlaized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                    display_labels=class_names,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = svm.SVC(class_weight='balanced', decision_function_shape='ovo')\n",
    "import sklearn.metrics as metrics\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                    (\"Normlaized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                    display_labels=class_names,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='12', max_iter=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "titles_options = [(\"Confusion matrix without normalization\", None),\n",
    "                    (\"Normlaized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                    display_labels=class_names,\n",
    "                                    cmap=plt.cm.Blues,\n",
    "                                    normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
