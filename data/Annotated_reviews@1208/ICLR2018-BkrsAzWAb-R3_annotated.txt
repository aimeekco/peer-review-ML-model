"\nThis paper revisits an interesting and important trick to automatically adapt the stepsize.[[INT-NEU], [null], [SMY], [GEN]] They consider the stepsize as a parameter to be optimized and apply stochastic gradient update for the stepsize.[[MET-NEU], [null], [SMY], [GEN]] Such simple trick alleviates the effort in tuning stepsize, and can be incorporated with popular stochastic first-order optimization algorithms, including SGD, SGD with Nestrov momentum, and Adam. Surprisingly, it works well in practice.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nAlthough the theoretical analysis is weak that theorem 1 does not reveal the main reason for the benefits of such trick, considering their performance, I vote for acceptance.[[MET-NEU], [REC-POS,EMP-NEG], [FBK], [MAJ]] But before that, there are several issues need to be addressed.[[OAL-NEU], [null], [DIS], [GEN]] \n\n1, the derivation of the update of \\alpha relies on the expectation formulation.[[MET-NEU], [EMP-NEU], [DIS], [MAJ]] I would like to see the investigation of the effect of the size of minibatch to reveal the variance of the gradient in the algorithm combined with such trick.[[EXP-NEU,MET-NEU,RES-NEU], [EMP-NEU], [SUG], [MAJ]] \n\n2, The derivation of the multiplicative rule of HD relies on a reference I cannot find. Please include this part for self-containing.[[MET-NEU,BIB-NEG], [EMP-NEU], [SUG], [MAJ]] \n\n3, As the authors claimed, the Maclaurin et.al. 2015 is the most related work, however, they are not compared in the experiments.[[RWK-NEU,EXP-NEU], [CMP-NEG], [CRT], [MAJ]] Moreover, the empirical comparisons are only conducted on MNIST.[[EXP-NEU], [CMP-NEG,EMP-NEU], [CRT], [MAJ]] To be more convincing, it will be good to include such competitor and comparing on practical applications on CIFAR10/100 and ImageNet.[[DAT-NEU,EXP-NEU], [CMP-NEU], [SUG], [MAJ]] \n\nMinors: \n\nIn the experiments results figures, after adding the new trick, the SGD algorithms become more stable, i.e., the variance diminishes.[[EXP-NEU,MET-POS,RES-NEU,TNF-NEU], [EMP-POS], [DIS], [MIN]] Could you please explain why such phenomenon happens?"[[MET-NEU], [EMP-NEU], [QSN], [MIN]]