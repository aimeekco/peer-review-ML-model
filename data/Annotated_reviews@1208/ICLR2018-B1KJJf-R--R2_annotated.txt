"This paper tackles the problem of doing program synthesis when given a problem description and a small number of input-output examples.[[PDI-NEU], [null], [SMY], [GEN]] The approach is to use a sequence-to-tree model along with an adaptation of beam search for generating tree-structured outputs.[[PDI-NEU], [null], [SMY], [GEN]]  In addition, the paper assembles a template-based synthetic dataset of task descriptions and programs.[[DAT-NEU,PDI-NEU], [null], [SMY], [GEN]]   Results show that a Seq2Tree model outperforms a Seq2Seq model, that adding search to Seq2Tree improves results,[[DAT-POS,MET-POS,RES-POS], [EMP-NEU], [APC], [MAJ]] and that search without any training performs worse, although the experiments assume that only a fixed number of programs are explored at test time regardless of the wall time that it takes a technique. [[EXP-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nStrengths:\n\n- Reasonable approach, quality is good[[MET-POS], [CLA-POS,EMP-POS], [APC], [MAJ]]\n\n- The DSL is richer than that of previous related work like Balog et al. (2016).[[RWK-POS,MET-POS], [EMP-POS], [APC], [MAJ]]\n\n- Results show a reasonable improvement in using a Seq2Tree model over a Seq2Seq model, which is interesting.[[RES-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]\n\nWeaknesses:\n\n- There are now several papers on using a trained neural network to guide search, and this approach doesn't add too much on top of previous work.[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]] Using beam search on tree outputs is a bit of a minor contribution.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n\n- The baselines are just minor variants of the proposed method.[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MIN]] It would be stronger to compare against a range of different approaches to the problem, particularly given that the paper is working with a new dataset.[[DAT-NEG,MET-NEG], [SUB-NEG], [SUG], [MIN]]\n\n- Data is synthetic, and it's hard to get a sense for how difficult the presented problem is, as there are just four example problems given.[[DAT-NEG], [CMP-NEG], [CRT], [MIN]]\n\nQuestions:\n\n- Why not compare against Seq2Seq + Search?[[MET-NEG], [EMP-NEG], [QSN], [MIN]]\n\n- How about comparing wall time against a traditional program synthesis technique (i.e., no machine learning), ignoring the descriptions.[[MET-NEG], [CMP-NEG], [QSN], [MIN]] I would guess that an efficiently-implemented enumerative search technique could quickly explore all programs of depth 3, which makes me skeptical that Figure 4 is a fair representation of how well a non neural network-based search could do.[[MET-NEU,TNF-POS], [EMP-NEU,PNF-POS], [APC,DIS], [MIN]]\n\n- Are there plans to release the dataset?[[DAT-NEU], [EMP-NEU], [QSN], [MIN]] Could you provide a large sample of the data at an anonymized link?[[DAT-NEU], [SUB-NEU], [QSN], [MIN]] I'd re-evaluate my rating after looking at the data in more detail.\n"[[DAT-NEU,OAL-NEU], [REC-NEU], [FBK], [MAJ]]