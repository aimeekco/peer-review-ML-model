"The paper extends the idea of eigenoptions, recently proposed by Machado et al. to domains with stochastic transitions and where state features are learned.[[INT-NEU,RWK-NEU], [null], [SMY], [GEN]] An eigenoption is defined as an optimal policy for a reward function defined by an eigenvector of the matrix of successor representation (SR), which is an occupancy measure induced here by a uniform policy.[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]] In high-dimensional state space, the authors propose to approximate that matrix with a convolutional neural network (CNN).[[MET-NEU], [null], [SMY], [GEN]] The approach is evaluated in a tabular domain (i.e., rooms) and Atari games.[[MET-NEU], [null], [SMY], [GEN]]\n\nOverall the paper is well-written and quite clear.[[OAL-POS], [CLA-POS], [APC], [MAJ]] The proposed ideas for the extension seem natural (i.e., use of SR and CNN).[[PDI-POS], [EMP-POS], [APC], [MAJ]] The theorem stated in the paper seems to provide an interesting link between SR and the Laplacian.[[MET-POS], [EMP-POS], [DIS], [MIN]] However, a few points are not clear to me:\n- Is the result new or not? [[RES-NEG], [NOV-NEG], [CRT], [MAJ]]If I understand correctly, Stachenfeld et al. discussed this result, but didn't prove it.[[RWK-NEU], [null], [DIS], [GEN]] Is that correct?[[RWK-NEU], [null], [QSN], [GEN]] So the provided proof is new?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n- Besides, how are D and W exactly defined?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] \n- Finally, as the matrix is not symmetric, do real eigenvalues always exist?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nThe execution of the proposed ideas in the experiments was a bit disappointing to me.[[EXP-NEG], [EMP-NEG], [CRT], [MIN]] The approximated eigenoption was simply computed as a one-step greedy policy.[[MET-NEU], [null], [DIS], [MIN]] Besides, the eigenoptions seem to help for exploration (as a uniform policy was used) as indicated by plot 3(d), but could they help for other tasks (e.g., learn to play Atari games faster or better)? [[MET-NEU], [EMP-NEU], [QSN], [MIN]]I think that would be a more useful measure for the learned eigenoptions.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n\nDuring learning SR and the features, what would be the impact if the gradient for SR estimation were also propagated?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nIn Figure 4, the trajectories generated by the different eigenoptions are barely visible.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nSome typos:\n- Section 2.1:\nin the definition of G_t, the expectation is taken over p as well\nI_w and T_w should be a subset of S[[MET-NEU], [CLA-NEU], [CRT], [MIN]]\n\n- in (2), the hat is missing over \\Psi\nin the definition of v_\\pi(s), r only depends on s'?[[MET-NEU], [CLA-NEU], [QSN], [MIN]] This seems inconsistent with the previous definition of \\psi\n\n- p.[[MET-NEU], [CLA-NEU], [CRT], [MIN]] 6:\nin the definition of L_{SR}(s, s'), why \\psi takes \\phi(s) as argument?\n\n- in conclusion:\nthat that"[[MET-NEU], [CLA-NEU], [QSN], [MIN]]