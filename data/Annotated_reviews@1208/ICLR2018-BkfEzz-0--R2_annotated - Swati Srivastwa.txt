"In this paper, the authors present a novel way to look at a neural network such that each neuron (node) in the network is an agent working to optimize its reward.[[MET-POS], [NOV-POS], [APC], [MAJ]] The paper shows that by appropriately defining the neuron level reward function, the model can learn a better policy in different tasks.[[PDI-NEU], [null], [SMY], [GEN]] For example, if a classification task is formulated as reinforcement learning where the ultimate reward depends on the batch likelihood, the presented formulation (called Adaptive DropConnect in this context) does better on standard datasets when compared with a strong baseline.[[RWK-NEU,MET-NEU], [CMP-NEU], [DIS], [MIN]]\n\nThe idea proposed in the paper is quite interesting,[[PDI-POS], [EMP-POS], [APC], [MAJ]] but the presentation is severely lacking.[[OAL-NEG], [PNF-NEG], [CRT], [MIN]] In a work that relies heavily on precise mathematical formulation, there are several instances when the details are not addressed leading to ample confusion making it hard to fully comprehend how the idea works.[[MET-NEG,ANA-NEG], [EMP-NEG], [CRT], [MAJ]]For example, in section 5.1, notations are presented and defined much later or not at all (g_{jit} and d_{it}).[[MET-NEG], [PNF-NEG], [CRT], [MIN]] Many equations were unclear to me for similar reasons to the point I decided to only skim those parts.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] Even the definition of external vs. internal environment (section 4) was unclear which is used a few times later.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  Like, what does it mean when we say, \u201cenvironment that the multi-agent system itself touches\u201d?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] \n\nOverall, I think the idea presented in the paper has merit,[[PDI-POS], [EMP-POS], [APC], [MAJ]]  but without a thorough rewriting of the mathematical sections, it is difficult to fully comprehend its potential and applications."[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] 