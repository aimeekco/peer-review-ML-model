"The main goal of this paper is to cluster images from classes unseen during training.[[PDI-NEU], [null], [SMY], [GEN]]\nThis is an interesting extension of the open-world paradigm, where at test time, the classifier has to identify images beloning to the C seen classes during training, but also identify (reject) images which were previously unseen.[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]] These rejected images could be clustered to identify the number of unseen classes; either for revealing the underlying structure of the unseen classes, or to reduce annotation costs.[[MET-NEU], [null], [SMY], [GEN]]\n\nIn order to do so, an extensive framework is proposed, consisting of 3 ConvNet architectures, followed by a hierarchical clustering approach.[[MET-NEU], [null], [SMY], [GEN]] The 3 ConvNets all have a different goal:\n1. an Open Classification Network (per class sigmoid, trained 1vsRest, with thresholds for rejection)[[MET-NEU], [null], [DIS], [GEN]]\n2. Pairwise Classification Network, (binary sigmoid, trained on pairs of images of same/different classes)[[MET-NEU], [null], [DIS], [GEN]]\n3. Auto encoder network\n\nThese network are jointly trained, and the joint-loss is simply the addition of a cross-entropy loss (from OCN), the binary cross-entropy loss (from PCN) and a pixel wise loss (from AE). [[MET-NEU], [null], [SMY], [GEN]]\nRemarks:\n- it is unclear if the ConvNet weights of the first layers are shared).[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] \n- it is unclear how joint training might help, given that the objectives do not influence each other[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n- Eq 1: \n  *label \"y_i\" has two different semantics (L_ocn it is the class label, while in L_pcn it is the label of an image pair being from the same class or not)[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n  * s_j is undefined[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n  * relation between the p(y_i = 1) (in PCN) and g(x_p,x_q) in Eq 2 could be made more explicit, PCN depends on two images, according to Eq 1, it seems just a sum over single images.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- It is unclear why the Auto Encoder network is added, and what its function is.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- It is unclear wether OCN requires/uses unseen class examples during training.\n- Last paragraph of 3.1 \"The 1-vs-rest ... rejected\", I don't see why you need 1vsRest classifiers for this, a multi-class (softmax) output can also be thresholded to reject an test image from the known classes and to assign it to the unknown class.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n\n\nExperimental evaluation\nThe experimental evaluation uses 2 datasets, MNIST and EMNIST, both are very specific for character recognition.[[DAT-NEU,EXP-NEU], [EMP-NEU], [DIS], [MIN]] It is a pity that not also more general image classification has been considered (CIFAR100, ImageNet, Places365, etc), that would provide insights to the more general behaviour of the proposed ideas.[[PDI-NEU,DAT-NEU], [EMP-NEU], [DIS], [MIN]]\n\nMy major concern is that the clustering task is not extensively explored.[[MET-NEG,ANA-NEG], [SUB-NEG,EMP-NEG], [CRT], [MAJ]] Just a single setting (with a single random sampling of seen/unseen classes) has been evaluated.[[MET-NEG,ANA-NEG], [SUB-NEG,EMP-NEG], [CRT], [MAJ]] This is -in part- due to the nature of the chosen datasets, in a 10 class dataset it is difficult to show the influence of the number of unseen classes.[[DAT-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] So, I'd really urge the authors to extend this evaluation.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Will the method discover more classes when 100 unknown classes are used?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] What kind of clusters are discovered?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Are the types of classes in the seen/unseen classes important, I'd expect at least multiple runs of the current experiments on (E)MNIST.[[DAT-NEU,EXP-NEU], [EMP-NEU], [DIS], [MIN]] \n\nFurther, I miss some baselines and ablation study.[[RWK-NEG], [EMP-NEG], [CRT], [MAJ]] Questions which I'd like to seen answered: how good is the OCN representation when used for clustering compared to the PCN representation?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] What is the benefit of joint-training?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] How important is the AE in the loss?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nRemaining remarks\n- Just a very simple / non-standard ConvNet architecture is trained.[[EXP-NEU], [EMP-NEU], [DIS], [MIN]] Will a ResNet(32) show similar performance?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n- In Eq 4, |C_i || y_j| seems a strange notation for union.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n\nConclusion\nThis paper brings in an interesting idea, is it possible to cluster the unseen classes in an open-world classification scenario? [[MET-NEU], [EMP-NEU], [QSN], [MIN]] A solution using a pairwise convnet followed by hierarchical clustering is proposed.[[MET-NEU], [null], [DIS], [MIN]] This is a plausible solution, yet in total I miss an exploration of the solution.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]] \n\nBoth in terms of general visual classification (only MNIST is used, while it would be nice to see results on CIFAR and/or ImageNet as in Bendale&Boult 2016), as in exploration of different scenarios (different number of unseen classes, different samplings) and ablation of the method (independent training, using OCN for hierarchical clustering, influence of Auto Encoder).[[DAT-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]] Therefore, I rate this paper as a (weak) reject: it is just not (yet) good enough for acceptance."[[OAL-NEG], [EMP-NEG], [CRT], [MAJ]]