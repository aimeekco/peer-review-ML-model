"The paper is well written, and the authors do an admirable job of motivating their primary contributions throughout the early portions of the paper.[[OAL-POS], [CLA-POS], [APC], [MAJ]] Each extension to the Dual Actor-Critic is well motivated and clear in context.[[MET-POS], [CLA-POS], [APC], [MAJ]] Perhaps the presentation of these extensions could be improved by providing a less formal explanation of what each does in practice; multi-step updates, regularized against MC returns, stochastic mirror descent.[[MET-NEU], [PNF-NEU], [SUG], [MIN]] \n\nThe practical implementation section losses some of this clear organization, and could certainly be clarified each part tied into Algorithm 1, and this was itself made less high-level. But these are minor gripes overall.[[EXP-NEU,MET-NEU], [EMP-NEG], [SUG], [MIN]]\n\nTurning to the experimental section, I think the authors did a good job of evaluating their approach with the ablation study and comparisons with PPO and TRPO.[[EXP-POS], [EMP-POS], [APC], [MAJ]] There were a few things that jumped out to me that I was surprised by.[[EXP-NEU], [EMP-NEU], [DIS], [GEN]] The difference in performance for Dual-AC between Figure 1 and Figure 2b is significant, but the only difference seems to be a reduce batch size, is this right?[[TNF-POS], [IMP-POS], [QSN], [MAJ]] This suggests a fairly significant sensitivity to this hyperparameter if so.[[FWK-NEU], [IMP-POS], [DIS], [MAJ]]\n\nReproducibility in continuous control is particularly problematic.[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]] Nonetheless, in recent work PPO and TRPO performance on the same set of tasks seem to be substantively different than what the authors get in their experiments.[[EXP-NEG], [EMP-NEG], [SMY], [MAJ]] I'm thinking in particular of:\n\nProximal Policy Optimization Algorithms (Schulman et. al., 2017)[[RWK-NEU,EXP-NEU,BIB-NEU], [CMP-NEU], [DIS], [MAJ]]\nMulti-Batch Experience Replay for Fast Convergence of Continuous Action Control (Han and Sung, 2017)[[RWK-NEU,BIB-NEU], [CMP-NEU], [DIS], [GEN]]\n\nIn both these cases the results for PPO and TRPO vary pretty significantly from what we see here, and an important one to look at is the InvertedDoublePendulum-v1 task, which I would think PPO would get closer to 8000, and TRPO not get off the ground.[[RWK-NEU,EXP-NEU], [EMP-NEU], [SMY], [MAJ]] Part of this could be the notion of an \"iteration\", which was not clear to me how this corresponded to actual time steps.[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]] Most likely, to my mind, is that the parameterization used (discussed in the appendix) is improving TRPO and hurting PPO.[[EXP-NEU], [EMP-NEU], [DIS], [MAJ]]\n\nWith these in mind I view the comparison results with a bit of uncertainty about the exact amount of gain being achieved,;[[RES-NEU], [CMP-NEG], [CRT], [MAJ]] which may beg the question if the algorithmic contributions are buying much for their added complexity?[[MET-NEU], [EMP-NEU], [QSN], [MAJ]]\n\nPros:\nWell written, thorough treatment of the approaches.[[OAL-POS], [CLA-POS], [APC], [MAJ]]\nImprovements on top of Dual-AC with ablation study show improvement.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nCons:\nEmpirical gains might not be very large.[[EXP-NEU,MET-NEU], [EMP-NEU], [DIS], [MAJ]]\n"