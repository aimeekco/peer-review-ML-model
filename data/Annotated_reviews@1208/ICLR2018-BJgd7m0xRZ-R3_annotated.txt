"Although the problem addressed in the paper seems interesting,[[PDI-POS], [EMP-POS], [APC], [MAJ]] but there lacks of evidence to support some of the arguments that the authors make.[[PDI-NEG], [SUB-NEG], [CRT], [MIN]] And the paper does not contribute novelty to representation learning, therefore, it is not a good fit for the conference.[[MET-NEG,OAL-NEG], [APR-NEG,NOV-NEG], [CRT], [MIN]] Detailed critiques are as following:1. The idea proposed by the authors seems too quite simple.[[PDI-NEG], [CLA-NEG], [CRT], [MIN]] It is just performing random projections for 1000 times and choose the set of projection parameters that results in the highest compactness as the dimensionality reduction model parameter before one-class SVM.[[PDI-NEG,MET-NEG], [EMP-NEG], [CRT], [MIN]]\n2. It says in the experiments part that the authors have used 3 different S_{attack} values, but they only present results for S_{attack} = 0.5.[[EXP-NEU,RES-NEU], [null], [DIS], [MIN]] It would be nicer if they include results for all S_{attack} values that they have used in their experiments, which would also give the reader insights on how the anomaly detection performance degrades when the S_attack value change.[[EXP-NEU,RES-NEU], [SUB-NEU], [SUG,DFT], [MIN]]\n3. The paper claims that the nonlinear random projection is a defence against adversary due to the randomness, but there is no results in the paper proving that other non-random projections are susceptible to adversary that is designed to target that projection mechanism and nonlinear random projection is able to get away with that.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]] And PCA as a non-random projection would a nice baseline to compare against.[[RWK-NEU], [CMP-NEU], [SUG], [MIN]]\n4. The paper seems to misuse the term \u201cFalse positive rate\u201d as the y label of figure 3(d/e/f).[[TNF-NEG], [PNF-NEG], [CRT], [MAJ]] The definition of false positive rate is FP/(FP+TN), so if the FPR=1 it means that all negative samples are labeled as positive.[[DAT-NEG], [EMP-NEG], [CRT], [MAJ]] So it is surprising to see FPR=1 in Figure 3(d) when feature dimension=784 while the f1 score is still high in Figure 3(a).[[TNF-NEG], [PNF-NEG,EMP-NEG], [DIS], [MAJ]] From what I understand, the paper means to present the percentage of adversarial examples that are misclassified instead of all the anomaly examples that get misclassified.[[DAT-NEG], [EMP-NEG], [CRT], [MAJ]] The paper should come up with a better term for that evaluation.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n5. The conclusion, that robustness of the learned model increases wrt the integrity attacks increases when the projection dimension becomes lower, cannot be drawn from Figure 3(d).[[TNF-NEG], [EMP-NEG], [CRT], [MIN]] Need more experiment on more dimensionality to prove that. \n6. In the appendix B results part, sometimes the word \u2019S_attack\u2019 is typed wrong. And the values in  \u201cdistorted/distorted\u201d columns in Table 5 do not match up with the ones in Figure 3(c)."[[EXP-NEG], [SUB-NEG], [DFT], [MIN]]