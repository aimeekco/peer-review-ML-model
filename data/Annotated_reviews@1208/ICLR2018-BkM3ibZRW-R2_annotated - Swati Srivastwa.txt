"the paper presents a way to encode discrete distributions which is a challenging problem.[[PDI-NEU], [null], [SMY], [GEN]] they propose to use a latent variable gan with one continuous encoding and one discrete encoding.[[EXP-NEU,MET-NEU], [null], [SMY], [GEN]] \n\ntwo questions linger around re practices:\n1. gan is known to struggle with discriminating distributions with different supports.[[MET-NEU], [null], [DIS], [MIN]] the problem also persists here as the gan is discriminating between a continuous and a discrete distribution. [[MET-NEU], [null], [DIS], [MIN]]  it'll interesting to see how the proposed approach gets around this issue.[[MET-POS], [EMP-POS], [APC], [MAJ]] \n\n2. the second question is related.[[CNT], [null], [DIS], [GEN]]  it is unclear how the optimal distribution would look like with the latent variable gan.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  ideally, the discrete encoding be simply a discrete approximation of the continuous encoding.[[EXP-NEU], [EMP-NEU], [DIS], [MIN]]  but optimization with two latent distributions and one discriminator can be hard.[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]]  what we get in practice is pretty unclear.[[EXP-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]]  also how this could outperform classical discrete autoencoders is unclear.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]]  gan is an interesting idea to apply to solve many problems; it'll be helpful to get the intuition of which properties of gan solves the problem in this particular application to discrete autoencoders."[[EXP-NEU,MET-POS], [EMP-NEU], [DIS], [MAJ]] 