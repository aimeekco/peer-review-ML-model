"The paper adopts the concept of saliency to explain how the deep model makes decisions with adversarial perturbations. [[PDI-NEU], [null], [SMY], [GEN]]The paper is not written well and the idea seems to be trivial compared with previous methods.[[MET-NEG,OAL-NEG], [CLA-NEG,CMP-NEG], [CRT], [MAJ]]\n\nThe paper uses three manners of adversarial attacks and formulate saliency as the gradient that is particularly influential to the final classification output.[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]] From what I can see, there is barely new that is proposed by the paper.[[PDI-NEG], [NOV-NEG], [CRT], [MAJ]] The experiment lacks the C&W's attack.[[EXP-NEG], [EMP-NEG], [DFT], [MAJ]] The second paragraph of introduction listed some related work and yet failed to compare with them well. [[RWK-NEG], [CMP-NEG], [CRT], [MAJ]]The method resembles quite a lot the Grad-CAM method and the conclusions from the experiment (\"shallow layers are robust enough to adversarial examples and middle layers ....\") seem shallow as well.[[EXP-NEG,MET-NEG], [CMP-NEG,SUB-NEG], [DFT,CRT], [MAJ]]\n\nThe presentation of the paper is poor.[[OAL-NEG], [PNF-NEG], [CRT], [MIN]] Many syntax errors/ format issues.[[OAL-NEG], [CLA-NEG], [CRT], [MIN]] For example, in the abstract, \"saliency simply explain how\" -> explains. Discussion section, \"how xxx contributing to wrong xxx\" -> contributes to."[[ABS-NEG], [CLA-NEG], [CRT], [MIN]]