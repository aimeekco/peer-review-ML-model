"I am not sure how to interpret this paper.[[EXT-NEU], [null], [DIS], [GEN]] The paper seems to be very thin technically, unless I missed some important details.[[OAL-NEG], [SUB-NEG], [DFT], [MIN]] Two proposals in the paper are:\n\n(1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training,[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]] and \n(2) Extract the penultimate layer output as features to train a conventional classifier such as SVM.[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nI don't understand why (1) differs from other approaches, in the sense that one cannot simply reduce the number of epochs without hurting performance.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] And for (2), it is a relatively standard approach in utilizing CNN features.[[MET-POS], [EMP-POS], [APC], [MAJ]] Essentially, if I understand correctly, this paper is proposing to prematurely stop training an use the intermediate feature to train a conventional classifier (which is not that away from the softmax classifier that CNNs usually use).[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MIN]] I fail to see how this would lead to superior performance compared to conventional CNNs."[[MET-NEG], [CMP-NEG], [CRT], [MAJ]]