"This paper focuses on the problem of \"machine teaching\", i.e., how to select a good strategy to select training data points to pass to a machine learning algorithm, for faster learning.[[PDI-NEU], [null], [SMY], [GEN]] The proposed approach leverages reinforcement learning by defining the reward as how fast the learner learns, and use policy gradient to update the teacher parameters.[[MET-NEU], [null], [SMY], [GEN]] I find the definition of the \"state\" in this case very interesting.[[MET-POS], [CNT], [APC], [MAJ]] The experimental results seem to show that such a learned teacher strategy makes machine learning algorithms learn faster.[[EXP-POS,RES-POS], [EMP-POS], [APC], [MAJ]] \n\nOverall I think that this paper is decent.[[OAL-POS], [null], [APC], [MAJ]] The angle the authors took is interesting (essentially replacing one level of the bi-level optimization problem in machine teaching works with a reinforcement learning setup).[[MET-POS], [EMP-POS], [APC], [MAJ]] The problem formulation is mostly reasonable, and the evaluation seems quite convincing.[[MET-POS], [EMP-POS], [APC], [MAJ]] The paper is well-written: I enjoyed the mathematical formulation (Section 3).[[MET-POS,OAL-POS], [CLA-POS,EMP-POS], [APC], [MAJ]] The authors did a good job of using different experiments (filtration number analysis, and teaching both the same architecture and a different architecture) to intuitively explain what their method actually does.[[EXP-POS,MET-POS,ANA-POS], [EMP-POS], [APC], [MAJ]] \n\nAt the same time, though, I see several important issues that need to be addressed if this paper is to be accepted.[[OAL-NEU], [REC-NEU], [FBK], [MAJ]] Details below. \n\n1. As much as I enjoyed reading Section 3, it is very redundant.[[MET-NEG], [CLA-NEG], [CRT], [MIN]] In some cases it is good to outline a powerful and generic framework (like the authors did here with defining \"teaching\" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).[[MET-NEU,ANA-NEU], [EMP-NEU], [SUG,DIS], [MIN]] However, I do not see it being the case here.[[MET-NEG,ANA-NEG], [EMP-NEG], [CRT], [MIN]] In my opinion, selecting good loss functions and hypothesis spaces are much harder problems than data teaching - except maybe when one use a pre-defined set of possible loss functions and select from it.[[EXT-NEU], [null], [DIS], [MIN]] But that is not very interesting (if you can propose new loss functions, that would be way cooler).[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] I also do not see how to define an intuitive set of \"states\" in that case.[[MET-NEG,ANA-NEG], [SUB-NEG], [DFT], [MIN]] Therefore, I think this section should be shortened.[[MET-NEU], [PNF-NEU], [SUG], [MIN]] I also think that the authors should not discuss the general framework and rather focus on \"data teaching\", which is the only focus of the current paper.[[PDI-NEU], [null], [SUG], [MAJ]] The abstract and introduction should also be modified accordingly to more honestly reflect the current contributions.[[ABS-NEU,INT-NEU], [PNF-NEU], [SUG], [MIN]] \n2. The authors should do a better job at explaining the details of the state definition, especially the student model features and the combination of data and current learner model.[[MET-NEU,ANA-NEU], [SUB-NEU], [SUG], [MAJ]] \n3. There is only one definition of the reward - related to batch number when the accuracy first exceeds a threshold.[[MET-NEG], [SUB-NEG], [DFT,CRT], [MAJ]] Is accuracy stable, can it drop back down below the threshold in the next epoch?[[RES-NEU], [EMP-NEU], [QSN], [MIN]] The accuracy on a held-out test set is not guaranteed to be monotonically increasing, right? [[RES-NEU], [EMP-NEU], [QSN], [MIN]]Is this a problem in practice (it seems to happen on your curves)?[[RES-NEU], [EMP-NEU], [QSN], [MIN]] What about other potential reward definitions?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] And what would they potentially lead to? [[MET-NEU], [EMP-NEU], [QSN], [MIN]] n4. Experimental results are averaged over 5 repeated runs - a bit too small in my opinion.[[EXP-NEG,RES-NEG], [SUB-NEG,EMP-NEU], [CRT], [MAJ]] \n5. Can the authors show convergence of the teacher parameter \\theta?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] I think it is important to see how fast the teacher model converges, too.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] \n6. In some of your experiments, every training method converges to the same accuracy after enough training (Fig.2b), while in others, not quite (Fig. 2a and 2c).[[EXP-NEU,MET-NEU,TNF-NEU], [EMP-NEU], [DIS], [MIN]] Why is this the case?[[EXP-NEU], [EMP-NEU], [QSN], [MIN]] Does it mean that you have not run enough iterations for the baseline methods?[[RWK-NEU,EXP-NEU,MET-NEU], [SUB-NEU], [QSN], [MIN]] My intuition is that if the learner algorithm is convex, then ultimately they will all get to the same accuracy level, so the task is just to get there quicker.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] I understand that since the learner algorithm is an NN, this is not the case - but more explanation is necessary here - does your method also reduces the empirical possibility to get stuck in local minima?[[MET-NEU,ANA-NEU], [SUB-NEU,EMP-NEU], [QSN], [MAJ]] \n7. More explanation is needed towards Fig.4c.[[TNF-NEU], [SUB-NEU], [DIS], [MIN]] In this case, using a teacher model trained on a harder task (CIFAR10) leads to much improved student training on a simpler task (MNIST). Why?[[DAT-NEU,EXP-NEU], [EMP-NEU], [QSN], [MIN]]\n8. Although in terms of \"effective training data points\" the proposed method outperforms the other methods, in terms of time (Fig.5) the difference between it and say, NoTeach, is not that significant (especially at very high desired accuracy).[[MET-NEU], [EMP-NEU], [DIS], [MAJ]] More explanation needed here. [[MET-NEU], [SUB-NEU], [DIS], [MAJ]]\n\nRead the rebuttal and revision and slightly increased my rating."[[OAL-POS], [REC-POS], [FBK], [MAJ]]