"Paper examines the use of skip connections (including residual layers) in deep networks as a way of alleviating two perceived difficulties in training: 1) when a neuron does not contain any information, and[[MET-NEU], [null], [SMY], [GEN]] 2) when two neurons in a layer compute the same function.[[MET-NEU], [null], [SMY], [GEN]] Both of these cases lead to singularities in the Hessian matrix, and this work includes a number of experiments showing the effect of skip connections on the Hessian during training.[[EXP-NEU], [null], [SMY], [GEN]] \n\nThis is a significant and timely topic.[[EXP-NEU], [null], [CRT], [MIN]] While I may not be the best one to judge the originality of this work, I appreciated how the authors presented clear and concise arguments with experiments to back up their claims.\n\n"[[EXP-POS], [EMP-POS,PNF-POS], [APC], [MAJ]] 