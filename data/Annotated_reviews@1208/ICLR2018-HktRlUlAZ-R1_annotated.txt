"This paper presents a new convolutional network architecture that is invariant to global translations and equivariant to rotations and scaling.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] The method is combination of a spatial transformer module that predicts a focal point, around which a log-polar transform is performed. [[MET-NEU], [null], [SMY], [GEN]]The resulting log-polar image is analyzed by a conventional CNN.[[MET-NEU,RES-NEU], [null], [SMY], [GEN]]\n\nI find the basic idea quite compelling.[[PDI-POS], [EMP-POS], [APC], [MAJ]] Although this is not mentioned in the article, the proposed approach is quite similar to human vision in that people choose where to focus their eyes, and have an approximately log-polar sampling grid in the retina.[[MET-NEU], [CMP-NEU], [DIS], [GEN]] Furthermore, dealing well with variations in scale is a long-standing and difficult problem in computer vision, and using a log-spaced sampling grid seems like a sensible approach to deal with it.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nOne fundamental limitation of the proposed approach is that although it is invariant to global translations, it does not have the built-in equivariance to local translations that a ConvNet has.[[MET-NEG], [CMP-NEG], [CRT], [MAJ]] Although we do not have data on this, I would guess that for more complex datasets like imagenet / ms coco, where a lot of variation can be reasonably well modelled by diffeomorphisms, this will result in degraded performance.[[DAT-NEU,RES-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nThe use of the heatmap centroid as the prediction for the focal point is potentially problematic as well.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] It would not work if the heatmap is multimodal, e.g. when there are multiple instances in the same image or when there is a lot of clutter.\n\nThere is a minor conceptual confusion on page 4, where it is written that \"Group-convolution requires integrability over a group and identification of the appropriate measure dg.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] We ignore this detail as implementation requires application of the sum instead of integral.[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]]\"\nWhen approximating an integral by a sum, one should generally use quadrature weights that depend on the measure, so the measure cannot be ignored.[[MET-NEU], [EMP-NEU], [SUG], [MIN]] Fortunately, in the chosen parameterization, the Haar measure is equal to the standard Lebesque measure, and so when using equally-spaced sampling points in this parameterization, the quadrature weights should be one.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] (Please double-check this - I'm only expressing my mathematical intuition but have not actually proven this).[[EXT-NEU], [CNT], [DIS], [GEN]]\n\nIt does not make sense to say that \"The above convolution requires computation of the orbit which is feasible with respect to the finite rotation group, but not for general rotation-dilations\", and then proceed to do exactly that (in canonical coordinates).[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Since the rotation-dilation group is 2D, just like the 2D translation group used in ConvNets, this is entirely feasible.[[MET-POS], [EMP-POS], [APC], [MAJ]] The use of canonical coordinates is certainly a sensible choice (for the reason given above),[[MET-POS], [EMP-POS], [APC], [MAJ]] but it does not make an infeasible computation feasible.[[EXP-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nThe authors may want to consider citing[[BIB-NEG], [SUB-NEG,PNF-NEG], [DFT,CRT], [MIN]]\n- Warped Convolutions: Efficient Invariance to Spatial Transformations, Henriques & Vedaldi.[[BIB-NEU], [SUB-NEU], [DIS], [MIN]]\nThis paper also uses a log-polar transform, but lacks the focal point prediction / STN.[[EXT-NEU], [SUB-NEU], [DIS], [GEN]]\nLikewise, although the paper makes a good effort to rewiev the literature on equivariance / steerability,[[RWK-POS,MET-POS], [SUB-POS], [APC], [MAJ]] it missed several recent works in this area:\n- Steerable CNNs, Cohen & Welling\n- Dynamic Steerable Blocks in Deep Residual Networks, Jacobsen et al.[[RWK-NEG], [SUB-NEG,CMP-NEG], [DFT,CRT], [MAJ]] \n- Learning Steerable Filters for Rotation Equivariant CNNs, Weiler et al.[[RWK-NEG], [SUB-NEG,CMP-NEG], [DFT,CRT], [MAJ]]\nThe last paper reports 0.71% error on MNIST-rot, which is slightly better than the PTN-CNN-B++ reported on in this paper.[[RWK-NEG,DAT-NEG,RES-NEG], [CMP-NEG,EMP-NEG], [CRT], [MAJ]]\n\nThe experimental results presented in this paper are quite good,[[EXP-POS], [EMP-POS], [APC], [MAJ]] but both MNIST and ModelNet40 seem like simple / toyish datasets.[[DAT-NEG], [EMP-NEG], [CRT], [MAJ]] For reasons outlined above, I am not convinced that this approach in its current form would work very well on more complicated problems.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] If the authors can show that it does (either in its current form or after improving it, e.g. with multiple saccades, or other improvements) I would recommend this paper for publication.[[MET-NEU], [SUB-NEU,EMP-NEU], [DIS], [MAJ]]\n\n\nMinor issues & typos\n- Section 3.1, psi_gh = psi_g psi_h.[[OAL-NEG], [CLA-NEG], [CRT], [MIN]] I suppose you use psi for L and L', but this is not very clear.[[OAL-NEG], [CLA-NEG], [CRT], [MIN]]\n- L_h f = f(h^{-1}), p. 4\n- \"coordiantes\", p. 5"[[OAL-NEG], [CLA-NEG], [CRT], [MIN]]