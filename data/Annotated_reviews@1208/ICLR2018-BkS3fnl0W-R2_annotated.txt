"The idea of the paper is to use a GAN-like training to learn a novelty detection approach.[[PDI-NEU], [null], [SMY], [GEN]] In contrast to traditional GANs, this approach does not aim at convergence, where the generator has nicely learned to fool the discriminator with examples from the same data distribution.[[MET-POS], [null], [SMY], [GEN]] The goal is to build up a series of generators that sample examples close the data distribution boundary but are regarded as outliers[[MET-NEU], [null], [SMY], [GEN]]. To establish such a behavior, the authors propose early stopping as well as other heuristics.[[MET-NEU], [null], [SMY], [GEN]] \n\nI like the idea of the paper,;[[PDI-POS], [null], [APC], [MAJ]] however, this paper needs a revision in various aspects, which I simply list in the following:;[[OAL-NEU], [null], [SUG], [MAJ]]\n* The authors do not compare with a lot of the state-of-the-art in outlier detection and the obvious baselines: SVDD/OneClassSVM without PCA, Gaussian Mixture Model, KNFST, Kernel Density Estimation, etc\n* The model selection using the AUC of \"inlier accepted fraction\" is not well motivated in my opinion.[[RWK-NEG], [CMP-NEG], [CRT], [MAJ]] This model selection criterion basically leads too a probability distribution with rather steep borders and indirectly prevents the outlier to be too far away from the positive data.[[DAT-NEU,MET-NEG], [EMP-NEU], [SMY], [MAJ]] The latter is important for the GAN-like training.[[RWK-NEU], [CMP-NEU], [SUG], [GEN]]\n* The experiments are not sufficient: Especially for multi-class classification tasks, it is easy to sample various experimental setups for outlier detection. This allows for robust performance comparison. [[EXP-NEG], [SUB-NEG,CMP-NEU], [CRT], [MAJ]]\n* With the imbalanced training as described in the paper, it is quite natural that the confidence threshold for the classification decision needs to be adapted (not equal to 0.5)[[MET-NEU], [EMP-NEU], [DIS], [MAJ]]\n* There are quite a few heuristic tricks in the paper and some of them are not well motivated and analyzed (such as the discriminator training from multiple generators)[[MET-NEG,ANA-NEG], [EMP-NEG], [CRT], [MAJ]]\n* A cross-entropy loss for the autoencoder does not make much sense in my opinion (?)[[MET-NEU], [EMP-NEU], [QSN], [MAJ]]\n\n\nMinor comments:\n* Citations should be fixed (use citep to enclose them in ())[[BIB-NEU], [PNF-NEU], [SUG], [MIN]]\n* The term \"AI-related task\" sounds a bit too broad[[CNT], [PNF-NEU], [SUG], [MIN]]\n* The authors could skip the paragraph in the beginning of page 5 on the AUC performance. AUC is a standard choice for evaluation in outlier detection.[[MET-NEU], [PNF-NEU], [SUG], [MIN]]\n* Where is Table 1?[[TNF-NEU], [PNF-NEU], [QSN], [MIN]]\n* There are quite a lot of typos.[[OAL-NEG], [CLA-NEG], [CRT], [MIN]]\n\n*After revision statement*\nI thank the authors for their revision, but I keep my rating.[[OAL-NEU], [REC-NEU], [FBK], [MAJ]] The clarity of the paper has improved;[[OAL-POS], [CLA-POS], [APC], [MAJ]] but the experimental evaluation is lacking realistic datasets and further simple baselines (as also stated by the other reviewers)"[[RWK-NEG,DAT-NEU,EXP-NEG], [SUB-NEG], [CRT], [MAJ]]