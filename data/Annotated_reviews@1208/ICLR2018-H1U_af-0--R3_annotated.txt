"This paper shows that techniques due to Genz & Monahan (1998) can be used to achieve low kernel approximation error under the framework of random fourier feature.[[INT-NEU,RWK-NEU], [null], [SMY], [GEN]]\n\nPros\n\n1. It is new to apply quadrature rules to improve kernel approximation.[[PDI-POS], [NOV-POS], [APC], [MAJ]] The only other work I found is\nGaussian Quadrature for Kernel Features NIPS 2017. \nThe work is pretty recent so the author might not know it when submitting the paper.[[RWK-POS], [NOV-POS,CMP-POS], [DIS], [MAJ]] But in either case, it will be good to discuss the connections.[[OAL-NEU], [CMP-NEU], [SUG], [MIN]]\n\n2. The proposed method is shown to outperform a few baselines empirically.[[MET-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]\n\nCons\n\n1. I don\u2019t find the theoretical analysis to be very useful.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] In particular, the theorem shows that the kernel approximation error is O(1/D), which is the same as the original RFF paper.[[RWK-NEG], [CMP-NEG], [DFT], [MAJ]] Unless the paper can provide a better characterization of the constants (like the ORF paper), it does not provide much insight in the proposed method.[[MET-NEU], [EMP-NEU], [DFT,DIS], [MAJ]] Unlike deep neural networks, since RFF is such a simple model, I think providing precise theoretical understanding is crucial.[[MET-NEU], [EMP-NEU], [SUG,DIS], [MIN]] \n\n2. Approximating an integral is a well-studied topic. I do not find a good discussion on all the possible methods.[[MET-NEG], [null], [DFT], [MAJ]] Why is Genz & Monahan 1998 better than other alternatives such as Monte-Carlo, QMC etc?[[MET-NEU], [null], [QSN], [MIN]] One argument seems to be \u201cfor kernels with specific specific integrand one can improve on its properties\u201d. But this trick can be used for Monte-Carlo as well. And I do not see benefit of this trick in the curves.[[MET-NEG], [EMP-NEG], [DFT,DIS], [MAJ]]\n\n3. When choosing the orthogonal matrix, I think one obvious choice is to sample a matrix from the Stiefel manifold (the Q matrix of a random Gaussian). This baseline should be added in additional to H and B.[[RWK-NEU,MET-NEU], [EMP-NEU], [SUG], [GEN]]\n\n4. A wall-time experiment is needed to justify the speedup.[[EXP-NEU], [null], [SUG], [MIN]]\n\nMinor comments:\n\u201cFor kennels with q(w) other than Gaussian\u2026 obtain very accurate results with little effort by using Gaussian approximation of q(w)\u201d.[[MET-POS], [EMP-POS], [SMY], [MIN]] What is the citation of this in the kernel approximation context?"[[MET-NEU], [null], [QSN], [MIN]]