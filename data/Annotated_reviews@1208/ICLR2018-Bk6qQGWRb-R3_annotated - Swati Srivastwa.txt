"(Last minute reviewer brought in as a replacement).\n\nThis paper proposed \"Bayesian Deep Q-Network\" as an approach for exploration via Thompson sampling in deep RL.[[INT-NEU,MET-NEU], [null], [SMY], [GEN]] \nThis algorithm maintains a Bayesian posterior over the last layer of the neural network and uses that as an approximate measure of uncertainty.[[INT-NEU,MET-NEU], [null], [SMY], [GEN]]\nThe agent then samples from this posterior for an approximate Thompson sampling.[[MET-NEU], [null], [SMY], [GEN]]\nExperimental results show that this outperforms an epsilon-greedy baseline.[[RWK-POS,EXP-POS,RES-POS], [CMP-POS], [APC], [MAJ]]\n\nThere are several things to like about this paper:\n- The problem of efficient exploration with deep RL is important and under-served by practical algorithms.[[MET-POS], [EMP-POS], [APC], [MAJ]] This seems like a good algorithm in many ways.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n- The paper is mostly clear and well written.[[OAL-POS], [CLA-POS], [APC], [MAJ]]\n- The experimental results are impressive in their outperformance.[[EXP-POS], [EMP-POS], [APC], [MAJ]]\n\nHowever, there are also some issues, many of which have already been raised:\n- The poor performance of the DDQN baseline is concerning and does not seem to match the behavior of prior work (see Pong for example).[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]]\n- There are some loose and misleading descriptions of the algorithm computing \"the posterior\" when actually this is very much an approximation method... that's OK to have approximations but it shouldn't be hidden away.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n- The connection to RLSVI is definitely understated, since with a linear architecture this is precisely RLSVI.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] The sentiment that extending TS to larger spaces hasn't been fully explored is definitely valid... but this line of work should certainly be mentioned in the 4th paragraph. [[MET-NEG,ANA-NEG], [SUB-NEG], [DFT], [MIN]] RLSVI is provably-efficient with a state-of-the-art regret bound for tabular learning - you would probably strengthen the case for this algorithm as an extension of RLSVI by building on this connection... otherwise it's a bit adhoc to justify this approximation method.[[RWK-NEU,MET-NEU], [CMP-NEU], [SUG], [MIN]]\n- This paper spends a lot of time re-deriving Bayesian linear regression in a really standard way... and without much discussion of how/why this method is an approximation (it is) especially when used with deep nets.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nOverall, I like this paper and the approach of extending TS-style algorithms to Deep RL by just taking the final layer of the neural network.[[MET-POS,OAL-POS], [EMP-NEG], [DFT], [MIN]]\nHowever, it also feels like there are some issues with the baselines + being a bit more clear about the approximations / position relative to other algorithms for approximate TS would be a better approach.[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]]\nFor example, in linear networks this is the same as RLSVI, bootstrapped DQN is one way to extend this idea to deep nets, but this is another one and it is much better because XYZ. (this discussion could perhaps replace the rather mundane discussion of BLR, for example).[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]]\n\nIn it's current state I'd say marginally above, but wouldn't be surprised if these changes turned it into an even better paper quite quickly.[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]]\n\n\n===============================================================\n\nRevising my review following the rebuttal period and also the (ongoing) revisions to the paper.[[EXT-NEU], [null], [DIS], [GEN]]\n\nI've been disappointed by the authors have incorporated the feedback/reviews - I expected something a little more clear / honest.[[EXT-NEG], [null], [DIS], [GEN]] Given the ongoing review decisions/issues I'm putting my review slightly below accept..[[OAL-NEU], [REC-NEU], [FBK], [MAJ]]\n\n## Relation to literature on \"randomized value functions\"\nIt's really wrong to present BDQN as is if it's the first attempt at large-scale approximations to Thompson sampling (and then slip in a citation to RLSVI as a BDQN-like algorithm).[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] This algorithm is a form of RLSVI (2014) where you only consider uncertainty over the last (linear) layer - I think you should present it like this.[[MET-NEU], [EMP-NEU], [SUG], [MIN]] Similarly *some* of the results for Bootstrapped DQN (2016) on Atari are presented without bootstrapping (pure ensemble) but this is very far from an essential part of the algorithm![[MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]] If you say something like \"they did not estimate a true posterior\" then you should quantify this and (presumably) justify the implication that taking a gaussian approximation to the final layer is a *true* posterior.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] In a similar vein, you should be clear about the connections to Lipton et al 2016 as another method for approximate Bayesian posteriors in DQN.[[RWK-NEU], [CMP-NEU], [DIS], [MIN]]\n\n## Quality/science of experiments\nThe experimental results have been updated, and the performance of the baseline now seems much more reasonable.[[RWK-POS,EXP-POS,RES-POS], [CMP-POS,EMP-POS], [APC], [MAJ]] However, the procedure for \"selecting arbitrary number of frames\" to report performance seems really unnecessary....[[DAT-NEG], [EMP-NEG], [CRT], [MAJ]] it would be clear that BDQN is outperforming DDQN..[[MET-NEU], [CMP-NEU], [DIS], [MIN]] you should run them all for the same number of frames and then either compare (final score, cumulative score, #frames to human) or something else more fair/scientific.[[DAT-NEU,EXP-NEU], [EMP-NEU], [DIS], [MIN]] This type of stuff smells like overfitting!".[[EXP-NEG], [EMP-NEG], [CRT], [MIN]]