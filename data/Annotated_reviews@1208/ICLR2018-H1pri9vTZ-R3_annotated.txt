"This paper deals with the problem of learning nonlinear operators using deep learning.[[INT-NEU], [null], [SMY], [GEN]] Specifically, the authors propose to extend deep neural networks to the case where hidden layers can be infinite-dimensional.[[INT-NEU], [null], [SMY], [GEN]] They give results on the quality of the approximation using these operator networks, and show how to build neural network layers that are able to take into account topological information from data.[[DAT-NEU,MET-NEU,RES-NEU], [EMP-NEU], [SMY], [GEN]] Experiments on MNIST using the proposed deep function machines (DFM) are provided.[[EXP-NEU], [null], [SMY], [GEN]] \n\nThe paper attempts to make progress in the region between deep learning and functional data analysis (FDA). This is interesting.[[INT-POS], [null], [APC], [MAJ]] Unfortunately, the paper requires significant improvements, both in terms of substance and in terms of presentation.[[OAL-NEU], [SUB-NEU,PNF-NEU], [DFT], [MAJ]] My main concerns are the following:\n\n1) One motivation of DFM is that in many applications data is a discretization of a continuous process and then can be represented by a function.[[MET-NEU], [EMP-NEU], [DIS], [GEN]] FDA is the research field that formulated the ideas about the statistical data analysis of data samples consisting of continuous functions, where each function is viewed as one sample element.[[MET-NEU], [null], [DIS], [GEN]] This paper fails to consider properly the work in its FDA context. [[MET-NEG], [SUB-NEG], [CRT], [MAJ]]Operator learning has been already studied in FDA. See for e.g. the problem of functional regression with functional responses.[[MET-NEU], [NOV-NEG], [DIS], [MAJ]] Indeed the functional model considered in the linear case is very similar to Eq. 2.5 or Eq. 3.2. Moreover, extension to nonparametric/nonlinear situations were also studied.[[RWK-NEU,MET-NEU], [null], [CRT], [MAJ]] The authors should add more information about previous work on this topic so that their results can be understood with respect to previous studies.\[[RWK-NEG], [CMP-NEU], [SUG], [MAJ]]n\n2) The computational aspects of DFM are not clear in the paper.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] From a practical computational perspective, the algorithm will be implemented on a machine which processes on finite representations of data.[[MET-NEU], [EMP-NEG], [DIS], [GEN]] The paper does not clearly provide information about how the functional nature and the infinite dimensional can be handled in practice. In FDA, generally this is achieved via basis function approximations.[[MET-NEG], [EMP-NEG], [DFT], [MAJ]]\n\n3) Some parts of the paper are hard to read. Sections 3 and 4 are not easy to understand.[[OAL-NEU], [CLA-NEG], [CRT], [MIN]] Maybe adding a section about the notation and developing more the intuition will improve the reading of the manuscript.[[EXT-NEU], [CLA-NEU], [SUG], [MIN]] \n\n4) The experimental section can be significantly improved.[[EXP-NEU], [EMP-NEU], [SUG], [MAJ]] It will be interesting to compare more DFM with its discrete counterpart.[[MET-NEU], [CMP-NEU], [SUG], [MIN]] Also, other FDA approaches for operator learning should be discussed and compared to the proposed approach.\n"[[MET-NEU], [CMP-NEU], [SUG], [MIN]]