"Clarity \nThe paper is well-written and clear.[[OAL-POS], [CLA-POS], [APC], [MAJ]] \n\nOriginality\nThe paper proposes a path consistency learning method with a new combination of entropy regularization and relative entropy.[[INT-NEU,MET-NEU], [null], [SMY], [GEN]] The paper leverages a novel method in determining the coefficient of relative entropy.[[INT-POS,MET-POS], [NOV-POS], [SMY], [GEN]]  \n\nSignificance\n- Trust-PCL achieves overall competitive with state-of-the-art external implementations.[[MET-POS,RWK-POS], [IMP-POS,CMP-POS], [APC], [MAJ]]\n- Trust-PCL (off-policy) significantly outperform TRPO in terms of data efficiency and final performance.[[RES-POS], [EMP-POS], [APC], [MAJ]]  \n- Even though the paper claims Trust-PCL (on-policy) is close to TRPO, the initial performance of TRPO looks better in HalfCheetah, Hopper, Walker2d and Ant.[[RWK-NEG,RES-NEG], [CMP-NEG], [APC], [MIN]]  \n- Some ablation studies (e.g., on entropy regularization and relative entropy) and sensitivity analysis on parameters (e.g. \\alpha and update frequency on \\phi) would be helpful.[[ANA-NEU], [SUB-NEU], [SUG], [MIN]] \n\nPros:\n- The paper is well-written and clear.[[OAL-POS], [CLA-POS], [APC], [MAJ]]  \n- Competitive with state-of-the-art external implementations[[RWK-POS], [CMP-POS], [APC], [MAJ]] \n- Significant empirical advantage over TRPO.[[MET-POS], [EMP-POS], [APC], [MAJ]] \n-  Open source codes.[[MET-POS], [EMP-POS], [APC], [MAJ]] \n\nCons:\n- No ablation studies. \n"[[ANA-NEG], [SUB-NEG], [CRT], [MIN]] 