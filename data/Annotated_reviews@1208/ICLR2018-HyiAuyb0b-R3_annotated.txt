"The authors present a testing framework for deep RL methods in which difficulty can be controlled along a number of dimensions, including: reward delay, reward sparsity, episode length with terminating rewards, binary vs real rewards and perceptual complexity.[[INT-NEU,PDI-NEU], [null], [DIS], [GEN]] The authors then experiment with a variety of TD and MC based deep learners to explore which methods are most robust to increases in difficulty along these dimensions.[[EXP-NEU,MET-NEU], [null], [DIS], [GEN]] The key finding is that MC appears to be more robust than TD in a number of ways, and in particular the authors link this to domains with greater perceptual challenges.[[MET-NEU], [null], [DIS], [GEN]] \n\nThis is a well motivated and explained paper, in which a research agenda is clearly defined and evaluated carefully with the results reflected on thoughtfully and with intuition.[[EXP-POS,MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The authors discover some interesting characteristics of MC based Deep-RL which may influence future work in this area, and dig down a little to uncover the principles a little.[[MET-POS,FWK-POS], [IMP-POS], [APC], [MAJ]] The testing framework will be made public too, which adds to the value of this paper.[[OAL-POS], [EMP-POS], [APC], [MAJ]] I recommend the paper for acceptance and expect it will garner interest from the community.[[OAL-POS], [REC-POS], [FBK], [MAJ]]\n\nDetailed comments\n  \u2022 [p4, basic health gathering task] \"The goal is to survive and maintain as much health\nas possible by collecting health kits...[[RES-NEU], [EMP-NEU], [DIS], [MIN]]The reward is +1 when the agent collects a health kit and 0 otherwise.[[RES-NEU], [EMP-NEU], [DIS], [MIN]]\" The reward suggests that the goal is to collect as many health kits as possible, for which surviving and maintaining health are secondary.[[RES-NEU], [EMP-NEU], [DIS], [MIN]]\n  \u2022 [p4, Delayed rewards] It might be interesting to have a delay sampled from a distribution with some known mean.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Otherwise, the structure of the environment might support learning even when the reward delay would otherwise not.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n  \u2022 [p4, Sparse rewards] I am not sure it is fair to say that the general difficulty is kept fixed.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Rather, the average achievable reward for an oracle (that knows whether health packs are) is fixed.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n  \u2022 [p6] \"Dosovitskiy & Koltun (2017) have not tested DFP on Atari games.[[RWK-NEU], [CMP-NEU], [DIS], [MIN]]\" Probably fairer/safer to say: did not report results on Atari games.\n"[[RWK-NEU], [CMP-NEU], [DIS], [MIN]]