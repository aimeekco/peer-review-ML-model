"NOTE: \n\nWould the authors kindly respond to the comment below regarding Kekulisation of the Zinc dataset?[[DAT-NEU], [EMP-NEU], [QSN], [GEN]] Fair comparison of the data is a serious concern.[[DAT-NEU], [EMP-NEU], [DIS], [MAJ]] I have listed this review as a good for publication due to the novelty of ideas presented,[[OAL-POS], [NOV-POS], [APC], [MAJ]] but the accusation of misrepresentation below is a serious one and I would like to know the author's response.[[DAT-NEG], [EMP-NEG], [CRT], [MAJ]]\n\n*Overview*\n\nThis paper presents a method of generating both syntactically and semantically valid data from a variational autoencoder model using ideas inspired by compiler semantic checking. Instead of verifying the semantic correctness offline of a particular discrete structure, the authors propose \u201cstochastic lazy attributes\u201d, which amounts to loading semantic constraints into a CFG and using a tailored latent-space decoder algorithm that guarantees both syntactic semantic valid.[[PDI-NEU,DAT-NEU,MET-NEU,RES-NEU], [null], [SMY], [GEN]] Using Bayesian Optimization, search over this space can yield decodings with targeted properties.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n\nMany of the ideas presented are novel.[[OAL-POS], [NOV-POS], [APC], [MAJ]] The results presented are state-of-the art.[[RES-POS], [CMP-POS,EMP-POS], [APC], [MAJ]] As noted in the paper, the generation of syntactically and semantically valid data is still an open problem.[[DAT-NEU], [null], [DIS], [GEN]] This paper presents an interesting and valuable solution, and as such constitutes a large advance in this nascent area of machine learning.[[RES-POS], [EMP-POS], [APC], [MAJ]]\n\n*Remarks on methodology*\n\nBy initializing a decoding by \u201cguessing\u201d a value, the decoder will focus on high-probability starting regions of the space of possible structures.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] It is not clear to me immediately how this will affect the output distribution.[[MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]] Since this process on average begins at high-probability region and makes further decoding decisions from that starting point, the output distribution may be biased since it is the output of cuts through high-probability regions of the possible outputs space.[[MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MIN]] Does this sacrifice exploration for exploitation in some quantifiable way?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Some exploration of this issue or commentary would be valuable.[[MET-NEU], [SUB-NEU], [SUG], [MIN]] \n\n*Nitpicks*\n\nI found the notion of stochastic predetermination somewhat opaque, and section 3 in general introduces much terminology, like lazy linking, that was new to me coming from a machine learning background.[[MET-NEU], [PNF-NEU], [DIS], [MIN]] In my opinion, this section could benefit from a little more expansion and conceptual definition.[[MET-NEU], [SUB-NEU], [SUG], [MIN]]\n\nThe first 3 sections of the paper are very clearly written,[[CNT], [CLA-POS], [APC], [MAJ]] but the remainder has many typos and grammatical errors (often word omission).[[CNT], [CLA-NEG], [CRT], [MIN]] The draft could use a few more passes before publication.\n"[[OAL-NEU], [REC-NEU], [FBK], [MAJ]]