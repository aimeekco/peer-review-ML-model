"This paper proposes to jointly learning a semantic objective and inducing a binary tree structure for word composition, which is similar to (Yogatama et al, 2017).[[INT-NEU,PDI-NEU], [CMP-NEU], [DIS], [GEN]] Differently from (Yogatama et al, 2017), this paper doesn\u2019t use reinforcement learning to induce a hard structure, but adopts a chart parser manner and basically learns all the possible binary parse trees in a soft way.[[RWK-NEU,MET-NEU], [CMP-NEU], [SMY], [GEN]] \n\nOverall, I think it is really an interesting direction and the proposed method sounds reasonable.[[MET-POS,OAL-POS], [EMP-POS], [DIS], [MAJ]] However, I am concerned about the following points:  \n\n- The improvements are really limited on both the SNLI and the Reverse Dictionary tasks.[[RES-NEG], [EMP-NEG], [CRT], [MIN]] (Yogatama et al, 2017) demonstrate results on 5 tasks and I think it\u2019d be helpful to present results on a diverse set of tasks and see if conclusions can generally hold.[[RWK-NEU,DAT-NEU], [EMP-NEU], [APC], [MIN]] Also, it would be much better to have a direct comparison to (Yogatama et al, 2017), including the performance and also the induced tree structures.[[RWK-NEU,RES-NEU], [CMP-NEU], [SUG], [MIN]]\n\n- The computational complexity of this model shouldn\u2019t be neglected.[[MET-NEU], [CNT], [DIS], [MIN]] If I understand it correctly, the model needs to compute O(N^3) LSTM compositions.[[MET-NEU], [CNT], [DIS], [MIN]] This should be at least discussed in the paper.[[MET-NEU], [SUB-NEU], [SUG,DIS], [MIN]] And I am not also sure how hard this model is being converged in all experiments (compared to LSTM or supervised tree-LSTM).\[[EXP-NEU], [EMP-NEU], [DIS], [MIN]]n\n- I am wondering about the effects of the temperature parameter t. Is that important for training?[[EXP-NEU], [EMP-NEU], [QSN], [MIN]]\n\nMinor:\n- What is the difference between LSTM and left-branching LSTM?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n- I am not sure if the attention overt chart is a highlight of the paper or not.[[MET-NEU], [PNF-NEU], [DIS], [MIN]] If so, better move that part to the models section instead of mention it briefly in the experiments section.[[EXP-NEU], [PNF-NEU], [SUG], [MIN]] Also, if any visualization (over the chart) can be provided, that\u2019d be helpful to understand what is going on. \n"[[EXP-NEU], [SUB-NEU], [SUG], [MIN]]