"In a previous work [1], an auto-placement (better model partition on multi GPUs) method was proposed to accelerate a TensorFlow model\u2019s runtime.[[RWK-NEU,PDI-NEU,MET-NEU], [IMP-NEU,EMP-NEU], [SMY], [MAJ]] However, this method requires the rule-based co-locating step, in order to resolve this problem, the authors of this paper purposed a fully connect network (FCN) to replace the co-location step.[[INT-NEU,RWK-NEU,PDI-NEU,MET-NEU], [SUB-NEU,EMP-NEU], [SMY], [GEN]] In particular, hand-crafted features are fed to the FCN and the output is the prediction of group id of this operation.[[PDI-NEU,DAT-NEU,EXP-NEU,MET-NEU,RES-NEU], [IMP-NEU,EMP-NEU], [SMY], [CNT]] Then all the embeddings in each group are averaged to serve as the input of a seq2seq encoder.[[PDI-NEU,DAT-NEU,MET-NEU], [EMP-NEU], [SUG,DIS], [GEN]] \n\nOverall speaking, this work is quite interesting.[[OAL-POS], [SUB-POS], [APC], [MAJ]] However, it also has several limitations, as explained below.\[[RWK-NEG,PDI-NEG], [SUB-NEG], [DFT], [MIN]]n\nFirst, the computational cost of the proposed method seems very high. [[PDI-NEG,EXP-NEG,MET-NEG,ANA-NEG], [EMP-NEG], [DFT], [MIN]]It may take more than one day on 320-640 GPUs for training (I did not find enough details in this paper, but the training complexity will be no less than the in [1]).[[RWK-NEG,EXP-NEG,MET-NEG], [SUB-NEG], [DFT], [MIN]] This makes it very hard to reproduce the experimental results (in order to verify it), and its practical value becomes quite restrictive (very few organizations can afford such a cost).[[PDI-NEG,EXP-NEU,RES-NEU], [SUB-NEG,EMP-NEU], [SUG,DFT], [MIN]]\n\nSecond, as the author mentioned, it\u2019s hard to compare the experimental results in this paper wit those in [1] because different hardware devices and software versions were used.[[RWK-NEG,PDI-NEG,EXP-NEG,RES-NEG], [IMP-NEG,CMP-NEG,EMP-NEG], [DFT], [MIN]] However, this is not a very sound excuse.[[RWK-NEG], [null], [DFT], [MIN]] I would encourage the authors to implement colocRL [1] on their own hardware and software systems, and make direct comparison. [[RWK-NEG,PDI-NEG,EXT-NEG], [CMP-NEG], [SUG,DFT], [MIN]]Otherwise, it is very hard to tell whether there is improvement, and how significant the improvement is[[RWK-NEU], [IMP-NEU], [SUG,DIS], [GEN]]. In addition, it would be better to have some analysis on the end-to-end runtime efficiency and the effectiveness of the placements[[RWK-NEU,PDI-NEU,ANA-NEG], [IMP-NEG], [DFT], [MIN]].\n\n [1] Mirhoseini A, Pham H, Le Q V, et al. Device Placement Optimization with Reinforcement Learning[J]. arXiv preprint arXiv:1706.04972, 2017. https://arxiv.org/pdf/1706.04972.pdf \n"[[CNT], [CNT], [CNT], [CNT]]