"This is an emergency review, as the replacement of an overdue review.[[CNT], [CNT], [CNT], [GEN]] \n\n------------------------------------------------------------------------\n\nThis paper proposes three variants of the exponential linear unit (ELU) by adding a learnable shift variable for each hidden unit.[[INT-NEU], [null], [SMY], [GEN]] This modification to ELU is motivated by the claimed observation that a learned piecewise linear activation function appears to have the ELU shape despite a bias factor.[[PDI-NEU], [null], [SMY], [GEN]] \n\nHowever, the motivation above is not justified well.[[PDI-NEG], [null], [CRT], [MAJ]] No theoretic results are present to support this design.[[RES-NEG], [SUB-NEG], [DFT], [MAJ]] Figure 4 shows the only experimental results to \u201csupport\u201d the motivation.[[RES-NEU,TNF-NEU], [PNF-NEU], [DIS], [MIN]] However, it is a bit weird that 1) 100% tuned results are not shown, and 2) the learned activation goes up as the input goes negative, which is not the shape of ELU.[[RES-NEG], [SUB-NEG,EMP-NEG], [DFT,CRT], [MAJ]] As a result, the motivation does not seem clear.[[PDI-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nThe shift variables seem only useful when they are not shared for different pixels.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Otherwise, the shift can be implemented by the bias term of the convolutional kernels and the bias term following batch normalization (if used).[[MET-NEU], [EMP-NEU], [SUG,DIS], [MIN]] The question is if it is worth adding so many pixel-wise parameters.[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Moreover, the proposed formulation does not seem useful for the fully connected layer at any time.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] \n\nThe experiments are limited.[[EXP-NEG], [EMP-NEG], [CRT], [MIN]] Only the basic LeNet and another network are considered on Cifar-100.[[DAT-NEU], [CNT], [DIS], [MIN]] The results are not as good as the state-of-the-art.[[RWK-NEG,RES-NEG], [CMP-NEG], [CRT], [MAJ]] More importantly, the proposed activation functions reduce the errors only a bit (<0.5%).[[MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MIN]] Stronger results on more datasets are necessary to justify the usefulness of the proposed method.\n"[[DAT-NEU,RES-NEU], [SUB-NEU], [SUG,DIS], [MIN]]