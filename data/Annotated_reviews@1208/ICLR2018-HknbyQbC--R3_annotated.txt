"The paper proposes a way of generating adversarial examples that fool classification systems.[[RWK-NEG], [IMP-NEG], [DFT], [MIN]]\nThey formulate it for a blackbox and a semi-blackbox setting (semi being, needed for training their own network, but not to generate new samples).\[[PDI-NEG,MET-NEU,RES-NEG], [IMP-NEG,EMP-NEU], [DFT,DIS], [MIN]]n\nThe model is a residual gan formulation, where the generator generates an image mask M, and (Input + M) is the adversarial example.\[[RWK-NEU,MET-NEU,RES-NEG], [IMP-NEG,EMP-NEU], [DFT,DIS], [MIN]]nThe paper is generally easy to understand and clear in their results.[[INT-POS,RES-POS], [CLA-POS,IMP-POS], [APC], [MAJ]]\nI am not awfully familiar with the literature on adversarial examples to know if other GAN variants exist[[RWK-NEU,MET-NEU], [EMP-NEU], [SMY,FBK], [GEN]]. From this paper's literature survey, they dont exist.[[INT-NEG,RWK-NEG], [IMP-NEG], [DFT], [MIN]] \nSo this paper is innovative in two parts:\n- it applies GANs to adversarial example generation\[[INT-NEU,MET-NEU], [EMP-NEU], [DIS], [GEN]]n- the method is a simple feed-forward network, so it is very fast to compute\[[RWK-NEU,MET-POS], [EMP-POS], [APC], [MAJ]]n\nThe experiments are pretty robust, and they show that their method is better than the proposed baselines[[PDI-POS,EXP-POS,MET-POS], [IMP-POS,EMP-POS], [APC], [MAJ]].\nI am not sure if these are complete baselines or if the baselines need to cover other methods (again, not fully familiar with all literature here).\n"[[EXP-NEU,MET-NEU,EXT-NEU], [null], [FBK], [GEN]]