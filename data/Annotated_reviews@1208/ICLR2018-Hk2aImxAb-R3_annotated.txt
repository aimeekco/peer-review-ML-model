"This paper introduces a new model to perform image classification with limited computational resources at test time. [[INT-NEU,PDI-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]]The model is based on a multi-scale convolutional neural network similar to the neural fabric (Saxena and Verbeek 2016),[[RWK-NEU,MET-NEU,BIB-NEU], [EMP-NEU], [SMY], [GEN]] but with dense connections (Huang et al., 2017) and with a classifier at each layer.[[RWK-NEU,MET-NEU,BIB-NEU], [EMP-NEU], [SMY], [GEN]] The multiple classifiers allow for a finer selection of the amount of computation needed for a given input image. [[RWK-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]]The multi-scale representation allows for better performance at early stages of the network.[[RWK-NEU,EXP-NEU,ANA-NEU], [EMP-NEU], [SMY,DIS], [GEN]] Finally the dense connectivity allows to reduce the negative effect that early classifiers have on the feature representation for the following layers.[[RWK-NEU], [null], [DIS], [GEN]]\nA thorough evaluation on ImageNet and Cifar100 shows that the network can perform better than previous models and ensembles of previous models with a reduced amount of computation.[[RWK-NEG,PDI-POS,EXP-POS,MET-POS], [IMP-POS,EMP-POS], [APC,DIS], [MAJ]]\n\nPros:\n- The presentation is clear and easy to follow.[[OAL-POS], [CLA-POS,PNF-POS], [APC], [MAJ]]\n- The structure of the network is clearly justified in section 4.[[RWK-POS], [APR-POS], [APC], [MAJ]]\n- The use of dense connectivity to avoid the loss of performance of using early-exit classifier is very interesting.[[PDI-POS,EXP-POS], [EMP-POS], [APC], [MAJ]]\n- The evaluation in terms of anytime prediction and budgeted batch classification can represent real case scenarios.[[RWK-NEU,EXP-NEU,ANA-NEU], [EMP-NEU], [SMY], [GEN]]\n- Results are very promising, with 5x speed-ups and same or better accuracy that previous models.[[RWK-NEU,RES-POS], [IMP-POS], [APC], [MAJ]]\n- The extensive experimentation shows that the proposed network is better than previous approaches under different regimes.[[RWK-NEU,PDI-POS,EXP-POS], [EMP-POS], [APC], [MAJ]]\n\nCons:\n- Results about the more efficient densenet* could be shown in the main paper[[RWK-NEG], [SUB-NEG,EMP-NEG], [DFT], [MIN]]\n\nAdditional Comments:\n- Why in training you used logistic loss instead of the more common cross-entropy loss?[[PDI-NEU], [EMP-NEU], [QSN], [GEN]] Has this any connection with the final performance of the network?[[RWK-NEU,RES-NEU], [null], [QSN], [GEN]]\n- In fig. 5 left for completeness I would like to see also results for DenseNet^MT and ResNet^MT[[RES-NEG,TNF-NEG], [SUB-NEG], [DFT], [MIN]]\n- In fig. 5 left I cannot find the 4% and 8% higher accuracy with 0.5x10^10 to 1.0x10^10 FLOPs, as mentioned in section 5.1 anytime prediction results[[RES-NEG,TNF-NEG], [SUB-NEG], [DFT], [MIN]]\n- How the budget in terms of Mul-Adds is actually estimated?\[[PDI-NEU], [EMP-NEU], [QSN], [GEN]]n\nI think that this paper present a very powerful approach to speed-up the computational cost of a CNN at test time and clearly explains some of the common trade-offs between speed and accuracy and how to improve them.[[INT-NEU,PDI-POS,MET-POS,ANA-POS], [SUB-POS,EMP-POS], [APC], [MAJ]] The experimental evaluation is complete and accurate. \n\n"[[PDI-POS,EXP-POS], [EMP-POS], [APC], [MAJ]]