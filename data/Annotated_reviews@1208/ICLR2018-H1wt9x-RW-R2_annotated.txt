"The authors define a novel method for creating a pair of models, a student and a teacher model, that are co-trained in a manner such that the teacher provides useful examples to the student to communicate a concept that is interpretable to people.[[PDI-POS,MET-POS], [NOV-POS,EMP-POS], [APC], [MAJ]] They do this by adapting a technique from computational cognitive science called rational pedagogy. [[PDI-NEU,MET-NEU], [null], [SMY], [GEN]]Rather than jointly optimize the student and teacher (as done previously), they have form a coupled relation between the student and teacher where each is providing a best response to the other. [[RWK-NEU], [EMP-NEU], [SMY], [GEN]]The authors demonstrate that their method provides interpretable samples for teaching in commonly used psychological domains and conduct human experiments to argue it can be used to teach people in a better manner than random teaching.[[PDI-POS,EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]] \n\nUnderstanding how to make complex models interpretable is an extremely important problem in ML for a number of reasons (e.g., AI ethics, explainable AI). [[RWK-NEU,PDI-NEU,BIB-NEU], [null], [QSN], [GEN]]The approach proposed by the authors is an excellent first step in this direction, and they provide a convincing argument for why a previous approach (joint optimization) did not work.[[RWK-POS,PDI-POS], [EMP-POS], [APC], [MAJ]] It is an interesting approach that builds on computational cognitive science research and the authors provide strong evidence their method creates interpretable examples.[[PDI-POS,MET-POS], [IMP-POS], [APC], [MAJ]] They second part of their article, where they test the examples created by their models using behavioral experiments was less convincing. [[RWK-NEU,EXP-NEG,MET-NEG], [IMP-NEG,EMP-NEG], [DFT], [MIN]]This is because they used the wrong statistical tests for analyzing the studies and it is unclear whether their results would stand with proper tests (I hope they will! \u2013 it seems clear that random samples will be harder to learn from eventually, but I also hoped there was a stronger baseline.).[[EXP-NEG,RES-NEG,ANA-NEG], [CLA-NEG,EMP-NEG], [DFT], [MIN]]\n\nFor analysis, the authors use t-tests directly on KL-divergence and accuracy scores; however, this is inappropriate (see Jaeger, 2008; Categorical data analysis: Away from ANOVAs (transformation or not) and towards logit mixed models.[[PDI-NEG,ANA-NEG,BIB-NEU], [EMP-NEG], [CRT], [MIN]] Journal of Memory and Language, 59(4), 434-446.).[[BIB-NEU], [null], [SMY], [GEN]] This is especially applicable to the accuracy score results and the authors should reanalyze their data following the paper referenced above.[[RWK-NEU,RES-NEU], [null], [SMY], [GEN]] With respect to KL-divergence, a G-test can be used (see https://en.wikipedia.org/wiki/G-test#Relation_to_Kullback.E2.80.93Leibler_divergence).[[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]] I suspect the results will still be meaningful, but the appropriate analysis is essential to be able to interpret the human results.[[RWK-NEU,RES-NEG,ANA-POS], [APR-NEU], [SMY], [GEN]] \n\nAlso, a related article: One article testing rational pedagogy in more ML contexts and using it to train ML models that is\nHo, M. K., Littman, M., MacGlashan, J., Cushman, F., & Austerweil, J. L. (NIPS 2016).[[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]] Showing versus Doing. Teaching by Demonstration.[[RWK-NEU], [null], [SMY], [GEN]]\n\nFor future work, it would be nice to show that the technique works for finding interpretable examples in more complex deep learning networks, which motivated the current push for explainable AI in the first place.[[EXP-NEU,MET-NEU,FWK-NEU], [null], [SMY,SUG], [GEN]]"
