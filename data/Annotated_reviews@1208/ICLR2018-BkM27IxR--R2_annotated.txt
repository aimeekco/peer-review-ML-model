"This paper proposed a reinforcement learning (RL) based method to learn an optimal optimization algorithm for training shallow neural networks.[[INT-NEU], [null], [SMY], [GEN]] This work is an extended version of [1], aiming to address the high-dimensional problem.[[RWK-NEU,MET-NEU], [EMP-NEU], [SMY], [MAJ]]\n\n\n\nStrengths:\n\nThe proposed method has achieved a better convergence rate in different tasks than all other hand-engineered algorithms.[[MET-POS], [EMP-POS], [APC], [MAJ]]\nThe proposed method has better robustess in different tasks and different batch size setting.[[MET-POS], [EMP-POS], [APC], [MAJ]]\nThe invariant of coordinate permutation and the use of block-diagonal structure improve the efficiency of LQG.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\n\nWeaknesses:\n\n1. Since the batch size is small in each experiment, it is hard to compare convergence rate within one epoch.[[EXP-NEU], [EMP-NEU], [DFT], [MAJ]] More iterations should be taken and the log-scale style figure is suggested.[[EXP-NEU,TNF-NEU], [SUB-NEU], [SUG], [MAJ]] \n\n2. In Figure 1b, L2LBGDBGD converges to a lower objective value, while the other figures are difficult to compare, the convergence value should be reported in all experiments.[[EXP-NEU,TNF-NEG], [CMP-NEG], [CRT], [MAJ]]\n\n3. \u201cThe average recent iterate\u201c described in section 3.6 uses recent 3 iterations to compute the average, the reason to choose \u201c3\u201d, and the effectiveness of different choices should be discussed, as well as the \u201c24\u201d used in state features.[[MET-NEU], [EMP-NEU], [SUG], [MAJ]]\n\n4. Since the block-diagonal structure imposed on A_t, B_t, and F_t, how to choose a proper block size?[[MET-NEU], [null], [QSN], [MIN]] Or how to figure out a coordinate group?[[MET-NEU], [null], [QSN], [MIN]]\n\n5. The caption in Figure 1,3, \u201cwith 48 input and hidden units\u201d should clarify clearly.[[TNF-NEG], [CLA-NEG], [CRT], [MIN]]\nThe curves of different methods are suggested to use different lines (e.g., dashed lines) to denote different algorithms rather than colors only.[[TNF-NEU], [PNF-NEU], [SUG], [MIN]]\n\n6. typo: sec 1 parg 5, \u201ccurrent iterate\u201d -> \u201ccurrent iteration\u201d.[[INT-NEG], [CLA-NEG], [CRT], [MIN]]\n\n\nConclusion:\n\nSince RL based framework has been proposed in [1] by Li & Malik, this paper tends to solve the high-dimensional problem.[[RWK-NEU,MET-NEU], [CMP-NEU], [SMY], [MAJ]] With the new observation of invariant in coordinates permutation in neural networks, this paper imposes the block-diagonal structure in the model to reduce the complexity of LQG algorithm.[[MET-NEU], [EMP-NEU], [SMY], [MAJ]] Sufficient experiment results show that the proposed method has better convergence rate than [1].[[RWK-NEU,MET-POS], [CMP-POS], [SMY], [MAJ]] But comparing to [1], this paper has limited contribution.[[RWK-NEU,OAL-NEG], [CMP-NEG], [CRT], [MAJ]]\n\n[1]: Ke Li and Jitendra Malik. Learning to optimize. CoRR, abs/1606.01885, 2016."[[BIB-NEU], [null], [SUG], [MIN]]