"This paper proposed an approach for detecting adversarial examples using saliency maps.[[PDI-NEU], [null], [SMY], [GEN]] The key idea is exploiting saliency maps as additional inputs to detector, which reveals importance of each pixel in classification.[[PDI-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nOverall, this reviewer leans towards rejecting this paper due to its limited contribution/novelty and the incomprehensive experiment results.[[EXP-NEG,RES-NEG,OAL-NEG], [NOV-NEG,EMP-NEG,REC-NEG], [CRT,FBK], [MAJ]] The proposed method simply concatenates a saliency map with the corresponding raw pixel image as an input to adversarial perturbation detector.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Despite of its simplicity, there are no discussions/empirical comparisons with other approaches, and simple ablative analysis such as performance of detector with and without saliency maps.   \n"[[MET-NEG,ANA-NEG], [CMP-NEG,EMP-NEG], [DFT,CRT], [MAJ]]