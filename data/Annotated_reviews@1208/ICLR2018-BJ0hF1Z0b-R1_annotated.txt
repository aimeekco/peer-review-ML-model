"Summary: The paper provides the first evidence of effectively training large RNN based language models under the constraint of differential privacy.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] The paper focuses on the user-level privacy setting, where the complete contribution of a single user is protected as opposed to protecting a single training example.[[PDI-NEU], [null], [SMY], [GEN]] The algorithm is based on the Federated Averaging and Federated Stochastic gradient framework.[[MET-NEU], [null], [SMY], [GEN]]\n\nPositive aspects of the paper: The paper is a very strong empirical paper, with experiments comparable to industrial scale.[[EXP-POS], [EMP-POS], [APC], [MAJ]] The paper uses the right composition tools like moments accountant to get strong privacy guarantees.[[MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The main technical ideas in the paper seem to be i) bounding the sensitivity for weighted average queries, and ii) clipping strategies for the gradient parameters, in order to control the norm.[[MET-NEU], [EMP-NEU], [DIS], [GEN]] Both these contributions are important in the effectiveness of the overall algorithm.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nConcern: The paper seems to be focused on demonstrating the effectiveness of previous approaches to the setting of language models.[[RWK-NEU], [CMP-NEU], [DIS], [MIN]] I did not find strong algorithmic ideas in the paper.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] I found the paper to be lacking in that respect.[[OAL-NEG], [SUB-NEG], [CRT], [MAJ]]  