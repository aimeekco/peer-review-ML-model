"The authors proposed a novel RNN model where both the input and the state update of the recurrent cells are skipped adaptively for some time steps.[[MET-POS], [EMP-POS], [APC], [MAJ]] The proposed models are learned by imposing a soft constraint on the computational budget to encourage skipping redundant input time steps.[[MET-NEU], [null], [SMY], [GEN]] The experiments in the paper demonstrated skip RNNs outperformed regular LSTMs and GRUs o thee addition, pixel MNIST and video action recognition tasks.[[RWK-POS,EXP-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]\n\n\n\nStrength:\n- The experimental results on the simple skip RNNs have shown a good improvement over the previous results.[[RWK-POS,EXP-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]\n\nWeakness:\n- Although the paper shows that skip RNN worked well, I found the appropriate baseline is lacking here.[[RWK-NEG,MET-NEG], [CMP-NEG,EMP-POS], [APC], [MAJ]] Comparable baselines, I believe, are regular LSTM/GRU whose inputs are randomly dropped out during training.[[RWK-NEG,EXP-NEG], [CMP-NEG,EMP-NEG], [CRT], [MAJ]]\n\n- Most of the experiments in the main paper are on toy tasks with small LSTMs.[[EXP-NEU,MET-NEU], [null], [DIS], [MIN]]  I thought the main selling point of the method is the computational gain.[[MET-NEU], [null], [DIS], [MIN]]  Would it make more sense to show that on large RNNs with thousands of hidden units?[[MET-NEU], [EMp-NEU], [QSN], [MIN]]  After going over the additional experiments in the appendix, and I find the three results shown in the main paper seem cherry-picked, and it will be good to include more NLP tasks."[[RES-NEU], [SUB-NEU], [SUG,DIS], [GEN]] 