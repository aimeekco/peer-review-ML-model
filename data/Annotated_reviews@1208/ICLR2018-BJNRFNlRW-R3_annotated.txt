"In this paper, the authors study the relationship between training GANs and primal-dual subgradient methods for convex optimization.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] Their technique can be applied on top of existing GANs and can address issues such as mode collapse.[[MET-NEU], [null], [SMY], [GEN]] The authors also derive a GAN variant similar to WGAN which is called the Approximate WGAN.[[MET-NEU], [null], [SMY], [GEN]] Experiments on synthetic datasets demonstrate that the proposed formulation can avoid mode collapse.[[EXP-NEU], [null], [SMY], [GEN]] This is a strong contribution[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]]\n\nIn Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore.[[TNF-NEG,MET-NEG], [SUB-NEG], [DFT,CRT], [MIN]] The authors should explain more possibly.[[MET-NEG], [SUB-NEG], [DFT], [MIN]]\nThere is a typo in Page 2 \u2013 For all these varaints, -variants.\n"[[CNT], [CLA-NEG], [CRT], [MIN]]