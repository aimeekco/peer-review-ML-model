"Paper Summary:\nThis work proposes a new geometric CNN model to process spatially sparse data.[[PDI-NEU], [null], [SMY], [GEN]] Like several existing geometric CNNs, convolutions are performed on each point using nearest neighbors.[[PDI-NEU], [null], [SMY], [GEN]] Instead of using a fixed or Gaussian parametric filters, this work proposes to predict filter weights using a multi-layer perception.[[PDI-NEU], [null], [SMY], [GEN]] Experiments on 3 different tasks showcase the potential of the proposed method.[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]]\n\nPaper Strengths:\n- An incremental yet interesting advance in geometric CNNs.[[MET-POS,OAL-POS], [EMP-POS], [APC], [MAJ]]\n- Experiments on three different tasks indicating the potential of the proposed technique.[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]]\n\nMajor Weaknesses:\n- Some important technical details about the proposed technique and networks is missing in the paper.[[MET-NEG,ANA-NEG], [SUB-NEG], [DFT], [MAJ]] It is not clear whether a different MLP is used for different channels and for different layers, to predict the filter weights.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  Also, it is not clear how the graph nodes and connectivity changes after the max-pooling operation.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]]  \n- Since filter weight prediction forms the central contribution of this work, I would expect some ablation studies on the MLP (network architecture, placement, weight sharing etc.) that predicts filter weights.[[ANA-NEU], [SUB-NEU], [SUG], [MIN]]   But, this is clearly missing in the paper.[[ANA-NEG], [SUB-NEG], [DFT], [MIN]]\n- If one needs to run an MLP for each edge in a graph, for each channel and for each layer, the computation complexity seems quite high for the proposed network.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]]Also, finding nearest neighbors takes time on large graphs.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] How does the proposed technique compare to existing methods in terms of runtime?[[MET-NEU], [CMP-NEU], [QSN], [MAJ]]\n\nMinor Weaknesses:\n- Since this paper is closely related to Monti et al., it would be good if authors used one or two same benchmarks as in Monti et al. for the comparisons.[[RWK-NEU], [CMP-NEU], [SUG], [MIN]] Why authors choose different set of benchmarks?[[RWK-NEU], [CMP-NEU], [QSN], [MIN]] Because of different benchmarks, it is not clear whether the performance improvements are due to technical improvements or sub-optimal parameters/training for the baseline methods.[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- I am not an expert in this area.[[EXT-NEU], [null], [DIS], [GEN]] But, the chosen benchmarks and datasets seem to be not very standard for evaluating geometric CNNs.[[RWK-POS], [CMP-POS], [APC], [MAJ]]\n- The technical novelty seems incremental (but interesting) with respect to existing methods.[[MET-POS], [NOV-POS,CMP-POS], [APC], [MAJ]]\n\nClarifications:\n- See the above mentioned clarification issues in 'major weaknesses'. [[EXT-NEU], [null], [DIS], [GEN]]Those clarification issues are important to address.[[EXT-NEU], [null], [DIS], [GEN]]\n- 'Non-parametric filter' may not be right word as this work also uses a parametric neural network to estimate filter weights?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nSuggestions:\n- It would be great if authors can add more details of the multi-layer perceptron, used for predicting weights, in the paper.[[ANA-NEU], [SUB-NEU], [SUG], [MIN]] It seems some of the details are in Appendix-A.[[CNT], [PNF-NEU], [DIS], [MIN]] It would be better if authors move the important details of the technique and also some important experimental details to the main paper.[[EXP-NEU,OAL-NEU], [PNF-NEU], [SUG], [MIN]]\n\nReview Summary:\nThe proposed technique is interesting and the experiments indicate its superior performance over existing techniques. [[EXP-POS,MET-POS,RES-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]Some incomplete technical details and non-standard benchmarks makes this not completely ready for publication."[[OAL-NEG], [SUB-NEG,REC-NEG], [DFT,FBK], [MAJ]]