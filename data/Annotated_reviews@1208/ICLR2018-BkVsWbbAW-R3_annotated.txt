"This paper introduces a neural network architecture for continual learning.[[INT-NEU], [null], [SMY], [GEN]] The model is inspired by current knowledge about long term memory consolidation mechanisms in humans.[[MET-NEU], [null], [SMY], [GEN]] As a consequence, it uses:\n-\tOne temporary memory storage (inspired by hippocampus) and a long term memory\n-\tA notion of memory replay, implemented by generative models (VAE), in order to simultaneously train the network on different tasks and avoid catastrophic forgetting of previously learnt tasks.[[MET-NEU], [null], [SMY], [GEN]]\nOverall, although the result are not very surprising, the approach is well justified and extensively tested.[[MET-POS,RES-NEU], [EMP-POS], [APC], [MAJ]] It provides some insights on the challenges and benefits of replay based memory consolidation.[[MET-NEU], [null], [SMY], [MAJ]]\n\nComments:\n\t\n1-\tThe results are somewhat unsurprising: as we are able to learn generative models of each tasks, we can use them to train on all tasks at the same time, a beat algorithms that do not use this replay approach.[[MET-NEU,RES-NEU], [EMP-NEU], [CRT], [MAJ]] \n2-\tIt is unclear whether the approach provides a benefit for a particular application: as the task information has to be available, training separate task-specific architectures or using classical multitask learning approaches would not suffer from catastrophic forgetting and perform better (I assume).[[MET-NEU], [EMP-NEU], [DIS], [MAJ]] \n3-\tSo the main benefit of the approach seems to point towards the direction of what possibly happens in real brains.[[MET-NEU], [EMP-NEU], [DIS], [MAJ]] It is interesting to see how authors address practical issues of training based on replay and it show two differences with real brains: 1/ what we know about episodic memory consolidation (the system modeled in this paper) is closer to unsupervised learning, as a consequence information such as task ID and dictionary for balancing samples would not be available, 2/ the cortex (long term memory) already learns during wakefulness, while in the proposed algorithm this procedure is restricted to replay-based learning during sleep.[[MET-POS,ANA-POS], [EMP-POS], [APC], [MAJ]]\n4-\tDue to these differences, I my view, this work avoids addressing directly the most critical and difficult issues of catastrophic forgetting, which relates more to finding optimal plasticity rules for the network in an unsupervised setting.[[MET-NEG], [EMP-NEU], [CRT], [MAJ]]\n5-\tThe writing could have been more concise and the authors could make an effort to stay closer to the recommended number of pages.[[OAL-NEU], [CLA-NEU,PNF-NEU], [SUG], [MIN]]\n"