"The authors show how techniques typically applied to real-valued networks (e.g. with real-valued inputs and parameters) can be straighforwardly generalized to complex-valued networks (e.g. with complex-valued inputs and parameters).[[RWK-NEU], [null], [SMY], [GEN]]  The authors then provide several evaluations of complex-valued networks on some standard ML benchmark tasks.[[RWK-POS,PDI-POS,MET-POS], [IMP-POS,EMP-POS], [APC], [GEN]] They find that the complex-valued networks do not in general perform better than real-valued networks.[[RWK-NEU,PDI-NEU,MET-NEG,ANA-NEG], [EMP-NEG], [DFT], [MIN]] \n\n====================\nClarity:  I found the paper clear and easy to understand. [[OAL-POS], [CLA-POS], [APC], [MAJ]] In a number of places there are clear signs of sloppiness (e.g. undefined citations). [[RWK-POS], [EMP-POS], [APC], [MAJ]] I found the undefined citations in the middle of page 2 frustrating, since I'd have liked to follow up on those citations as comparison points for this work[[EXT-NEG], [null], [FBK], [GEN]]. \n\nQuality: The mathematical formulas describing basic complex analysis ideas (e.g.  derivatives of complex functions, definitions of complex versions of standard activation functions) seem reasonable to me[[RWK-NEU,ANA-NEU], [IMP-NEU], [SMY,DIS], [GEN]].   The general approach of assigning a parameter budget to ensure fairness in comparison between complex and real-valued networks seems reasonable --[[PDI-POS,EXP-POS,MET-POS], [IMP-POS,EMP-POS], [APC], [MAJ]]- although of course, since all results should be reported on cross-validated testing subsets anyhow,[[RWK-NEU,RES-NEU,ANA-NEU], [IMP-NEU], [SMY,DIS], [GEN]]  parameter equalization is not the only approach to fair evaluation[[PDI-NEG,ANA-NEG], [IMP-NEG], [DFT], [MIN]].   \n\nOriginality:  It seems very unclear to me what is added in this paper in comparison to works like (e.g.) Trabelsi (2017).[[RWK-NEG,BIB-NEG], [CLA-NEG], [DFT], [MIN]]  That and other recent work have provided some systematic evaluations of complex-valued networks, and shown their utility in a number of cases. [[EXT-POS], [null], [SUG], [GEN]]  The current paper's authors talk about previous work not being well-controlled for number of parameters.[[RWK-NEG], [EMP-NEG], [DFT], [MIN]]   However, at least in some key cases in the recent literature, parameter numbers *were* controlled (see e.g. Table 4 of Trabelsi (2017)).[[RWK-NEU,BIB-NEU], [null], [DIS], [GEN]]  So I'm not really sure what is being added here.[[RWK-NEG,EXT-NEG], [null], [FBK], [GEN]] \n\nSignificance:   The paper does not make a great case for caring about complex-valued networks.[[INT-NEG,RWK-NEG,MET-NEG], [EMP-NEG], [DFT], [MIN]]  Of course, negative results are of value, but it doesn't seem like much is at stake in this work to begin with.[[RWK-NEG,PDI-NEG], [IMP-NEG], [DFT], [MIN]]   It's not like people expected complex-valued networks to somehow be extremely effective for the tasks discussed here -[[RWK-NEG,PDI-NEG], [IMP-NEG], [DFT], [MIN]]- so the failure to be better than the real-valued alternatives seems unremarkable.[[RWK-NEU,ANA-NEG], [CMP-NEG,EMP-NEG], [DFT], [MIN]]   The paper also doesn't illustrate any novel results on tasks for which it would be reasonable to assume that complex-valued inputs would be particularly important.  [[INT-NEG,PDI-NEG,RES-NEG], [NOV-NEG], [DFT], [MIN]](The authors reference some signal processing tasks in the introduction[[INT-NEU], [null], [DIS], [GEN]], but don't actually show any results on such tasks.)    \n\n[[RWK-NEG,RES-NEG], [IMP-NEG], [DFT], [MIN]]"