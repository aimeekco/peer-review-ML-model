"The paper is generally well-written and the intuition is very clear. [[OAL-POS], [CLA-POS], [APC], [MAJ]]It combines the advanced attention mechanism, pointer networks and REINFORCE learning signal to train a sequence-to-sequence model for text summarization.[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] The experimental results show that the model is able to achieve the state-of-the-art performance on CNN/Daily Main and New York Times datasets.[[RWK-NEU,DAT-NEU,MET-NEU], [NOV-NEU,EMP-NEU], [SMY], [GEN]] It is a good incremental research,[[PDI-POS,OAL-POS], [IMP-POS], [APC], [MAJ]] but the downside of this paper is lack of innovations since most of the methods proposed in this paper are not new to us.[[MET-NEG,OAL-NEG], [SUB-NEG], [DFT], [MIN]]\n\nI would like to see the model ablation w.r.t. repetition avoidance trick by muting the second trigram at test time.[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] Intuitively, if the repetition issue is prominent to having decent summarization performance, it might affect our judgement on the significance of using intra-attention or combined RL signal.[[RWK-NEU,EXP-NEU,MET-NEU,OAL-NEU], [null], [SMY], [GEN]]\nAnother thought on this: is it possible to integrate the trigram occurrence with summarization reward?[[RWK-NEU], [null], [SMY,QSN], [GEN]] so that the recurrent neural networks with attention could capture the learning signal to avoid the repetition issue and the heuristic function in the test time can be removed.[[RWK-NEU,EXP-NEG,MET-NEG], [EMP-NEG], [DFT,CRT], [MIN]] \n\nIn addition, as the encoder-decoder structure gradually becomes the standard choice of sequence prediction, I would suggest the authors to add the sum of parameters into model ablation for reference.[[RWK-NEU], [null], [SMY], [GEN]]\n\nSuggested References:\nBahdanau et al. (2016) An Actor-critic Algorithm for Sequence Prediction.[[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]] (actor-critic on machine translation)\nMiao & Blunsom (2016) Language as a Latent Variable: Discrete Generative Models for Sentence Compression.[[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]] (mixture pointer mechanism + REINFORCE)[[RWK-NEU], [null], [SMY], [GEN]]\n"