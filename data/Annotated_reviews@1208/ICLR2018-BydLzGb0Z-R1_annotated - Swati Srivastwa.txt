"\n1) Summary\nThis paper proposes a recurrent neural network (RNN) training formulation for encouraging RNN the hidden representations to contain information useful for predicting future timesteps reliably.[[INT-NEU], [null], [SMY], [GEN]] The authors propose to train a forward and backward RNN in parallel.[[PDI-NEU], [null], [SMY], [GEN]]  The forward RNN predicts forward in time and the backward RNN predicts backwards in time.[[PDI-NEU], [null], [SMY], [GEN]]  While the forward RNN is trained to predict the next timestep, its hidden representation is forced to be similar to the representation of the backward RNN in the same optimization step.[[PDI-NEU], [null], [SMY], [GEN]]  In experiments, it is shown that the proposed method improves training speed in terms of number of training iterations, achieves 0.8 CIDEr points improvement over baselines using the proposed training, and also achieves improved performance for the task of speech recognition.[[RWK-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]] \n\n\n2) Pros:\n+ Novel idea that makes sense for learning a more robust representation for predicting the future and prevent only local temporal correlations learned.[[PDI-POS], [NOV-POS], [APC], [MAJ]] \n+ Informative analysis for clearly identifying the strengths of the proposed method and where it is failing to perform as expected.[[MET-POS,ANA-POS], [EMP-POS], [APC], [MAJ]]\n+ Improved performance in speech recognition task.[[RES-POS], [EMP-POS], [APC], [MAJ]]\n+ The idea is clearly explained and well motivated.[[PDI-POS], [EMP-POS], [APC], [MAJ]]\n\n\n3) Cons:\nImage captioning experiment:\nIn the experimental section, there is an image captioning result in which the proposed method is used on top of two baselines.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] This experiment shows improvement over such baselines,[[RWK-POS,EXP-POS], [CMP-POS], [APC], [MAJ]] however, the performance is still worse compared against baselines such as Lu et al, 2017 and Yao et al, 2016.[[RWK-NEG,RES-NEG], [NOV-POS], [APC], [MAJ]] It would be optimal if the authors can use their training method on such baselines and show improved performance, or explain why this cannot be done.[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]]\n\n\nUnconditioned generation experiments:\nIn these experiments, sequential pixel-by-pixel MNIST generation is performed in which the proposed method did not help.[[EXP-NEU,MET-NEG], [EMP-NEG], [CRT], [MAJ]] Because of this, two conditioned set ups are performed: 1) 25% of pixels are given before generation, and 2) 75% of pixels are given before generation.[[EXP-NEU,MET-NEU], [null], [DIS], [MIN]] The proposed method performs similar to the baseline in the 25% case, and better than the baseline in the 75% case.[[RWK-NEU,MET-NEU], [EMP-NEU], [DIS], [GEN]] For completeness, and to come to a stronger conclusion on how much uncertainty really affects the proposed method, this experiment needs a case in which 50% of the pixels are given. [[EXP-NEU], [EMP-NEU], [DIS], [MIN]]Observing 25% of the pixels gives almost no information about the identity of the digit and it makes sense that it\u2019s hard to encode the future, however, 50% of the pixels give a good idea of what the digit identity is.[[RES-POS], [EMP-POS], [APC], [MAJ]] If the authors believe that the 50% case is not necessary, please feel free to explain why.[[RES-NEU], [EMP-NEU], [DIS], [MIN]]\n\n\nAdditional comments:\nThe method is shown to converge faster compared to the baselines, however, it is possible that the baseline may finish training faster (the authors do acknowledge the additional computation needed in the backward RNN).[[RWK-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]]\nIt would be informative for the research community to see the relationship of training time (how long it takes in hours) versus how fast it learns (iterations taken to learn).[[ANA-NEU], [EMP-NEU], [DIS], [MIN]]\n\nExperiments on RL planning tasks would be interesting to see (Maybe on a simple/predictable environment).[[EXP-NEU], [EMP-NEU], [DIS], [MIN]]\n\n\n4) Conclusion\nThe paper proposes a method for training RNN architectures to better model the future in its internal state supervised by another RNN modeling the future in reverse.[[MET-NEU], [null], [DIS], [MIN]] Correctly modeling the future is very important for tasks that require making decisions of what to do in the future based on what we predict from the past.[[MET-NEU], [null], [DIS], [MIN]] The proposed method presents a possible way of better modeling the future,[[MET-POS], [EMP-POS], [APC], [MAJ]] however, some the results do not clearly back up the claim yet.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]] The given score will improve if the authors are able to address the stated issues.[[OAL-NEU], [REC-NEU], [FBK], [MAJ]]\n\n\nPOST REBUTTAL RESPONSE:\nThe authors have addressed the comments on the MNIST experiments and show better results,[[EXP-POS,RES-POS], [EMP-POS], [APC], [MAJ]] however, as far as I can see, they did not address my concern about the comparisons on the image captioning experiment.[[EXP-NEG], [CMP-NEG], [CRT], [MAJ]] In the image captioning experiment the authors choose two networks (Show & Tell and Soft attention) that they improve using the proposed method that end up performing similar to the second best baseline (Yao et al. 2016) based on Table 3 and their response.[[MET-POS,TNF-NEU], [EMP-POS], [APC], [MAJ]] I requested for the authors to use their method on the best performing baselines (i.e. Yao et al. 2016 or Liu et al. 2017) or explain why this cannot be done (maybe my request was not clearly stated).[[RWK-NEU,MET-NEU], [CMP-NEU], [DIS], [MIN]] Applying the proposed method on the strong baselines would highlight the author's claims more strongly than just applying on the average performing chosen baselines.[[RWK-NEU,MET-NEU], [CMP-NEU,EMP-NEU], [SUG], [MIN]] This request was not addressed and instead the authors just improved the average performing baselines in Table 3 to meet the best baselines.[[RWK-NEU,TNF-NEU], [CNT], [DIS], [MIN]] Given, that the authors were able to improve the results in the sequential MNIST and improve the average baselines, my rating improves one point.[[RWK-POS,RES-POS], [EMP-POS,REC-POS], [FBK], [MAJ]] However, I still have concerns about this method not being shown to improve the best methods presented in Table 3 which would give a more solid result.[[MET-NEG,TNF-NEG], [EMP-NEG], [CRT], [MAJ]] My rating changes to marginally above threshold for acceptance."[[OAL-POS], [REC-POS], [FBK], [MAJ]]