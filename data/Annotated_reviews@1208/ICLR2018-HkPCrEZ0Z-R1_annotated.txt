"The paper studies a combination of model-based and model-free RL.[[INT-NEU,MET-NEU], [null], [SMY], [GEN]] The idea is to train a forward predictive model which provides multi-step estimates to facilitate model-free policy learning.[[PDI-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]]  Some parts of the paper lack clarity and the empirical results need improvement to support the claims (see details below). [[RES-NEG,OAL-NEG], [CLA-NEG,EMP-NEG], [CRT], [MIN]]  \n\nClarity \n- The main idea of the proposed method is clear.[[PDI-POS], [CLA-POS], [APC], [MAJ]] \n- Some notations and equations are broken.[[TNF-NEG], [PNF-NEG], [CRT], [MIN]] For example: \n(1) The definition of \\bar{A} in Section 4 is broken.[[RWK-NEU], [null], [SMY], [GEN]] \n(2) The overall objective in Section 5 is broken.[[RWK-NEU], [null], [SMY], [GEN]] \n(3) The computation of w in Algorithm 2 is problematic.[[RWK-NEG,MET-NEG], [IMP-NEG], [CRT], [MIN]] \n- Some details of the experiments/methods are confusing.[[EXP-NEG,MET-NEG], [IMP-NEG], [CRT], [MIN]] For example: \n(1) The step number k is dynamically determined by a short line search as in Section 4 ``Dynamic Rollout\u2019\u2019, but later in the experiments (Section 6) the value of k is set to be 2 uniformly.[[RWK-NEU,PDI-NEU,MET-NEU,BIB-NEU], [null], [SMY], [GEN]] \n(2) Only the policy and value networks specified.[[RWK-NEG], [EMP-NEG], [DFT], [MIN]] The forward models are not specified.[[MET-NEG], [IMP-NEG,EMP-NEG], [DFT], [MIN]]  \n(3) In algorithm 1, what exact method is used in determining if \\mu is converged or not?[[RWK-NEU,MET-NEU], [null], [QSN], [GEN]] \n\nOriginality\nThe proposed method can be viewed as a multi-step version of the stochastic value gradient algorithm.[[PDI-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] An empirical comparison could be helpful but not provided.[[PDI-NEG], [CMP-NEG,EMP-NEG], [DFT], [MIN]] \n\nThe idea of the proposed method is related to the classic Dyna methods from Sutton.[[RWK-NEU,PDI-NEU,EXP-NEU], [EMP-NEU], [SMY], [GEN]] A discussion on the difference would be helpful.[[EXT-NEU], [CNT], [CNT], [CNT]] \n\nSignificance\n- The paper could compare against other relevant baselines that combine model-based and model-free RL methods, such as SVG (stochastic value gradient).[[RWK-NEU,EXP-NEU,MET-NEU], [CMP-NEU], [SMY], [GEN]] \n- To make a fair comparison, the results in Table 1 should consider the amount of data used in pre-training the forward models.[[DAT-NEU,EXP-NEU,RES-NEU,TNF-NEU], [CMP-NEU,EMP-NEU], [SMY], [GEN]] Current results in Table 1 only compare the amount of data in policy learning.[[DAT-NEU,RES-NEU,TNF-NEU], [null], [SMY], [GEN]]  \n- Figure 3 is plotted for just one random starting state.[[TNF-NEU], [null], [SMY], [GEN]] The Figure could have been more informative if it was averaged over different starting states.[[TNF-NEG], [SUB-NEG], [DFT], [MIN]]  The same issue is found in Figure 2.[[TNF-NEU], [null], [SMY], [GEN]]  It would be helpful if the plots of other domains are provided.[[RWK-NEG], [SUB-NEG,EMP-NEG], [DFT], [MIN]] \n- In Figure 2, even though the diff norm fluctuates, the cosine similarity remains almost constant.[[PDI-NEU,MET-NEU,TNF-NEU], [null], [SMY], [GEN]] Does it suggest the cosine similarity is not effective in measuring the state similarity?[[PDI-NEU,MET-NEU], [null], [QSN], [GEN]] \n- Figure 1, 4 and 5 need confidence intervals or standard errors.[[FWK-NEG], [SUB-NEG], [DFT], [MIN]] \n\nPros:\n- The research direction in combining model-based and model-free RL is interesting.[[PDI-POS,MET-POS], [IMP-POS], [SMY], [MAJ]]\n- The main idea of the proposed method is clear.[[PDI-POS], [CLA-POS], [APC], [MAJ]] \n\nCons:\n- Parts of the paper are unclear and some details are missing.[[RES-NEG], [CLA-NEG,SUB-NEG], [DFT], [MIN]] \n- The paper needs more discussion and comparison to relevant baseline methods.[[EXP-NEG,OAL-NEG], [SUB-NEG,CMP-NEG], [DFT], [MIN]]  \n- The empirical results need improvement to support the paper\u2019s claims.[[RES-NEG], [SUB-NEG,EMP-NEG], [DFT], [MIN]] \n"