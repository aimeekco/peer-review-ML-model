"This paper proposed to use affect lexica to improve word embeddings.[[INT-NEU], [null], [SMY], [GEN]] They extended the training objective functions of Word2vec and Glove with the affect information.[[MET-NEU], [null], [SMY], [GEN]] The resulting embeddings were evaluated not only on word similarity tasks but also on a bunch of downstream applications such as sentiment analysis. [[MET-NEU], [null], [SMY], [GEN]]Their experimental results showed that their proposed embeddings outperformed standard Word2vec and Glove.[[RWK-NEU,EXP-NEU,RES-NEU], [CMP-POS], [SMY], [GEN]] In sum, it is an interesting paper with promising results and the proposed methods were carefully evaluated in many setups.[[MET-POS,RES-POS,OAL-POS], [EMP-POS], [APC], [MAJ]]\n\nSome detailed comments are:\n-\tAlthough the use of affect lexica is innovative, the idea of extending the training objective function with lexica information is not new.[[PDI-POS], [NOV-NEG], [DFT,DIS], [MAJ]] Almost the same method was proposed in K.A. Nguyen, S. Schulte im Walde, N.T. Vu. Integrating Distributional Lexical Contrast into Word Embeddings for Antonym-Synonym Distinction. In Proceedings of ACL, 2016.[[RWK-NEU,PDI-NEU,BIB-NEU], [NOV-NEG], [CRT], [MAJ]]\n-\tAlthough the lexicons for valence, arousal, and dominance provide different information, their combination did not perform best.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] Do the authors have any intuition why?[[MET-NEU], [null], [QSN], [MAJ]]\n-\tIn Figure 2, the authors picked four words to show that valence is helpful to improve Glove word beddings. It is not convincing enough for me.[[EXP-NEG,TNF-NEG], [EMP-NEG], [DFT], [MIN]]  I would like to see to the top k nearest neighbors of each of those words.\n"[[EXP-NEU], [EMP-NEU], [SUG], [MIN]]