"This paper proposes to perform link prediction in Knowledge Bases by supplementing the original entities with multimodal information such as text description or images.[[INT-NEU], [null], [SMY], [GEN]] A model, based on DistMult, able to encode all sort of information when scoring triples is presented with experiments on 2 new datasets based on Yago and MovieLens.[[DAT-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nThis paper reads well and the results appear sound.[[RES-POS,OAL-POS], [CLA-POS], [APC], [MAJ]] Unfortunately, the contribution seems rather small to be accepted for ICLR.[[OAL-NEU], [APR-NEG], [CRT], [MAJ]] This is a straight application and combination of existing pieces with not much originality and without being backed up by very strong experimental results.[[EXP-NEU,RES-NEU], [NOV-NEU,EMP-NEU], [CRT], [MAJ]]\n\n* Having only results on new datasets makes it hard to compare the objective quality of the DistMult baselines and hence of the improvements due to the multimodal info.[[RWK-NEU,DAT-NEU,RES-NEU], [CMP-NEU], [CRT], [MAJ]] Isn't there any existing benchmark where this could have an impact?[[RWK-NEU], [IMP-NEU], [QSN], [MIN]]\n* The much better performance of ConvE is worrying there.[[RWK-NEU,EXP-NEU], [CMP-NEU,EMP-NEU], [CRT], [MAJ]] It is suggested that the proposed approach could be incorporated in ConvE to lead to similar improvements than on DistMult. The paper would be much stronger with those.[[MET-NEU], [EMP-NEU], [SUG], [MAJ]] \n* Are we sure that the textual description do not explicitly contain the information of the triple to be predicted?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] This would explain the massive gains in Yago.[[RES-NEU,ANA-NEU], [EMP-NEU], [SUG], [MAJ]]\n* For Table 8, the similarities are not striking.[[TNF-NEU], [EMP-NEG], [CRT], [MIN]] What were the nearest neighboring posters in the original VGG space? They should not be that bad too.[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n* The work on multimodal embeddings like \"Multimodal Distributional Semantics\" by Bruni et al. or \"Multi-and Cross-Modal Semantics Beyond Vision: Grounding in Auditory Perception.\" by Kiela et al. could be discussed/cited.[[BIB-NEU], [CMP-NEU], [SUG], [MIN]]\n\n"