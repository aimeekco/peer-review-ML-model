"The paper proposes training ``inference networks,'' which are neural network structured predictors. [[INT-NEU,PDI-NEU], [null], [SMY], [GEN]]The setup is analogous to generative adversarial networks, where the role of the discriminator is played by a structured prediction energy network (SPEN) and the generator is played by an inference network. [[PDI-NEU], [null], [SMY], [GEN]]\n\nThe idea is interesting. It could be viewed as a type of adversarial training for large-margin structured predictors, where counterexamples, i.e., structures with high loss and low energy, cannot be found by direct optimization. [[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] However, it remains unclear why SPENs are the right choice for an energy function. [[MET-NEU], [null], [SMY], [GEN]]\n\nExperiments suggest that it can result in better structured predictors than training models directly via backpropagation gradient descent. [[EXP-NEU,RES-NEU], [EMP-NEU], [DIS], [GEN]] However, the experimental results are not clearly presented. [[EXP-NEG], [EMP-NEG], [CRT], [MAJ]] The clarity is poor enough that the paper might not be ready for publication. [[OAL-NEG], [CLA-NEG], [CRT], [MAJ]]\n\nComments and questions:\n\n1) It is unclear whether this paper is motivated by training SPENs or by training structured predictors. [[MET-NEG], [EMP-NEG], [CRT], [MAJ]] The setup focuses on using SPENs as an inference network, but this seems inessential.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  Experiments with simpler energy functions seem to be absent, though the experiments are unclear (see below).[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]] \n\n2) The confusion over the motivation is confounded by the fact that the experiments are very unclear.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  Sometimes predictions are described as the output of SPENs (Tables 2, 3, 4, and 7), sometimes as inference networks (Table 5), and sometimes as a CRF (Tables 4 and 6). [[MET-NEG], [EMP-NEG], [CRT], [MAJ]] In 7.2.2 it says that a BiLSTM is used for the inference network in Twitter POS tagging, but Tables 4 and 6 indicate both CRFs and BiLSTMS?[[TNF-NEG], [EMP-NEG], [QSN], [MAJ]]  It is also unclear when a model, e.g., BiLSTM or CRF is the energy function (discriminator) or inference network (generator).[[MET-NEU], [EMP-NEU], [CRT], [MAJ]] \n\n3) The third and fourth columns of Table 5 are identical.[[TNF-NEG], [EMP-NEG], [CRT], [MAJ]]  The presentation should be made consistent, either with dev/test or -retuning/+retuning as the top level headers.\[[OAL-NEG], [PNF-NEG], [CRT], [MAJ]] n\n4) It is also unclear how to compare Tables 4 and 5.[[TNF-NEG], [CLA-NEG], [CRT], [MIN]]  The second to bottom row of Table 5 seems to correspond with the first row of Table 5, but other methods like slack rescaling have higher performance.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]]  What is the takeaway from these two tables supposed to be?\n\n5) Part of the motivation for the work is said to be the increasing interest in inference networks: [[OAL-POS], [EMP-POS], [APC], [MAJ]] \"In these and related settings, gradient descent has started to be replaced by inference networks.[[MET-NEG], [EMP-NEG], [DIS], [MAJ]]  Our results below provide more evidence for making this transition.\" However, no other work on inference networks is directly cited."[[RWK-NEG,BIB-NEG], [SUB-NEG], [DFT,CRT], [MAJ]] 