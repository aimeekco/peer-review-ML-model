"This paper presents a pixel-matching based approach to synthesizing RGB images from input edge or normal maps.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] The approach is compared to Isola et al\u2019s conditional adversarial networks, and unlike the conditional GAN, is able to produce a diverse set of outputs.[[RWK-NEU, MET-NEU], [CMP-NEU], [SMY], [GEN]]\n\nOverall, the paper describes a computer visions system based on synthesizing images, and not necessarily a new theoretical framework to compete with GANs.[[PDI-NEU, MET-NEU], [null], [SMY], [GEN]] With the current focus of the paper being the proposed system, it is interesting to the computer vision community.[[OAL-POS], [IMP-POS], [APC], [MAJ]] However, if one views the paper in a different light, namely showing some \u201cblind-spots\u201d of current conditional GAN approaches like lack of diversity, then it can be of much more interest to the broader ICLR community.[[MET-POS,OAL-POS], [IMP-POS], [APC], [MAJ]]\n\nPros: \nOverall the paper is well-written[[OAL-POS], [CLA-POS], [APC], [MAJ]]\nMakes a strong case that random noise injection inside conditional GANs does not produce enough diversity[[MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]]\nShows a number of qualitative and quantitative results[[RES-POS], [EMP-POS], [APC], [MAJ]]\n\nConcerns about the paper:\n1.) It is not clear how well the proposed approach works with CNN architectures other than PixelNet[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n2.) Since the paper used \u201cthe pre-trained PixelNet to extract surface normal and edge maps\u201d for ground-truth generation, it is not clear whether the approach will work as well when the input is a ground-truth semantic segmentation map.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n3.) Since the paper describes a computer-vision image synthesis system and not a new theoretical result, I believe reporting the actual run-time of the system will make the paper stronger.[[EXP-NEU], [EMP-NEU], [SUG], [MAJ]]\ Can PixelNN run in real-time?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] How does the timing compare to Isola et al\u2019s Conditional GAN?[[RWK-NEU,EXP-NEU], [CMP-NEU], [QSN], [MIN]]\n\nMinor comments:\n1.) The paper mentions making predictions from \u201cincomplete\u201d input several times, but in all experiments, the input is an edge map, normal map, or low-resolution image.[[EXP-NEG], [EMP-NEG], [CRT], [MIN]] When reading the manuscript the first time, I was expecting experiments on images that have regions that are visible and regions that are masked out.[[EXP-NEU], [EMP-NEU], [DIS], [MIN]] However, I am not sure if the confusion is solely mine, or shared with other readers.[[EXT-NEU], [CNT], [DIS], [MIN]]\n\n2.) Equation 1 contains the norm operator twice, and the first norm has no subscript, while the second one has an l_2 subscript.[[MET-NEG], [SUB-NEG], [DFT,CRT], [MIN]] I would expect the notation style to be consistent within a single equation (i.e., use ||w||_2^2, ||w||^2, or ||w||_{l_2}^2)\n\n3.)[[MET-NEU], [PNF-NEG], [DIS], [MIN]] Table 1 has two sub-tables: left and right. The sub-tables have the AP column in different places.[[TNF-NEU], [null], [SMY,DIS], [MIN]]\n\n4.) \u201cDense pixel-level correspondences\u201d are discussed but not evaluated.\n"[[MET-NEU,ANA-NEG], [SUB-NEU], [DFT], [MIN]]