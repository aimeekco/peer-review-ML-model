"The paper describes a neural end-to-end architecture to solve multiple tasks at once.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]]  The architecture consists of an encoder, a mixer, a decoder, and many modality networks to cover different types of input and output pairs for different tasks.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]]  The engineering endeavor is impressive,[[MET-POS,EXP-POS], [null], [SMY], [GEN]] but the paper has little scientific value.[[CNT], [CNT], [CRT], [MAJ]]  Below are a few suggestions to make the paper stronger.[[OAL-NEU], [CNT], [SUG], [MIN]]\n\nIt is possible that the encoder, mixer, and decoder are just multiplexing tasks based on the input.[[EXP-NEU], [EMP-NEU], [DIS], [GEN]]  One way to analyze whether this happens is to predict the identity of the task from the hidden vectors.[[EXP-NEU], [EMP-NEU], [SUG], [MIN]]  If this is the case, how to prevent it from happening?[[EXP-NEU], [EMP-NEU], [QSN], [MIN]]  If this does not happen, what is being shared across tasks?[[EXP-NEU], [EMP-NEU], [QSN], [MIN]]  This can be analyzed by embedding the inputs from different tasks and looking for inputs from other tasks within a neighborhood in the embedding space.[[ANA-NEU], [EMP-NEU], [SUG], [MIN]]\n\nWhy multitask learning help the model perform better is still unclear.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  If the model is able to leverage knowledge learned from one task to perform another task, then we expect to see either faster convergence or good performance with fewer samples.[[DAT-NEU,MET-NEU,RES-NEU], [EMP-NEU], [DIS], [MIN]]  The authors should analyze if this is the case, and if not, what are we actually benefiting from multitask learning?[[MET-NEU], [EMP-NEU], [QSN], [MAJ]]\n\nIf the modality network is shared across multiple tasks, we expect the learned hidden representation produced by the modality network is more universal.[[MET-NEU,RES-NEU], [EMP-NEU], [DIS], [MIN]]  If that is the case, what information of the input is being retained when training with multiple tasks and what information of the input is being discarded when training with a single task?[[MET-NEU,EXP-NEU], [EMP-NEU], [QSN], [MIN]]\n\nReporting per-token accuracies, such as those in Table 2, is problematic.[[TNF-NEG], [EMP-NEG], [CRT], [MAJ]]  It's unclear how to compute per-token accuracies for structured prediction tasks, such as speech recognition, parsing, and translation.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]]  Furthermore, based on the results in Table 2, the model clearly fails on the speech recognition task.[[RES-NEG,TNF-NEG], [EMP-NEG], [CRT], [MAJ]]  The author should also report the standard speech recognition metric, word error rates (WER), for the speech recognition task in Table 1.\n"[[RES-NEU,TNF-NEU], [SUB-NEU], [SUG], [MAJ]]