"The paper presents a means of evaluating a neural network securely using homomorphic encryption[[INT-NEU], [null], [SMY], [GEN]]. A neural network is already trained, and its weights are public.[[RWK-NEU], [null], [SMY], [GEN]] The network is to be evaluated over a private input, so that only the final outcome of the computation-and nothing but that-is finally learned.[[MET-NEU], [null], [SMY], [GEN]]\n\nThe authors take a binary-circuit approach: they represent numbers via a fixed point binary representation, and construct circuits of secure adders and multipliers, based on homomorphic encryption as a building block for secure gates.[[MET-NEU], [null], [SMY], [GEN]] This allows them to perform the vector products needed per layer; two's complement representation also allows for an \"easy\" implementation of the ReLU activation function, by \"checking\" (multiplying by) the complement of the sign bit.[[MET-NEU], [null], [SMY], [GEN]] The fact that multiplication often involves public weights is used to speed up computations, wherever appropriate.[[MET-NEU], [null], [SMY], [GEN]] A rudimentary  experimental evaluation with small networks is provided.[[EXP-NEU], [null], [SMY], [GEN]]\n\nAll of this is somewhat straightforward; a penalty is paid by representing numbers via fixed point arithmetic, which is used to deal with ReLU mostly.[[RWK-NEU,MET-NEU], [EMP-NEU], [SMY], [MAJ]] This is somewhat odd: it is not clear why, e.g., garbled circuits where not used for something like this, as it would have been considerably faster than FHE.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nThere is also a work in this area that the authors do not cite or contrast to, bringing the novelty into question; please see the following papers and references therein:;[[RWK-NEG,BIB-NEU], [CMP-NEG], [CRT], [MAJ]]\n\nGILAD-BACHRACH, R., DOWLIN, N., LAINE, K., LAUTER, K., NAEHRIG, M., AND WERNSING, J. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In Proceedings of The 33rd International Conference on Machine Learning (2016), pp. 201\u2013210.[[RWK-NEU,BIB-NEU], [null], [SUG], [MAJ]]\n\nSecureML: A System for Scalable Privacy-Preserving Machine Learning\nPayman Mohassel and Yupeng Zhang.[[RWK-NEU,BIB-NEU], [null], [SUG], [MAJ]]\n\nSHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep learning.[[RWK-NEU,BIB-NEU], [null], [SUG], [MAJ]] In\nProceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (2015), ACM, pp. 1310\u20131321.[[RWK-NEU,BIB-NEU], [null], [SUG], [MAJ]]\n\nThe first paper is the most related, also using homomorphic encryption, and seems to cover a superset of the functionalities presented here (more activation functions, a more extensive analysis, and faster decryption times).[[RWK-NEU], [CMP-NEU], [SMY], [MAJ]] The second paper uses arithmetic circuits rather than HE, but actually implements training an entire neural network securely.[[RWK-NEU], [CMP-NEU], [SMY], [MAJ]]\n\n Minor details:\n\nThe problem scenario states that the model/weights is private, but later on it ceases to be so (weights are not encrypted).[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n\n\"Both deep learning and FHE are relatively recent paradigms\". Deep learning is certainly not recent, while Gentry's paper is now 7 years old.[[RWK-NEU], [null], [CRT], [MIN]]\n\n\"In theory, this system alone could be used to compute anything securely.\" This is informal and incorrect.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] Can it solve the halting problem?[[MET-NEU], [null], [QSN], [MIN]]\n\n\"However in practice the operations were incredibly slow, taking up to 30 minutes in some cases.\" It is unclear what operations are referred to here.[[MET-NEU], [CLA-NEG], [CRT], [MIN]]\n\n\n\n\n\n\n\n\n"