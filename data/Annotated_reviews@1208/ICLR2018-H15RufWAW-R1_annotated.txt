"I am overall positive about the work but I would like to see some questions addressed.[[EXT-NEU], [null], [DIS], [GEN]]  \n\nQuality: The paper is good[[OAL-POS], [null], [APC], [MAJ]]  but does not address some important issues.[[OAL-NEG], [SUB-NEG], [DFT], [MAJ]]  The paper proposes a GAN model to generate graphs with non-trivial properties.[[PDI-NEU], [null], [SMY], [GEN]]  This is possibly one of the best papers on graph generation using GANs currently in the literature.[[PDI-POS], [null], [APC], [MAJ]]  However, there are a number of statistical issues that should be addressed.[[OAL-NEU], [null], [DIS], [MAJ]]  I fear the paper is not ready yet, but I am not opposed to publication as long as there are warnings in the paper about the shortcomings.[[OAL-NEU], [REC-NEU], [FBK], [MAJ]] \n\nOriginality: This is an original approach.[[PDI-POS], [NOV-POS], [APC], [MAJ]]  Random walks sometimes are overused in the graph literature, but they seem justified in this work.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]  But it also requires extra work to ensure they are generating meaningful graphs.[[ANA-NEU], [SUB-NEU], [SUG], [MIN]]\n\nSignificance: The problem is important.[[PDI-POS], [IMP-POS], [APC], [MAJ]] Learn to generate graphs is a key task in drug discovery, relational learning, and knowledge discovery.[[EXT-NEU], [null], [DIS], [GEN]]\n\nEvaluation: The link prediction task is too easy, as links are missing at random.[[EXP-NEU], [EMP-NEU], [DIS], [MAJ]] It would be more useful to predict links that are removed with an unknown bias.[[EXP-NEU], [EMP-NEU], [DIS], [MIN]] The graph (wedge, claw, etc) characteristics are good (but simple) metrics; however, it is unclear how a random graph with the same size and degree distribution (configuration model) would generate for the same metrics (it is not shown for comparison).[[EXP-NEG,MET-NEG], [CMP-NEG,EMP-NEG], [CRT], [MAJ]] \n\nIssues that I wish were addressed in the paper: \na)\tHow is the method learning a generator from a single graph?[[MET-NEU,ANA-NEU], [SUB-NEU,EMP-NEU], [QSN], [MIN]] What are the conditions under which the method is likely to perform well?[[MET-NEU,ANA-NEU], [SUB-NEU,EMP-NEU], [QSN], [MIN]] It seems to rely on some mixing RW conditions to model the distinct graph communities.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] What are these mixing conditions?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] These are important questions that should have at least an empirical exploration.[[EXP-NEU], [null], [DIS], [MIN]]\nb)\tWhat is the spatial independence assumption needed for such a generator?[[MET-NEU,ANA-NEU], [EMP-NEU], [QSN], [MIN]] \nc)\tWould this approach be able to generate a lattice?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Would it be able to generate an expander graph?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] What about a graph with poorly connect communities?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Is there any difficulties with power law graphs?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] \nd)\tHow is the RW statistically addressing the generation of high-order (subgraph) features?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\ne)\tCan this approach be used with multiple i.i.d. graphs?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] \nf)\tIsn\u2019t learning the random walk sample path a much harder / higher-dimensional task than it is necessary?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Again, the short walk may be capturing the communities but the high-dimensional random walk sample path seems like a high price to pay to learn community structure.[[MET-NEU], [EMP-NEU], [DIS], [GEN]]\ng)\tClearly, with a large T (number of RW steps), the RW is not modeling just a single community. Is there a way to choose T?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] How larger values of T to better model inter-community links?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Would different communities have different choices of T?[[CNT], [CNT], [QSN], [MIN]] \nh)\tAnd a related question, how well can the method generate the inter-community links?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\ni)\tThe RW model is actually similar to an HMM.[[MET-NEU], [CMP-NEU], [DIS], [GEN]] Would learning a mixture of HMMs (one per community) have similar performance?\n"[[MET-NEU], [EMP-NEU], [QSN], [MIN]]