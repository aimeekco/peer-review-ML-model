"This paper derived an upper bound on adversarial perturbation for neural networks with one hidden layer.[[INT-NEU], [null], [SMY], [GEN]] The upper bound is derived via (1) theorem of middle value; (2) replace the middle value by the maximum (eq 4); (3) replace the maximum of the gradient value (locally) by the global maximal value (eq 5); (4) this leads to a non-convex quadratic program, and then the authors did a convex relaxation similar to maxcut to upper bound the function by a SDP, which then can be solved in polynomial time.[[MET-NEU], [EMP-NEU], [SMY], [GEN]]\n\nThe main idea of  using upper bound (as opposed to lower bound) is reasonable.[[PDI-NEU], [null], [FBK], [MAJ]] However, I find there are some limitations/weakness of the proposed method:\n1. The method is likely not extendable to more complicated and more practical networks, beyond the ones discussed in the paper (ie with one hidden layer)\n2.[[MET-NEG], [EMP-NEG], [DFT], [MAJ]] SDP while tractable, would still require very expensive computation to solve exactly.[[MET-NEU], [EMP-NEU], [DFT], [MIN]]\n3. The relaxation seems a bit loose - in particular, in above step 2 and 3, the authors replace the gradient value by a global upper bound on that, which to me seems can be pretty loose."[[MET-NEG], [EMP-NEG], [DFT], [MIN]]