"\n-----UPDATE------\n\nThe authors addressed my concerns satisfactorily.[[RWK-POS,OAL-POS], [IMP-POS], [APC], [MAJ]] Given this and the other reviews I have bumped up my score from a 5 to a 6.[[RWK-POS,ANA-POS], [IMP-POS], [APC], [MAJ]]\n\n----------------------\n\n\nThis paper introduces two modifications that allow neural networks to be better at distinguishing between in- and out- of distribution examples: (i) adding a high temperature to the softmax, and (ii) adding adversarial perturbations to the inputs.[[INT-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] This is a novel use of existing methods.[[RWK-POS,MET-POS], [NOV-POS,EMP-POS], [APC], [MAJ]]\n\nSome roughly chronological comments follow:\n\nIn the abstract you don't mention that the result given is when CIFAR-10 is mixed with TinyImageNet.[[ABS-NEU,RWK-NEU,RES-NEU], [IMP-NEU,EMP-NEU], [SMY], [GEN]]\n\nThe paper is quite well written aside from some grammatical issues.[[INT-NEU,RWK-POS], [CLA-POS,PNF-NEG], [DFT], [MIN]] In particular, articles are frequently missing from nouns.[[RWK-NEU], [PNF-NEU], [DFT], [MIN]] Some sentences need rewriting (e.g. in 4.1 \"which is as well used by Hendrycks...\", in 5.2 \"performance becomes unchanged\").[[RWK-NEG], [PNF-NEG], [DFT], [MIN]]\n\n It is perhaps slightly unnecessary to give a name to your approach (ODIN) but in a world where there are hundreds of different kinds of GANs you could be forgiven.[[RWK-NEG,MET-NEG], [IMP-NEG,EMP-NEG], [DFT], [MIN]]\n\nI'm not convinced that the performance of the network for in-distribution images is unchanged, as this would require you to be able to isolate 100% of the in-distribution images.[[RWK-NEU,MET-NEG], [EMP-NEG], [DFT], [MIN]] I'm curious as to what would happen to the overall accuracy if you ignored the results for in-distribution images that appear to be out-of-distribution (e.g. by simply counting them as incorrect classifications).[[RWK-NEU,RES-NEU,ANA-NEU], [null], [DIS,QSN], [GEN]] Would there be a correlation between difficult-to-classify images, and those that don't appear to be in distribution?[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY,DIS], [GEN]]\n\nWhen you describe the method it relies on a threshold delta which does not appear to be explicitly mentioned again.[[RWK-NEG,EXP-NEG,MET-NEG], [EMP-NEG], [DFT], [MIN]]\n\nIn terms of experimentation it would be interesting to see the reciprocal of the results between two datasets.[[RWK-NEU,EXP-POS,RES-POS], [EMP-POS], [APC], [MIN]] For instance, how would a network trained on TinyImageNet cope with out-of-distribution images from CIFAR 10?\n\nSection 4.5 felt out of place, as to me, the discussion section flowed more naturally from the experimental results.[[RWK-NEU,EXP-NEU,RES-NEU], [IMP-NEU,EMP-NEU], [SMY], [GEN]] This may just be a matter of taste.\[[RWK-NEU], [null], [SMY], [GEN]]n\nI did like the observations in 5.1 about class deviation, although then, what would happen if the out-of-distribution dataset had a similar class distribution to the in-distribution one?[[RWK-NEU,EXP-NEU], [null], [QSN], [GEN]] (This is in part, addressed in the CIFAR80 20 experiments in the appendices).[[RWK-NEU,EXP-NEU,BIB-NEU], [null], [SMY], [GEN]]\n\nThis appears to be a borderline paper, as I am concerned that the method isn't sufficiently novel (although it is a novel use of existing methods).[[INT-NEU,MET-POS], [NOV-NEG], [DFT], [MIN]]\n\nPros:\n- Baseline performance is exceeded by a large margin\n- Novel use of adversarial perturbation and temperature\n- Interesting analysis[[RWK-NEU,EXP-NEU], [NOV-NEU], [SMY], [GEN]]\n\nCons:\n- Doesn't introduce and novel methods of its own\n- Could do with additional experiments (as mentioned above)\n- Minor grammatical error[[INT-NEG,EXP-NEG,MET-NEG], [NOV-NEG,EMP-NEG], [DFT], [MIN]]s\n"