"This paper proposes a simple problem to demonstrate the short-horizon bias of the learning rate meta-optimization.[[INT-NEU], [null], [SMY], [GEN]]\n\n- The idealized case of quadratic function the analytical solution offers a good way to understand how T-step look ahead can benefit the meta-algorithm.[[PDI-POS], [null], [SMY], [GEN]]\n- The second part of the paper seems to be a bit disconnected to the quadratic function analysis.[[MET-NEG], [EMP-NEG], [DFT,CRT], [MAJ]] It would be helpful to understand if there is gap between gradient based meta-optimization and the best effort(given by the analytical solution)[[MET-NEU], [CMP-NEU], [SUG], [MAJ]]\n- Unfortunately, no guideline or solution is offered in the paper.[[MET-NEG], [null], [CRT], [MAJ]]\n\nIn summary, the idealized model gives a good demonstration of the problem itself.[[PDI-POS], [null], [DIS], [MAJ]] I think it might be of interest to some audiences in ICLR.[[OAL-NEU], [REC-POS], [FBK], [MAJ]]"