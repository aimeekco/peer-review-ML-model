"The paper tries to maintain the accuracy of 2bits network, while uses possibly less than 2bits weights.[[RWK-NEU,EXP-NEU,RES-NEU,ANA-NEU], [EMP-NEU], [SMY], [GEN]]\n\n1.  The paper misses some more recent reference, e.g. [a,b].[[BIB-NEG,OAL-NEG], [SUB-NEG], [DFT], [MIN]] The author should also have a discussion on them.[[OAL-NEG], [SUB-NEG], [DFT], [MIN]]\n\n2. Indeed, AlexNet is a good seedbed to test binary methods.[[RWK-NEU,EXP-NEU,MET-NEU], [null], [SUG], [GEN]] However, it is more interesting and important to test on more advanced networks.[[RWK-POS,EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]] So, I wish to see a section on testing with Resnet and GoogleNet.[[EXT-NEU], [null], [FBK], [GEN]]\n\nIndeed, the authors have commented: \"AlexNet with batch-normalization (AlexNet-BN) is the standard model ... acceptance that improvements made to accuracy transfer well to more modern architectures.[[RWK-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]]\" So, please show that.[[RWK-NEG], [SUB-NEG], [DFT], [MIN]]\n\n3. The paper wants to find a good trade-off on speed and accuracy.[[EXT-NEU], [null], [FBK], [GEN]] The authors have plotted such trade-off on space v.s. accuracy in Figure 3(b), then how about speed v.s. accuracy?[[RWK-NEU,EXP-NEU,ANA-NEU], [null], [QSN], [GEN]]\n\nMy concern is that one-bit system is already complicated to implement.[[EXT-NEU], [null], [CRT], [MIN]] Indeed, the authors have discussed their implementation in Section 3.3, so, how their method works in practice?[[RWK-NEU,EXP-NEU,MET-NEU], [null], [SMY,QSN], [GEN]] One example is Section 4 in [Courbariaux et al. 2016].[[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]]\n\n4. Is trade-off between 1 to 2 bits really important? [[RWK-NEU], [null], [QSN], [GEN]]\n\nCompared with 2bits or ternary network, the proposed method at most achieving (1.4/2) compression ratio and (2/1.4) speedup (based on their Table 1). [[RWK-NEU,PDI-NEU,MET-NEU,TNF-NEU], [null], [SMY], [GEN]]Is such improvement really important?[[EXT-NEU], [null], [SUG], [GEN]]\n\nReference:\n[a]. Trained Ternary Quantization. ICLR 2017\n[b].[[BIB-NEU], [null], [SMY], [GEN]] Extremely low bit neural network: Squeeze the last bit out with ADMM.[[RWK-NEU], [null], [SMY], [GEN]] arvix 2017"