"This paper describes an approach to decode non-autoregressively for neural machine translation (and other tasks that can be solved via seq2seq models).[[MET-NEU], [null], [SMY], [GEN]] The advantage is the possibility of more parallel decoding which can result in a significant speed-up (up to a factor of 16 in the experiments described).[[EXP-POS,MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The disadvantage is that it is more complicated than a standard beam search as auto-regressive teacher models are needed for training and the results do not reach (yet) the same BLEU scores as standard beam search.[[EXP-NEG,MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]] \n\nOverall, this is an interesting paper.[[OAL-POS], [CNT], [APC], [MAJ]] It would have been good to see a speed-accuracy curve which plots decoding speed for different sized models versus the achieved BLUE score on one of the standard benchmarks (like WMT14 en-fr or en-de) to understand better the pros and cons of the proposed approach and to be able to compare models at the same speed or the same BLEU scores.[[EXP-NEU,MET-NEU,TNF-NEU], [SUB-NEU,EMP-NEU], [SUG], [MAJ]] Table 1 gives a hint of that but it is not clear whether much smaller models with standard beam search are possibly as good and fast as NAT -- losing 2-5 BLEU points on WMT14 is significant.[[MET-NEU,TNF-NEU], [EMP-NEG], [DIS], [MAJ]]  While the Ro->En results are goodG this particular language pair has not been used much by others; it would have been more interesting to stay with a single well-used language pair and benchmark and analyze why WMT14 en->de and de->en are not improving more.[[MET-NEG,ANA-NEG], [EMP-NEG], [CRT], [MAJ]] Finally it would have been good to address total computation in the comparison as well -- it seems while total decoding time is smaller total computation for NAT + NPD is actually higher depending on the choice of s.\n "[[MET-NEG,ANA-NEG], [EMP-NEG], [SUG], [MAJ]]