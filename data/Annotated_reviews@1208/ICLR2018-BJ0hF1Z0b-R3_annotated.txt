"This paper extends the previous results on differentially private SGD to user-level differentially private recurrent language models.[[RWK-NEU,PDI-NEU], [CMP-NEU], [SMY], [GEN]] It experimentally shows that the proposed differentially private LSTM achieves comparable utility compared to the non-private model.[[RWK-NEU,EXP-NEU,RES-NEU], [CMP-NEU], [SMY], [GEN]]\n\nThe idea of training differentially private neural network is interesting and very important to the machine learning + differential privacy community.[[PDI-POS], [IMP-POS], [APC], [MAJ]] This work makes a pretty significant contribution to such topic.[[OAL-POS], [IMP-POS], [APC], [MAJ]] It adapts techniques from some previous work to address the difficulties in training language model and providing user-level privacy.[[RWK-NEU,MET-NEU], [CMP-NEU], [SMY,DIS], [MIN]] The experiment shows good privacy and utility.[[EXP-POS], [EMP-POS], [APC], [MAJ]]\n\nThe presentation of the paper can be improved a bit.[[OAL-NEU], [PNF-NEG], [SUG], [MIN]] For example, it might be better to have a preliminary section before Section2 introducing the original differentially private SGD algorithm with clipping, the original FedAvg and FedSGD, and moments accountant as well as privacy amplification; otherwise, it can be pretty difficult for readers who are not familiar with those concepts to fully understand the paper.[[MET-NEU], [PNF-NEU], [SUG], [MIN]] Such introduction can also help readers understand the difficulty of adapting the original algorithms and appreciate the contributions of this work.\n"[[OAL-NEU], [PNF-NEU], [SUG], [MIN]]