"The authors describe a mechanism for defending against adversarial learning attacks on classifiers.[[INT-NEU], [null], [SMY], [GEN]] They first consider the dynamics generated by the following procedure.[[MET-NEU], [null], [SMY], [GEN]] They begin by training a classifier, generating attack samples using FGSM, then hardening the classifier by retraining with adversarial samples, generating new attack samples for the retrained classifier, and repeating.[[DAT-NEU,MET-NEU], [null], [SMY], [GEN]]  \n\nThey next observe that since FGSM is given by a simple perturbation of the sample point by the gradient of the loss, that the fixed point of the above dynamics can be optimized for directly using gradient descent.[[MET-NEU,ANA-NEU], [EMP-NEU], [SMY], [GEN]] They call this approach Sens FGSM, and evaluate it empirically against the various iterates of the above approach.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] \n\nThey then generalize this approach to an arbitrary attacker strategy given by some parameter vector (e.g. a neural net for generating adversarial samples).[[MET-NEU], [EMP-NEU], [SMY], [GEN]] In this case, the attacker and defender are playing a minimax game, and the authors propose finding the minimax (or maximin) parameters using an algorithm which alternates between maximization and minimization gradient steps.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] They conclude with empirical observations about the performance of this algorithm.[[EXP-NEU,MET-NEU,ANA-NEU], [EMP-NEU], [SMY], [GEN]]\n\nThe paper is well-written and easy to follow.[[OAL-POS], [CLA-POS], [APC], [MAJ]] However, I found the empirical results to be a little underwhelming.[[RES-NEU], [EMP-NEU], [DFT], [MAJ]] Sens-FGSM outperforms the adversarial training defenses tuned for the \u201cwrong\u201d iteration, but it does not appear to perform particularly well with error rates well above 20%.[[EXP-NEU], [EMP-NEG], [CRT], [MAJ]] How does it stack up against other defense approaches (e.g. https://arxiv.org/pdf/1705.09064.pdf)?[[EXP-NEU], [null], [QSN], [MIN]] Furthermore, what is the significance of FGSM-curr (FGSM-81) for Sens-FGSM? [[MET-NEU], [IMP-NEU], [QSN], [MIN]]It is my understanding that Sens-FGSM is not trained to a particular iteration of the \u201ccat-and-mouse\u201d game.[[MET-NEU], [EMP-NEU], [DIS], [MAJ]] Why, then, does Sens-FGSM provide a consistently better defense against FGSM-81?[[MET-NEU], [EMP-NEU], [QSN], [MAJ]] With regards to the second part of the paper, using gradient methods to solve a minimax problem is not especially novel (i.e. Goodfellow et al.),;[[RWK-NEU,MET-NEU], [NOV-NEG], [CRT], [MAJ]] thus I would liked to see more thorough experiments here as well.[[EXP-NEU], [SUB-NEU], [SUG], [MAJ]] For example, it\u2019s unlikely that the defender would ever know the attack network utilized by an attacker.[[EXP-NEG], [EMP-NEG], [DIS], [MAJ]] How robust is the defense against samples generated by a different attack network?[[DAT-NEU,EXP-NEU], [EMP-NEU], [QSN], [MIN]] The authors seem to address this in section 5 by stating that the minimax solution is not meaningful for other network classes. However, this is a bit unsatisfying.[[MET-NEU,ANA-NEU], [EMP-NEU], [CRT], [MAJ]] Any defense can be *evaluated* against samples generated by any attacker strategy.[[MET-NEU], [EMP-NEU], [DIS], [GEN]] Is it the case that the defenses fall flat against samples generated by different architectures? [[MET-NEU], [EMP-NEU], [QSN], [MAJ]]\n\n\nMinor Comments:\nSection 3.1, First Line. \u201df(ul(g(x),y))\u201d appears to be a mistake.[[OAL-NEU], [CLA-NEG], [DFT], [MIN]]"