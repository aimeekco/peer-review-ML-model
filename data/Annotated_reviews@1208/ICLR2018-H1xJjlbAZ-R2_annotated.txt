"The key observation is that it is possible to generate adversarial perturbations wherein the behavior of feature importance methods (e.g. simple gradient method (Simonyan et al, 2013), integrated gradient (Sundararajan et al, 2017), and DeepLIFT ( Shrikumar et al, 2016) ) have large variation while predicting same output.[[RWK-NEU,RES-NEU], [CMP-NEU], [DIS], [GEN]]    Thus the authors claim that one has to be careful about using feature importance maps.[[PDI-NEU], [null], [SMY], [GEN]]\n\nPro:  The paper raises an interesting point about the stability of feature importance maps generated by gradient based schemes.[[PDI-POS], [EMP-POS], [APC], [MAJ]]-  The examples in the paper seem to be cherry picked to illustrate dramatic effects.[[CNT], [CNT], [APC], [MAJ]]   The experimental protocol used does not provide enough information of the variability of the salience maps shown around small perturbations of adversarial inputs.[[EXP-NEG,ANA-NEG], [SUB-NEG], [DFT], [MAJ]]  The paper would benefit from more systematic experimentation and a better definition of what authors believe are important attributes of stability of human interpretability of neural net behavior."[[EXP-NEU,ANA-NEU], [SUB-NEU], [SUG], [MAJ]] 