"\n-----UPDATE------\n\nHaving read the responses from the authors, and the other reviews, I am happy with my rating and maintain that this paper should be accepted.[[EXT-POS], [REC-POS], [APC], [MAJ]]\n\n----------------------\n\n\n\nIn this paper, the authors trains a large number of MNIST classifier networks with differing attributes (batch-size, activation function, no. layers etc.) and then utilises the inputs and outputs of these networks to predict said attributes successfully.[[INT-NEU], [null], [SMY], [GEN]] They then show that they are able to use the methods developed to predict the family of Imagenet-trained networks and use this information to improve adversarial attack[[MET-NEU], [NULL], [DIS], [GEN]].\n\nI enjoyed reading this paper.[[OAL-POS], [CLA-POS], [APC], [MAJ]] It is a very interesting set up, and a novel idea.[[MET-POS], [NOV-POS], [APC], [MAJ]]\n\nA few comments:\n\nThe paper is easy to read, and largely written well[[OAL-POS], [CLA-POS], [APC], [MAJ]]. The article is missing from the nouns quite often though so this is something that should be amended. There are a few spelling slip ups (\"to a certain extend\" --> \"to a certain extent\", \"as will see\" --> \"as we will see\")][[OAL-NEG], [CLA-NEG], [DFT], [MIN]]\n\nIt appears that the output for kennen-o is a discrete probability vector for each attribute, where each entry corresponds to a possibility (for example, for \"batch-size\" it is a length 3 vector where the first entry corresponds to 64, the second 128, and the third 256)[[DAT-NEU,RES-NEU],[SUB-NEU], [DIS], [GEN]]. What happens if you instead treat it as a regression task, would it then be able to hint at intermediates (a batch size of 96) or extremes (say, 512).\[[EXP-NEU], [EMP-NEU], [QSN], [MIN]]n\nA flaw of this paper is that kennen-i and io appear to require gradients from the network being probed (you do mention this in passing), which realistically you would never have access to. (Please do correct me if I have misunderstood this)[[MET-NEG], [EMP-NEG], [DIS], [MIN]]\n\nIt would be helpful if Section 4 had a paragraph as to your thoughts regarding why certain attributes are easier/harder to predict[[MET-NEU], [CLA-NEU], [SUG], [MIN]]. Also, the caption for Table 2 could contain more information regarding the network outputs.[[TNF-NEU], [CLA-NEU], [SUG], [MIN]]\n\nYou have jumped from predicting 12 attributes on MNIST to 1 attribute on Imagenet[[MET-NEU],[EMP-NEU], [DIS], [GEN]]. It could be beneficial to do an intermediate experiment (a handful of attributes on a middling task)[[EXP-NEU], [SUB-NEU], [SUG], [MIN]].\n\nI think this paper should be accepted as it is interesting and novel[[OAL-POS], [NOV-POS,REC-POS], [FBK], [MAJ]].\n\nPros\n------\n- Interesting idea[[PDI-POS], [null], [APC], [MAJ]]\n- Reads well[[OAL-POS], [CLA-POS], [APC], [MAJ]]\n- Fairly good experimental results[[RES-POS], [null], [APC], [MAJ]]\n\nCons\n------\n- kennen-i seems like it couldn't be realistically deployed\n- lack of an intermediate difficulty task\n[[MET-NEG], [EMP-NEG], [DIS], [GEN]]