"This paper proposes an iterative inference scheme for latent variable models that use inference networks.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] Instead of using a fixed-form inference network, the paper proposes to use the learning to learn approach of Andrychowicz et. al.[[RWK-NEU,MET-NEU], [null], [SMY], [GEN]] The parameter of the inference network is still a fixed quantity but the function mapping is based on a deep network (e.g. it could be RNN but the experiments uses a feed-forward network).[[MET-NEU], [null], [SMY], [GEN]]\n\nMy main issue with the paper is that it does not do a good job justifying the main advantages of the proposed approach.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] It appears that the iterative method should result in \"direct improvement with additional samples and inference iterations\".[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] I am supposing this is at the test time. [[MET-NEU], [EMP-NEU], [DIS], [MIN]]It is not clear exactly when this will be useful. [[RWK-NEU,MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nI believe an iterative approach is also possible to perform with the standard VAE, e.g., by bootstrapping over the input data and then using the iterative scheme of Rezende et. al.[[MET-NEU], [SUB-NEG], [SUG], [MIN]] 2014 (they used this method to perform data imputation).[[RWK-NEU,DAT-NEU], [null], [DIS], [MIN]]\n\nThe paper should also discuss the additional difficulty that arises when training the proposed model and compare them to training of standard inference networks in VAE.[[EXP-NEG,ANA-NEG], [SUB-NEG], [DFT], [MAJ]]\n\nIn summary, the paper needs to do a better job in justifying the advantages obtained by the proposed method. "[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]