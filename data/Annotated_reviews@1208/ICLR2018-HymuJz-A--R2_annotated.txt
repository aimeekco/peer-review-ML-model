"The authors introduce a set of very simple tasks that are meant to illustrate the challenges of learning visual relations.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]]  They then evaluate several existing network architectures on these tasks, and show that results are not as impressive as others might have assumed they would be.[[MET-NEU,RES-NEG], [EMP-NEG], [CRT], [MAJ]]   They show that while recent approaches (e.g. relational networks) can generalize reasonably well on some tasks, these results do not generalize as well to held-out-object scenarios as might have been assumed.[[RWK-NEG,RES-NEG], [CMP-NEG,EMP-NEG], [CRT], [MAJ]] \n\nClarity:  The paper is fairly clearly written. [[OAL-POS], [CLA-POS], [APC], [MAJ]]  I think I mostly followed it.[[OAL-POS], [CLA-POS], [APC], [MAJ]]   \n\nQuality:  I'm intrigued by but a little uncomfortable with the generalization metrics that the authors use.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]   The authors estimate the performance of algorithms by how well they generalize to new image scenarios when trained on other image conditions.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]   The authors state that \". . . the effectiveness of an architecture to learn visual-relation problems should be measured in terms of generalization over multiple variants of the same problem, not over multiple splits of the same dataset.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] \"  Taken literally, this would rule out a lot of modern machine learning, even obviously very good work.[[RWK-NEG], [IMP-NEG], [CRT], [MIN]]  On the other hand, it's clear that at some point, generalization needs to occur in testing ability to understand relationships.[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]]   I'm a little worried that it's \"in the eye of the beholder\" whether a given generalization should be expected to work or not.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]  \n\nThere are essentially three scenarios of generalization discussed in the paper:\n        (a) various generalizations of image parameters in the PSVRT dataset\n  [[DAT-NEU,MET-NEU], [null], [DIS], [MIN]]       (b) various hold-outs of the image parameters in the sort-of-CLEVR dataset\n [[DAT-NEU,MET-NEU], [null], [DIS], [MIN]]        (c) from sort-of-CLEVR \"objects\" to PSVRT bit patterns[[DAT-NEU,MET-NEU], [null], [DIS], [MIN]] \n\nThe result that existing architectures didn't do very well at these generalizations (especially b and c) *may* be important -- or it may not.[[MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MIN]]     Perhaps if CNN+RN were trained on a quite rich real-world training set with a variety of real-world three-D objects beyond those shown in sort-of-CLEVR, it would generalize to most other situations that might be encountered.[[DAT-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [CRT], [MIN]]     After all, when we humans generalize to understanding relationships, exactly what variability is present in our \"training sets\" as compared to our \"testing\" situations?[[EXT-NEU], [null], [DIS], [MIN]]    How do the authors know that humans are effectively generalizing rather than just \"interpolating\" within their (very rich) training set?[[DAT-NEU,MET-NEU], [EMP-NEU], [QSN], [MIN]]   It's not totally clear to me that if totally naive humans (who had never seen spatial relationships before) were evaluated on exactly the training/testing scenarios described above, that they would generalize particularly well either.[[DAT-NEG,MET-NEG], [EMP-NEG], [CRT], [MIN]]    I don't think it can just be assumed a priori that humans would be super good this form of generalization.[[RES-NEU], [EMP-NEU], [DIS], [MIN]]   \n\nSo how should authors handle this criticism?[[RES-NEG], [EMP-NEG], [CRT], [MIN]]   What would be useful would either be some form of positive control.[[RES-NEG], [EMp-NEG], [CRT], [MIN]]   Either human training data showing very effective generalization (if one could somehow make \"novel\" relationships unfamiliar to humans), or a different network architecture that was obviously superior in generalization to CNN+RN.[[DAT-NEU,MET-NEU], [null], [DIS], [MIN]]  If such were present, I'd rate this paper significantly higher.[[OAL-NEU], [REC-NEU], [FBK], [MIN]] \n\nAlso, I can't tell if I really fully believe the results of this paper.[[RES-NEG], [EMP-NEG], [CRT], [MIN]]   I don't doubt that the authors saw the results they report.[[RES-NEG], [EMP-NEG], [CRT], [MIN]]   However, I think there's some chance that if the same tasks were in the hands of people who *wanted* CNNs or CNN+RN to work well, the results might have been different.[[MET-NEU,RES-NEU], [EMP-NEU], [DIS], [MIN]]   I can't point to exactly what would have to be different to make things \"work\", because it's really hard to do that ahead of actually trying to do the work. [[OAL-NEU], [null], [DIS], [MIN]]  However, this suspicion on my part is actually a reason I think it might be *good* for this paper to be published at ICLR.[[OAL-POS], [REC-POS], [FBK], [MAJ]]  This will give the people working on (e.g.) CNN+RN somewhat more incentive to try out the current paper's benchmarks and either improve their architecture or show that the the existing one would have totally worked if only tried correctly.[[FWK-POS], [IMP-POS], [APC], [MAJ]]  I myself am very curious about what would happen and would love to see this exchange catalyzed.[[FWK-POS,OAL-POS], [IMP-POS], [APC], [MAJ]] \n\nOriginality and Significance:  The area of relation extraction seems to me to be very important and probably a bit less intensively worked on that it should be.[[OAL-POS], [NOV-POS], [APC], [MAJ]]  However, as the authors here note, there's been some recent work (e.g. Santoro 2017) in the area.[[RWK-NEU], [CMP-NEU], [DIS], [MIN]]   I think that the introduction of baselines  benchmark challenge datasets such as the ones the authors describe here is very useful, and is a somewhat novel contribution. [[DAT-POS,RWK-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]    "