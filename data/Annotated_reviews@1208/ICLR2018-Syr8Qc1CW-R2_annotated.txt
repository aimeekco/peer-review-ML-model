"Summary:\nThis paper investigated the problem of attribute-conditioned image generation using generative adversarial networks.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] More specifically, the paper proposed to generate images from attribute and latent code as high-level representation.[[PDI-NEU], [null], [SMY], [GEN]] To learn the mapping from image to high-level representations, an auxiliary encoder was introduced.[[MET-NEU], [null], [SMY], [GEN]] The model was trained using a combination of reconstruction (auto-encoding) and adversarial loss.[[MET-NEU], [null], [SMY], [GEN]] To further encourage effective disentangling (against trivial solution), an annihilating operation was proposed together with the proposed training pipeline.[[MET-NEU], [null], [SMY], [GEN]]  Experimental evaluations were conducted on standard face image databases such as Multi-PIE and CelebA.[[DAT-NEU, EXP-NEU], [null], [SMY], [GEN]] \n\n== Novelty and Significance ==\nMulti-attribute image generation is an interesting task but has been explored to some extent.[[PDI-NEG], [NOV-NEG,IMP-NEG], [CRT], [MIN]] The integration of generative adversarial networks with auto-encoding loss is not really a novel contribution.[[PDI-NEG], [NOV-NEG], [CRT], [MIN]] \n-- Autoencoding beyond pixels using a learned similarity metric. Larsen et al., In ICML 2016.[[RWK-NEU,MET-NEU], [CMP-NEU], [DIS], [MIN]]\n\n== Technical Quality == \nFirst, it is not clear how was the proposed annihilating operation used in the experiments (there is no explanation in the experimental section).[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] Based on my understanding, additional loss was added to encourage effective disentangling (prevent trivial solution).[[MET-NEU], [EMP-NEU], [DIS], [MIN]] I would appreciate the authors to elaborate this a bit.[[EXP-NEU], [SUB-NEU], [SUG,DIS], [MIN]]\n\nSecond, the iterative training (section 3.4) is not a novel contribution since it was explored in the literature before (e.g., Inverse Graphics network).[[RWK-NEU,MET-NEG], [CMP-NEG], [CRT], [MAJ]] The proof developed in the paper provides some theoretical analysis but cannot be considered as a significant contribution.[[ANA-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nThird, it seems that the proposed multi-attribute generation pipeline works for binary attribute only.[[MET-NEG], [SUB-NEG], [DFT], [MIN]] However, such assumption limits the generality of the work.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] Since the title is quite general, I would assume to see the results (1) on datasets with real-valued attributes, mixture attributes or even relative attributes[[INT-NEU,DAT-NEU,RES-NEU], [EMP-NEU], [DIS], [MIN]] and (2) not specific to face images.[[RES-NEU], [EMP-NEU], [DIS], [MIN]]\n-- Learning to generate chairs with convolutional neural networks. Dosovitskiy et al., In CVPR 2015.\n-- Deep Convolutional Inverse Graphics Network. Kulkarni et al., In NIPS 2015.\n-- Attribute2Image: Conditional Image Generation from Visual Attributes. Yan et al., In ECCV 2016.[[RWK-NEU,BIB-NEU], [CMP-NEU], [DIS], [MIN]]\n-- InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. Chen et al., In NIPS 2016.Yan et al., In ECCV 2016.[[RWK-NEU,BIB-NEU], [CMP-NEU], [DIS], [MIN]]\n\nAdditionally, considering the generation quality, the CelebA samples in the paper are not the state-of-the-art.[[RWK-NEG], [CMP-NEG], [CRT], [MAJ]] I suspect the proposed method only works in a more constrained setting (such as Multi-PIE where the images are all well aligned).[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nOverall, I feel that the submitted version is not ready for publication in the current form.\n" [[OAL-NEG], [REC-NEG], [FBK], [MAJ]]