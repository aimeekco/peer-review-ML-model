"Quality\n\nThe authors introduce a deep network for predictive coding.[[MET-NEU], [null], [SMY], [GEN]] It is unclear how the approach improves on the original predictive coding formulation of Rao and Ballard, who also use a hierarchy of transformations.[[MET-NEG], [EMP-NEG], [SMY], [GEN]] The results seem to indicate that all layers are basically performing the same.[[MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]] No insight is provided about the kinds of filters that are learned.[[RES-NEG], [SUB-NEG], [DFT], [MAJ]]n\nClarity\n\nIn its present form it is hard to assess if there are benefits to the current formulation compared to already existing formulations.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]]. The paper should be checked for typos.[[OAL-NEG], [CLA-NEG], [SUG,CRT], [MAJ]]\n\nOriginality\n\nThere exist alternative deep predictive coding models such as https://arxiv.org/abs/1605.08104.[[MET-NEG], [NOV-NEG], [CRT], [MAJ]] This work should be discussed and compared.[[RWK-NEU], [CMP-NEU], [SUG], [MIN]]\n\nSignificance \n\nIt is hard to see how the present paper improves on classical or alternative (deep) predictive coding results.[[RES-NEG], [EMP-NEG], [CRT], [MIN]]\n\nPros\n\nRelevant attempt to develop new predictive coding architectures[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nCons\n\nUnclear what is gained compared to existing work."[[RWK-NEG], [EMP-NEG], [CRT], [MIN]]