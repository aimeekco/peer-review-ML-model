"This paper studies a dual formulation of an adversarial loss based on an upper-bound of the logistic loss.[[INT-NEU], [null], [SMY], [GEN]] This allows the authors to turn the standard min max problem of adversarial training into a single minimization problem, which is easier to [[PDI-NEU], [null], [SMY], [GEN]] The method is demonstrated on a toy example and on the task of unsupervised domain adaptation.[[MET-NEU], [null], [SMY], [GEN]] \n\nStrengths:\n- The derivation of the dual formulation is novel[[MET-POS], [NOV-POS], [APC], [MAJ]] \n- The dual formulation simplifies adversarial training[[EXP-POS], [EMP-POS], [APC], [MAJ]] \n- The experiments show the better behavior of the method compared to adversarial training for domain adaptation[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]] \n\nWeaknesses:\n- It is unclear that this idea would generalize beyond a logistic regression classifier, which might limit its applicability in practice[[PDI-NEG], [EMP-NEG], [CRT], [MIN]] \n- It would have been nice to see results on other tasks than domain adaptation, such as synthetic image generation, for which GANs are often used[[MET-NEU], [null], [SUG], [MIN]] \n- It would be interesting to see if the DA results with a kernel classifier are better (comparable to the state of the art)[[RWK-NEU], [CMP-NEU], [SUG], [MIN]]\n- The mathematical derivations have some errors[[MET-NEG], [null], [SUG], [MIN]]\n\n\nDetailed comments:\n- The upper bound used to derive the formulation applies to a logistic regression classifier.[[MET-NEU], [EMP-NEU], [DIS], [GEN]] While effective, such a classifier might not be as powerful as multi-layer architectures that are used as discriminators. [[MET-NEG], [EMP-NEG], [CRT], [MIN]] I would be interested to know if they authors see ways to generalize to better classifiers.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n\n- The second weakness listed above might be related to the first one.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Did the authors tried their approach to non-DA tasks, such as generating images, as often done with GANs?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Showing such results would be more convincing.[[RES-NEU], [EMP-NEU], [SUG], [MIN]] However, I wonder if the fact that the method has to rely on a simple classifier does not limit its ability to tackle other tasks.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\n- The DA results are shown with a linear classifier, for the comparison to the baselines to be fair, which I appreciate.[[RES-POS], [EMP-POS], [APC], [MAJ]] However, to evaluate the effectiveness of the method, it would be interesting to also report results with a kernel-based classifier, so as to see how it compares to the state of the art.[[RWK-NEU,MET-POS,RES-NEU,ANA-NEU], [SUB-NEU,EMP-NEU], [SUG], [MIN]]\n\n- There are some errors and unclear things in the mathematical derivations:\n* In the equation above Eq. 2, \\alpha should in fact be \\alpha_i, and it is not a vector (no need to transpose it)[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n* In Eq. 2, it should be \\alpha_i \\alpha_j instead of \\alpha^T\\alpha\n*[[MET-NEG], [EMP-NEG], [CRT], [MIN]] In Eq. 3, it is unclear to me where the constraint 0 \\leq \\alpha \\leq 1 comes from.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] The origin of the last equality constraints on the sums of \\alpha_A and \\alpha_B is also unclear to me.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n* In Eq. 3, it is also not clear to me why the third term has a different constant weight than the first two.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] This would have an impact on the relationship to the MMD[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n\n- The idea of sample reweighting within the MMD was in fact already used for DA, e.g., Huang et al., NIPS 2007, Gong et al., ICML 2013.[[RWK-NEU,MET-NEU], [CMP-NEU], [DIS], [MIN]] What is done here is quite different, but I think it would be worth discussing these relationships in the paper.[[RWK-NEU], [CMP-NEU], [SUG], [MIN]]\n\n- The paper is reasonably clear,[[OAL-POS], [CLA-POS], [APC], [MAJ]] but could be improved with some more details on the mathematical derivations (e.g., explaining where the constraints on \\alpha come from), and on the experiments (it is not entirely clear how the distributions of accuracies were obtained).\n"[[EXP-NEG,MET-NEG], [EMP-NEG], [SUG,CRT], [MAJ]]