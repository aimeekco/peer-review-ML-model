"1. Paper summary \n\nThis paper describes a technique using 3 neural networks to privatize data and make predictions: a feature extraction network, an image classification network, and an image reconstruction network.[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]]  The idea is to learn a feature extraction network so that the image classification network performs well and the image reconstruction network performs poorly.[[PDI-NEU], [null], [SMY], [GEN]] \n\n\n2. High level paper - subjective\n\nI think the presentation of the paper is somewhat scattered: In section 2 the authors introduce their network and their metric for utility and privacy and then immediately do a sensitivity analysis.[[ANA-NEG,OAL-NEG], [PNF-NEG], [CRT], [MIN]]  Section 3 continues with a sensitivity analysis now considering performance and storage of the method.[[MET-NEU,ANA-NEU], [PNF-NEU], [DIS], [MIN]]  Then 2.5 pages are spent on channel pruning.[[CNT], [PNF-NEU], [DIS], [MIN]] \nI would have liked if the authors spent more time justifying why we should trust their method as a privacy preserving technique (described in detail below).[[MET-NEU,ANA-NEU], [PNF-NEG], [CRT], [MIN]]  \nThe authors clearly performed an impressive amount of sensitivity experiments.[[EXP-POS], [EMP-POS], [APC], [MAJ]]  Assuming the privacy claims are reasonable (which I have some doubts about below) then this paper is clearly useful to any company wanting to do privacy preserving classification.[[ANA-NEG,OAL-NEG], [PNF-NEG], [CRT], [MIN]]  At the same time I think the paper does not have a significant amount of machine learning novelty in it.[[OAL-NEG], [NOV-NEG], [CRT], [MIN]]  \n\n\n3. High level technical\n\nI have a few doubts about this method as a privacy-preserving technique:\n- Nearly every privacy-preserving technique gives a guarantee, e.g., differential privacy guarantees a statistical notion of privacy and cryptographic methods guarantee a computational notion of privacy.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]  In this work the authors provide a way to measure privacy but there is no guarantee that if someone uses this method their data will be private, by some definition, even under certain assumptions.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- Another nice thing about differential privacy and cryptography is that they are impervious to different algorithms because it is statistically hard or computationally hard to reveal sensitive information.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Here there could be a better image reconstruction network that does a better job of reconstructing images than the ones used in the paper.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- It's not clear to my why PSNR is a useful way to measure privacy loss.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] I understand that it is a metric to compare two images that is based on the mean-squared error so a very private image should have a low PSNR while a not private image should have a high PSNR, but I have no intuition about how small the PSNR should be to afford a useful amount of privacy. For instances, in nearly all of the images of Figures 21 and 22 I think it would be quite easy to guess the original images.[[TNF-NEU], [CNT], [DIS], [MIN]]\n\n\n4. 1/2 sentence summary\n\nWhile the authors did an extensive job evaluating different settings of their technique I have serious doubts about it as a privacy-preserving method."[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]