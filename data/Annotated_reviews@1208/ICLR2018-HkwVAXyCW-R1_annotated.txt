"UPDATE: Following the author's response I've increased my score from 5 to 6.[[OAL-NEU], [REC-NEU], [FBK], [MAJ]] The revised paper includes many of the additional references that I suggested, and the author response clarified my confusion over the Charades experiments; their results are indeed close to state-of-the-art on Charades activity localization (slightly outperformed by [6]), which I had mistakenly confused with activity classification (from [5]).[[RWK-NEU,RES-NEU], [null], [DIS], [GEN]]\n\nThe paper proposes the Skip RNN model which allows a recurrent network to selectively skip updating its hidden state for some inputs, leading to reduced computation at test-time.[[MET-NEU], [null], [SMY], [GEN]] At each timestep the model emits an update probability; if this probability is over a threshold then the next input and state update will be skipped.[[MET-NEU], [null], [SMY], [GEN]] The use of a straight-through estimator allows the model to be trained with standard backpropagation.[[MET-NEU], [null], [SMY], [GEN]] The number of state updates that the model learns to use can be controlled with an auxiliary loss function. [[MET-NEU], [null], [SMY], [GEN]]Experiments are performed on a variety of tasks, demonstrating that the Skip-RNN compares as well or better than baselines even when skipping nearly half its state updates.[[RWK-POS,MET-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]\n\nPros:\n- Task of reducing computation by skipping inputs is interesting\n[[MET-POS], [EMP-POS], [APC], [MAJ]]- Model is novel and interesting[[MET-POS], [NOV-POS], [APC], [MAJ]]\n- Experiments on multiple tasks and datasets confirm the efficacy of the method[[EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]]\n- Skipping behavior can be controlled via an auxiliary loss term[[MET-NEU], [null], [DIS], [MIN]]\n- Paper is clearly written[[OAL-POS], [CLA-POS], [APC], [MAJ]]\n\nCons:\n- Missing comparison to prior work on sequential MNIST[[DAT-NEG,MET-NEG], [SUB-NEG,CMP-NEG], [DFT], [MIN]]\n- Low performance on Charades dataset, no comparison to prior work\n[[RWK-NEG,DAT-NEG], [CMP-NEG,EMP-NEG], [DFT,CRT], [MAJ]]- No comparison to prior work on IMDB Sentiment Analysis or UCF-101 activity classification[[RWK-NEG,ANA-NEG], [CMP-NEG], [DFT], [MAJ]]\n\nThe task of reducing computation by skipping RNN inputs is interesting, and the proposed method is novel, interesting, and clearly explained.[[MET-POS], [CLA-POS,NOV-POS], [APC], [MAJ]] Experimental results across a variety of tasks are convincing; in all tasks the Skip-RNNs achieve their goal of performing as well or better than equivalent non-skipping variants.[[EXP-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The use of an auxiliary loss to control the number of state updates is interesting;[[MET-POS], [EMP-POS], [APC], [MAJ]] since it sometimes improves performance it appears to have some regularizing effect on the model in addition to controlling the trade-off between speed and accuracy.[[MET-POS], [EMP-POS], [APC], [MAJ]] \n\nHowever, where possible experiments should compare directly with prior published results on these tasks; none of the experiments from the main paper or supplementary material report any numbers from any other published work.[[RWK-NEG,RES-NEG], [CMP-NEG], [DFT,CRT], [MAJ]] \n\nOn permuted MNIST, Table 2 could include results from [1-4].[[DAT-NEU,RES-NEU,TNF-NEU], [EMP-NEU], [DIS], [MIN]]  Of particular interest is [3], which reports 98.9% accuracy with a 100-unit LSTM initialized with orthogonal and identity weight matrices; this is significantly higher than all reported results for the sequential MNIST task.[[DAT-POS,RES-POS], [EMP-POS], [APC], [MAJ]] \n\nFor Charades, all reported results appear significantly lower than the baseline methods reported in [5] and [6] with no explanation.[[RWK-NEG,RES-NEG], [CMP-NEG], [CRT], [MAJ]]  All methods work on \u201cfc7 features from the RGB stream of a two-stream CNN provided by the organizers of the [Charades] challenge\u201d, and the best-performing method (Skip GRU) achieves 9.02 mAP.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]  This is significantly lower than the two-stream results from [5] (11.9 mAP and 14.3 mAP) and also lower than pretrained AlexNet features averaged over 30 frames and classified with a linear SVM, which [5] reports as achieving 11.3 mAP.[[RWK-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]]   I don\u2019t expect to see state-of-the-art performance on Charades; the point of the experiment is to demonstrate that Skip-RNNs perform as well or better than their non-skipping counterparts, which it does.[[RWK-NEG,MET-NEG], [CMP-NEU], [DIS], [MIN]]   However I am surprised at the low absolute performance of all reported results, and would appreciate if the authors could help to clarify whether this is due to differences in experimental setup or something else.[[EXP-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]]  \n\nIn a similar vein, from the supplementary material, sentiment analysis on IMDB and action classification on UCF-101 are well-studied problems, but the authors do not compare with any previously published results on these tasks.[[RWK-NEG,ANA-NEG], [CMP-NEG], [CRT], [MAJ]]  .\n\nThough experiments may not show show state-of-the-art performance, I think that they still serve to demonstrate the utility of the Skip-RNN architecture when compared side-by-side with a similarly tuned non-skipping baseline.[[RWK-POS,EXP-POS], [CMP-POS], [APC], [MAJ]]   However I feel that the authors should include some discussion of other published results.[[RWK-NEU,RES-NEU], [SUB-NEU], [SUG], [MIN]]  \n\nOn the whole I believe that the task and method are interesting, and experiments convincingly demonstrate the utility of Skip-RNNs compared to the author\u2019s own baselines.[[RWK-POS,EXP-POS,MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]]   I will happily upgrade my rating of the paper if the authors can address my concerns over prior work in the experiments.[[RWK-NEU,EXP-NEU], [CMP-NEU,REC-NEU], [FBK], [MAJ]]  \n\n\nReferences\n\n[1] Le et al, \u201cA Simple Way to Initialize Recurrent Networks of Rectified Linear Units\u201d, arXiv 2015\n[2] Arjovsky et al, \u201cUnitary Evolution Recurrent Neural Networks\u201d, ICML 2016\n[3] Cooijmans et al, \u201cRecurrent Batch Normalization\u201d, ICLR 2017\n[4] Zhang et al, \u201cArchitectural Complexity Measures of Recurrent Neural Networks\u201d, NIPS 2016\n[5] Sigurdsson et al, \u201cHollywood in homes: Crowdsourcing data collection for activity understanding\u201d, ECCV 2016\n[6] Sigurdsson et al, \u201cAsynchronous temporal fields for action recognition\u201d, CVPR 2017"[[BIB-NEU], [null], [DIS], [MIN]]  