"This paper proposes a new method, called VCL, for continual learning.[[INT-NEU,MET-NEU], [null], [SMY], [GEN]] This method is a combination of the online variational inference for streaming environment with Monte Carlo method.[[MET-NEU], [null], [SMY], [GEN]] The authors further propose to maintain a coreset which consists of representative data points from the past tasks.[[RWK-NEU,DAT-NEU], [SUB-NEU], [SMY], [GEN]] Such a coreset is used for the main aim of avoiding the catastrophic forgetting problem in continual learning.[[DAT-POS], [SUB-POS], [DIS], [GEN]] Extensive experiments shows that VCL performs very well, compared with some state-of-the-art methods.[[EXP-POS], [SUB-POS,CMP-POS], [APC], [MAJ]] \n\nThe authors present two ideas for continual learning in this paper: (1) Combination of online variational inference and sampling method, (2) Use of coreset to deal with the catastrophic forgetting problem.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] Both ideas have been investigated in Bayesian literature, while (2) has been recently investigated in continual learning.[[RWK-POS,PDI-NEU], [NOV-NEU], [DIS], [MAJ]] Therefore, the authors seems to be the first to investigate the effectiveness of (1) for continual learning.[[MET-POS,ANA-POS], [EMP-POS], [APC], [MAJ]] From extensive experiments, the authors find that the first idea results in VCL which can outperform other state-of-the-art approaches, while the second idea plays little role. [[RWK-NEU,EXP-POS], [CMP-POS,EMP-POS], [SMY], [MAJ]]\n\nThe finding of the effectiveness of idea (1) seems to be significant. [[MET-POS], [IMP-POS], [SMY], [GEN]]The authors did a good job when providing a clear presentation, a detailed analysis about related work, an employment to deep discriminative models and deep generative models, and a thorough investigation of empirical performance.[[RWK-POS,MET-POS,ANA-POS], [PNF-POS,EMP-POS], [APC], [MAJ]]\n\nThere are some concerns the authors should consider:\n- Since the coreset plays little role in the superior performance of VCL, it might be better if the authors rephrase the title of the paper.[[INT-NEU,DAT-NEU], [null], [SUG], [MIN]] When the coreset is empty, VCL turns out to be online variational inference [Broderich et al., 2013; Ghahramani & Attias, 2000].[[RWK-POS,BIB-NEU], [CMP-POS], [SMY], [GEN]] Their finding of the effectiveness of online variational inference for continual learning should be reflected in the writing of the paper as well.[[MET-POS], [CLA-NEU], [SUG], [MIN]]\n- It is unclear about the sensitivity of VCL with respect to the size of the coreset. The authors should investigate this aspect.[[DAT-NEU], [SUB-NEU,EMP-NEU], [DFT], [MIN]]\n- What is the trade-off when the size of the coreset increases?\n"[[DAT-NEU], [null], [QSN], [MIN]]