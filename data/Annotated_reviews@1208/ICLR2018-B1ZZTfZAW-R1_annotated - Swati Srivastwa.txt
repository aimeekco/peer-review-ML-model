"The authors propose to use synthetic data generated by GANs as a replacement for personally identifiable data in training ML models for privacy-sensitive applications such as medicine.[[PDI-NEU], [null], [SMY], [GEN]] In particular it demonstrates adversarial training of a recurrent generator for an ICU monitoring multidimensional time series, proposes to evaluate such models by the performance (on real data) of supervised classifiers trained on the synthetic data (\"TSTR\"), and empirically analyzes the privacy implications of training and using such a model.[[EXP-NEU,MET-NEU,ANA-NEU], [null], [SMY], [GEN]] \n\nThis paper touches on many interesting issues -- deep/recurrent models of time series, privacy-respecting ML, adaptation from simulated to real-world domains.[[PDI-POS], [EMP-POS], [APC], [MAJ]] But it is somewhat unfocused and does not seem make a clear contribution to any of these.[[PDI-NEG], [EMP-NEG], [CRT], [MIN]] \n\nThe recurrent GAN architecture does not appear particularly novel --- the authors note that similar architectures have been used for discrete tasks such language modeling (and fail to note work that uses convolutional or recurrent generators for video prediction, a more relevant continuous task, see e.g.  http://carlvondrick.com/tinyvideo/, or autoregressive approaches to deep models of time series, e.g. WaveNet https://arxiv.org/abs/1609.03499) and there is no obvious new architectural innovation. [[EXP-NEG,MET-NEG], [NOV-NEG], [CRT], [MAJ]]\n\nI also find it difficult to assess whether the proposed model is actually generating reasonable time series.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] It may be true that \"one plot showing synthetic ICU data would not provide enough information to evaluate its actual similarity to the real data\" because it could not rule out that case that the model has captured the marginal distribution in each dimension but not joint structure.[[DAT-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] However producing marginal distributions that look reasonable is at least a *necessary* condition and without seeing those plots it is hard to rule out that the model may be producing highly unrealistic samples.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] \n\nThe basic privacy paradigm proposed seems to be:\n1. train a GAN using private data[[EXP-NEU], [null], [DIS], [MIN]]\n2. generate new synthetic data, assume this data does not leak private information[[DAT-NEU], [null], [DIS], [MIN]]\n3. train a supervised classifier on the private data\nso that the GAN training-sampling loop basically functions as an anonymization procedure. For this to pan out, we'd need to see that the GAN samples are a) useful for a range of supervised tasks, and b) do not leak private information.[[EXP-NEU], [null], [DIS], [MIN]] But the results  in Table 2 show that the TSTR results are quite a lot worse than real data in most cases, and it's not obvious that the small set of tasks evaluated are representative of all tasks people might care about.[[TNF-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]] The attempts to demonstrate empirically that the GAN does not memorize training data aren't particularly convincing; this is an adversarial setting so the fact that a *particular* test doesn't reveal private data doesn't imply that a determined attacker wouldn't succeed.[[DAT-NEG,EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] In this vein, the experiments with DP-\u000fSGD are more interesting,[[EXP-POS], [EMP-POS], [APC], [MAJ]] although a more direct comparison would be helpful (it is frustrating to flip back and forth between Tables 2 and 3 in an attempt to tease out relative performance) and and it is not clear how the settings (\u03b5 \u000f\u000f\u000f= 0.5 and \u03b4 \u2264 9.8 \u00d7 10\u22123) were selected or whether they provide a useful level of privacy.[[EXP-NEG,MET-NEG,TNF-NEG], [EMP-NEG], [CRT], [MAJ]] That said I agree this is an interesting avenue for future work.[[OAL-POS], [IMP-POS], [APC], [MAJ]]\n\nFinally it's worth noting that discarding patients with missing data is unlikely to be innocuous for ICU applications; data are quite often not missing at random (e.g., a patient going into a seizure may dislocate a sensor).[[DAT-NEG], [SUB-NEG], [CRT], [MAJ]] It appears that the analysis in this paper threw out more than 90% of the patients in their original dataset, which would present serious concerns in using the resulting synthetic data to represent the population at large.[[DAT-NEG,ANA-NEG], [SUB-NEG,EMP-NEG], [CRT], [MAJ]] One could imagine coding missing data in various ways (e.g. asking the generator to produce a missingness pattern as well as a time series and allowing the discriminator to access only the masked time series, or explicitly building a latent variable model) and some sort of principled approach to missing data seems crucial for meaningful results on this application. "[[DAT-NEG,MET-NEG,ANA-NEG], [SUB-NEG,EMP-NEG], [CRT], [MAJ]]