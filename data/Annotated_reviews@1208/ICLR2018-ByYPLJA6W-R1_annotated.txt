"The paper considers distribution to distribution regression with MLPs.[[INT-NEU], [null], [SMY], [GEN]]  The authors use an energy function based approach.[[MET-NEU], [null], [SMY], [GEN]]  They test on a few problems, showing similar performance to other distribution to distribution alternatives, but requiring fewer parameters.[[EXP-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nThis seems to be a nice treatment of distribution to distribution regression with neural networks.[[MET-POS], [EMP-POS], [APC], [MAJ]] The approach is methodological similar to using expected likelihood kernels.[[MET-POS], [EMP-POS], [APC], [MAJ]]  While similar performance is achieved with fewer parameters, it would be more enlightening to consider accuracy vs runtime instead of accuracy vs parameters.[[MET-NEU], [EMP-NEU], [SUG], [MAJ]]  That\u2019s what we really care about.  In a sense, because this problem has been considered several times in slightly different model classes, there really ought to be a pretty strong empirical investigation. In the discussion, it says. [[MET-NEU], [EMP-NEU], [DIS], [MAJ]] \n\u201cFor future work, a possible study is to investigate what classes of problems DRN can solve.[[FWK-NEU], [null], [DIS], [MAJ]]\u201d  It feels like in the present work there should have been an investigation about what classes of problems the DRN can solve.[[MET-NEU], [EMP-NEU], [SUG], [MAJ]]  Its practical utility is questionable.  It\u2019s not clear how much value there is adding yet another distribution to distribution regression approach, this time with neural networks, without some pretty strong motivation (which seems to be lacking), as well as experiments.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]]  In the introduction, it would also improve the paper to outline clear points of methodological novelty.[[INT-NEU], [CLA-NEU], [SUG], [MAJ]]  \n"