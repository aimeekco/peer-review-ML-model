"Summary: This paper proposes to use the latent representations learned by a model-free RL agent to learn a transition model for use in model-based RL (specifically MCTS).[[INT-NEU], [null], [SMY], [GEN]] The paper introduces a strong model-free baseline (win rate ~80% in the MiniRTS environment) and shows that the latent space learned by this baseline does include relevant game information.[[RWK-POS,MET-NEU], [EMP-POS], [APC], [MAJ]] They use the latent state representation to learn a model for planning, which performs slightly better than a random baseline (win rate ~25%).[[RWK-NEU,MET-POS], [CMP-POS], [APC], [MAJ]]\n\nPros:\n- Improvement of the model-free method from previous work by incorporating information about previously observed states, demonstrating the importance of memory.[[RWK-NEU,MET-POS], [CMP-POS], [APC], [MAJ]]\n- Interesting evaluation of which input features are important for the model-free algorithm, such as base HP ratio and the amount of resources available.[[MET-NEU,ANA-POS], [EMP-POS], [APC], [MAJ]]\n\nCons:\n- The model-based approach is disappointing compared to the model-free approach.[[MET-NEU], [CMP-NEU], [CRT], [MAJ]]\n\nQuality and Clarity:\n\nThe paper in general is well-written and easy to follow and seems technically correct,;[[OAL-POS], [CLA-POS], [APC], [MAJ]] though I found some of the figures and definitions confusing, specifically:\n\n- The terms for different forward models are not defined (e.g. MatchPi, MatchA, etc.).[[MET-NEG,TNF-NEG], [EMP-NEG], [CRT], [MAJ]] I can infer what they mean based on Figure 1 but it would be helpful to readers to define them explicitly.[[TNF-NEU], [PNF-NEU], [SUG], [MAJ]]\n- In Figure 3b, it is not clear to me what the difference between the red and blue curves is.[[TNF-NEG], [PNF-NEG], [CRT], [MIN]]\n- In Figure 4, it would be helpful to label which color corresponds to the agent and which to the rule-based AI.[[TNF-NEU], [PNF-NEU], [SUG], [MIN]]\n- The caption in Figure 8 is malformatted.[[TNF-NEG], [PNF-NEG], [CRT], [MIN]]\n- In Figure 7, the baseline of \\hat{h_t}=h_{t-2} seems strange---I would find it more useful for Figure 7 to compare to the performance if the model were not used (i.e. if \\hat{h_t}=h_t) to see how much performance suffers as a result of model error.[[RWK-NEG,MET-NEU,TNF-NEU], [EMP-NEG], [CRT], [MAJ]]\n\nOriginality:\n\nI am unfamiliar with the MiniRTS environment, but given that it is only published in this year's NIPS (and that I couldn't find any other papers about it on Google Scholar) it seems that this is the first paper to compare model-free and model-based approaches in this domain.[[MET-NEU], [NOV-POS], [DIS], [MAJ]] However, the model-free approach does not seem particularly novel in that it is just an extension of that from Tian et al. (2017) plus some additional features.[[RWK-NEU,MET-NEU], [NOV-NEU,CMP-NEU], [DIS], [MAJ]] The idea of learning a model based on the features from a model-free agent seems novel but lacks significance in that the results are not very compelling (see below).[[PDI-POS,RES-NEG], [NOV-POS,IMP-NEG], [DIS], [MAJ]]\n\nSignificance:\n\nI feel the paper overstates the results in saying that the learned forward model is usable in MCTS.[[RES-NEU], [IMP-NEU], [CRT], [MAJ]] The implication in the abstract and introduction (at least as I interpreted it) is that the learned model would outperform a model-free method, but upon reading the rest of the paper I was disappointed to learn that in reality it drastically underperforms.[[ABS-NEU,INT-NEU,MET-NEG], [EMP-NEG], [CRT], [MAJ]] The baseline used in the paper is a random baseline, which seems a bit unfair---a good baseline is usually an algorithm that is an obvious first choice, such as the model-free approach.[[RWK-NEG], [EMP-NEG], [CRT], [MAJ]]"