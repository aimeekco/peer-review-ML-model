"This paper presents an experimental study on the behavior of the units of neural networks.[[INT-NEU], [null], [SMY], [GEN]] In particular, authors aim to show that units behave as binary classifiers during training and testing.[[PDI-NEU], [null], [SMY], [MAJ]] \n\nI found the paper unnecessarily longer than the suggested 8 pages.[[OAL-NEG], [CLA-NEG], [CRT], [MAJ]] The focus of the paper is confusing: while the introduction discusses about works on CNN model interpretability, the rest of the paper is focused on showing that each unit behaves consistently as a binary classifier, without analyzing anything in relation to interpretability.[[INT-NEU,MET-NEU], [CLA-NEG,EMP-NEU], [CRT], [MAJ]]  I think some formal formulation and specific examples on the relevance of the partial derivative of the loss with respect to the activation of a unit will help to understand better the main idea of the paper.[[RWK-NEU,MET-NEU], [CLA-NEU], [SUG], [MAJ]] Also, quantitative figures would be useful to get the big picture.[[RES-NEU,TNF-NEU], [null], [SUG], [MAJ]] For example in Figures 1 and 2 the authors show the behavior of some specific units as examples, but it would be nice to see a graph showing quantitatively the behavior of all the units at each layer.[[RES-NEU,TNF-NEU], [PNF-NEU], [SUG], [MAJ]] It would be also useful to see a comparison of different CNNs and see how the observation holds more or less depending on the performance of the network.[[RWK-NEU,MET-NEU], [CMP-NEU], [SUG], [MAJ]]\n"