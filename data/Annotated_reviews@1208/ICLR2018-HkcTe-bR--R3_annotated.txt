"Summary: This paper studies a series of reinforcement learning (RL) techniques in combination with recurrent neural networks (RNNs) to model and synthesise molecules. [[INT-NEU,PDI-NEU,DAT-NEU,MET-NEU], [EMP-NEU], [SMY,DIS], [GEN]]The experiments seem extensive, using many recently proposed RL methods, [[RWK-NEU,EXP-NEG,MET-NEU], [EMP-NEU], [SMY,DFT], [GEN]]and show that most sophisticated RL methods are less effective than the simple hill-climbing technique, with PPO is perhaps the only exception[[RWK-NEU,PDI-NEG,MET-NEG], [IMP-NEG,EMP-NEG], [DFT], [MIN]].  \n\nOriginality and significance:[[RWK-NEU], [NOV-NEU,IMP-NEU], [SMY], [GEN]] \n\nThe conclusion from the experiments could be valuable to the broader sequence generation/synthesis field, showing that many current RL techniques can fail dramatically. [[RWK-NEU,EXP-POS,MET-NEG,FWK-NEG], [IMP-NEU,EMP-NEG], [DFT], [MIN]]\n\nThe paper does not provide any theoretical contribution but nevertheless is a good application paper combining and comparing different techniques[[INT-NEG,RWK-NEG], [SUB-NEG,CMP-NEU,EMP-NEG], [DFT], [MIN]].\n\nClarity: The paper is generally well-written. However, I'm not an expert in molecule design, so might not have caught any trivial errors in the experimental set-up.[[INT-POS,RWK-NEU,EXP-NEU,EXT-NEU], [CLA-POS,IMP-NEU,REC-NEU,EMP-NEU], [DIS,FBK], [GEN]] "