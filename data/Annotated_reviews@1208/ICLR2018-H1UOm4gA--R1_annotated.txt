"This paper introduces a new task that combines elements of instruction following\nand visual question answering: agents must accomplish particular tasks in an\ninteractive environment while providing one-word answers to questions about\nfeatures of the environment.[[PDI-NEU], [null], [SMY], [GEN]] To solve this task, the paper also presents a new\nmodel architecture that effectively computes a low-rank attention over both\npositions and feature indices in the input image.[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]] It uses this attention as a\ncommon bottleneck for downstream predictors that select actions and answers to\nquestions.[[MET-NEU], [null], [SMY], [GEN]] The paper's main claim is that this model architecture enables strong\ngeneralization: it allows the model to succeed at the instruction following task\neven when given words it has only seen in QA contexts, and vice-versa.[[PDI-NEU,MET-NEU], [null], [SMY], [GEN]]\nExperiments show that on the navigation task, the proposed approach outperforms\na variety of baselines under both a normal data condition and one requiring\nstrong generalization.[[RWK-POS,EXP-POS], [CMP-POS], [APC], [MAJ]]\n\nOn the whole, I think this paper does paper does a good job of motivating the\nproposed modeling decisions.[[MET-POS], [EMP-POS], [APC], [MAJ]] The approach is likely to be useful for other\nresearchers working on related problems.[[MET-POS], [IMP-POS], [APC], [MAJ]] I have a few questions about the\nevaluation, but most of my comments are about presentation.[[EXP-NEU,MET-NEU], [PNF-NEU], [DIS], [GEN]]\n\nEVALUATION\n\nIs it really the case that no results are presented for the QA task, or am I\nmisreading one of the charts here?[[EXP-NEU,RES-NEU], [SUB-NEU,EMP-NEU], [QSN], [MIN]] Given that this paper spends a lot of time\nmotivating the QA task as part of the training scenario, I was surprised not to\nsee it evaluated.[[EXP-NEG,MET-NEG], [SUB-NEG], [DFT], [MAJ]] \n\nAdditionally, when I first read the paper I thought that the ZS1 experiments\nfeatured no QA training at all.[[EXP-NEU], [null], [DIS], [GEN]] However, your response to one of the sibling\ncomments suggests that it's still a \"mixed\" training setting where the sampled\nQA and NAV instances happen to cover the full space.[[EXP-NEU], [null], [DIS], [GEN]] This should be made more\nclear in the paper.[[EXP-NEU], [CLA-NEU], [SUG], [MIN]] It would be nice to know (1) how the various models perform\nat QA in both ZS1 and ZS2 settings, and (2) what the actual performance is NAV\nalone (even if the results are terrible).[[MET-NEU,RES-NEU], [EMP-NEU], [SUG], [MIN]]\n\nMODEL PRESENTATION\n\nI found section 2 difficult to read: in particular, the overloading of \\Phi\nwith different subscripts for different output types, the general fact that\ne.g. x and \\Phi_x are used interchangeably, and the large number of different\nvariables.[[MET-NEG], [CLA-NEG,PNF-NEG], [CRT], [MIN]] My best suggestions are to drop the \\Phis altogether and consider\nusing text subscripts rather than coming up with a new name for every variable,\nbut there are probably other things that will also help.[[MET-NEU], [CLA-NEU,PNF-NEU], [SUG], [MIN]]\n\nOTHER NOTES\n\n- This paper needs serious proofreading---just in the first few pages the errors\n  I noticed were \"in 2D environment\" (in the title!), \"such capability\", \"this\n  characteristics\", \"such language generalization problem\", \"the agent need to\",\n  \"some early pioneering system\", \"commands is\".[[OAL-NEG], [CLA-NEG], [CRT], [MIN]] I gave up on keeping track at\n  this point but there are many more.[[OAL-NEG], [CLA-NEG], [CRT], [MIN]]\n\n- \\phi in Fig 2 should be explained by the caption.[[TNF-NEU], [PNF-NEU], [SUG], [MIN]]\n\n- Here's another good paper to cite for the end of 2.2.1:\n  https://arxiv.org/pdf/1707.00683.pdf.[[BIB-NEU], [null], [SUG], [MIN]]\n\n- The mechanism in 2.2.4 feels a little like\n  http://aclweb.org/anthology/D17-1015[[RWK-NEU], [CMP-NEU], [DIS], [MIN]]\n\n- I don't think the content on pages 12, 13, and 14 adds much to the\n  paper---consider moving these to an appendix."[[OAL-NEU], [PNF-NEU], [SUG], [MIN]]