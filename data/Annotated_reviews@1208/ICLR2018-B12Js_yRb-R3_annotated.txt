"This paper tackles the object counting problem in visual question answering.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] It is based on the two-stage method that object proposals are generated from the first stage with attention.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] It proposes many heuristics to use the object feature and attention weights to find the correct count.[[MET-NEU], [null], [SMY], [GEN]]  In general, it treats all object proposals as nodes on the graph.[[MET-NEU], [null], [SMY], [GEN]] With various agreement measures, it removes or merges edges and count the final nodes.[[MET-NEU], [null], [SMY], [GEN]] The method is evaluated on one synthetic toy dataset and one VQA v2 benchmark dataset.[[DAT-NEU,MET-NEU], [null], [SMY], [GEN]] The experimental results on counting are promising.[[EXP-POS,RES-POS], [EMP-POS], [APC], [MAJ]]  Although counting is important in VQA, the method is solving a very specific problem which cannot be generalized to other representation learning problems.[[MET-POS], [EMP-POS], [APC], [MAJ]]  Additionally, this method is built on a series of heuristics without sound theoretically justification, and these heuristics cannot be easily adapted to other machine learning applications.[[MET-NEU], [EMP-NEU], [DIS], [MAJ]] I thus believe the overall contribution is not sufficient for ICLR.[[OAL-NEG], [APR-NEG], [CRT], [MAJ]]\n\nPros:\n1. Well written paper with clear presentation of the method. [[MET-POS,OAL-POS], [CLA-POS,PNF-POS], [APC], [MAJ]]\n2. Useful for object counting problem.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n3. Experimental performance is convincing.[[EXP-POS], [EMP-POS], [APC], [MAJ]] \n\nCons:\n1. The application range of the method is very limited.[[MET-NEG], [SUB-NEG,EMP-NEG], [CRT], [MAJ]] \n2. The technique is built on a lot of heuristics without theoretical consideration.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] \n\nOther comments and questions:\n\n1. The determinantal point processes [1] should be able to help with the correct counting the objects with proper construction of the similarity kernel.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]  It may also lead to simpler solutions.[[RES-NEU], [EMP-NEU], [DIS], [MIN]] For example, it can be used for deduplication using A (eq 1) as the similarity matrix.[[MET-NEU,RES-NEU], [EMP-NEU], [SUG], [MIN]] \n\n2. Can the author provide analysis on scalability the proposed method?[[ANA-NEU,MET-NEU], [SUB-NEU], [QSN], [MIN]] When the number of objects is very large, the graph could be huge.[[TNF-NEG], [PNF-NEG], [SUG,DIS], [MIN]] What are the memory requirements and computational complexity of the proposed method?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]  \nIn the end of section 3, it mentioned that \"without normalization,\" the method will not scale to an arbitrary number of objects.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] I think that it will only be a problem for extremely large numbers.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] I wonder whether the proposed method scales.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] \n\n3. Could the authors provide more insights on why the structured attention (etc) did not significantly improve the result? [[MET-NEG,RES-NEG], [SUB-NEG], [CRT], [MAJ]]Theoritically, it solves the soft attention problems.[[MET-NEU,RES-NEU], [EMP-NEU], [DIS], [MIN]] \n\n4. The definition of output confidence (section 4.3.1) needs more motivation and theoretical justification.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] \n\n[1] Kulesza, Alex, and Ben Taskar. \"Determinantal point processes for machine learning.\" Foundations and Trends\u00ae in Machine Learning 5.2\u20133 (2012): 123-286."[[BIB-NEU], [null], [DIS], [MIN]]