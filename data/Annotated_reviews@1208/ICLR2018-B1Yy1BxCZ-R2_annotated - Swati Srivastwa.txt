"The paper represents an empirical validation of the well-known idea (it was published several times before) \nto increase the batch size over time.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] Inspired by recent works on large-batch studies, the paper suggests to adapt the learning rate as a function of the batch size.[[RWK-NEU,MET-NEU], [CMP-NEU], [SMY], [MIN]]\n\nI am interested in the following experiment to see how useful it is to increase the batch size compared to fixed batch size settings.[[EXP-NEU], [EMP-NEU], [DIS], [MIN]] \n\n1) The total budget / number of training samples is fixed.[[EXP-NEU], [EMP-NEU], [DIS], [MIN]] \n2) Batch size is scheduled to change between B_min and B_max\n3) Different setting of B_min and B_max>=B_min are considered, e.g., among [64, 128, 256, 512, ...] or [64, 256, 1024, ...] if it is too expensive.[[EXP-NEU], [null], [DIS], [MIN]]\n4) Drops of the learning rates are scheduled to happen at certain times represented in terms of the number of training samples passed so far (not parameter updates).[[EXP-NEU], [null], [DIS], [MIN]]\n5) Learning rates and their drops should be rescaled taking into account the schedule of the batch size and the rules to adapt learning rates in large-scale settings as by Goyal. "[[EXP-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]]