"The authors present a scalable model for questioning answering that is able to train on long documents.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] On the TriviaQA dataset, the proposed model achieves state of the art results on both domains (wikipedia and web).[[DAT-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The formulation of the model is straight-forward,[[OAL-POS], [EMP-POS], [APC], [MAJ]] however I am skeptical about whether the results prove the premise of the paper (e.g. multi-mention reasoning is necessary).[[RES-NEG], [EMP-NEG], [CRT], [MAJ]] Furthermore, I am slightly unconvinced about the authors' claim of efficiency.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]] Nevertheless, I think this work is important given its performance on the task.[[RES-POS,OAL-POS], [EMP-POS], [APC], [MAJ]]\n\n1. Why is this model successful?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Multi-mention reasoning or more document context?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\nI am not convinced of the necessity of multi-mention reasoning, which the authors use as motivation, as shown in the examples in the paper.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] For example, in Figure 1, the answer is solely obtained using the second last passage.[[MET-NEG,TNF-NEG], [EMP-NEG], [CRT], [MIN]] The other mentions provide signal, but does not provide conclusive evidence.[[ANA-NEG], [SUB-NEG], [DFT,CRT], [MIN]] Perhaps I am mistaken, but it seems to me that the proposed model cannot seem to handle negation, can the authors confirm/deny this?[[MET-NEG], [EMP-NEG], [QSN,CRT], [MAJ]] I am also skeptical about the computation efficiency of a model that scores all spans in a document (which is O(N^2), where N is the document length).[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] Can you show some analysis of your model results that confirm/deny this hypothesis?[[RES-NEU,ANA-NEU], [EMP-NEU], [QSN], [MIN]]\n\n2. Why is the computational complexity not a function of the number of spans?[[MET-NEG], [EMP-NEG], [QSN,CRT], [MIN]]\nIt seems like the derivations presents several equations that score a given span.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Perhaps I am mistaken, but there seems to be n^2 spans in the document that one has to score.[[MET-NEU], [EMP-NEG], [DIS], [MIN]] Shouldn't the computational complexity then be at least O(n^2), which makes it actually much slower than, say, SQuAD models that do greedy decoding O(2n + nm)?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nSome minor notes\n- 3.3.1 seems like an attention computation in which the attention context over the question and span is computed using the question.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] Explicitly mentioning this may help the reading grasp the formulation.[[MET-NEU], [CNT], [SUG], [MIN]]\n- Same for 3.4, which seems like the biattention (Seo 2017) or coattention (Xiong 2017) from previous squad work.[[RWK-NEU], [CMP-NEU], [DIS], [MIN]]\n- The sentence \"We define ... to be the embeddings of the l words of the sentence that contains s.\" is not very clear.[[TNF-NEG], [CLA-NEG], [CRT], [MIN]] Do you mean that the sentence contains l words?[[CNT], [CLA-NEG], [QSN], [MIN]] It could be interpreted that the span has l words.[[TNF-NEG], [CLA-NEG], [SUG], [MIN]]\n- There is a typo in your 3.7 \"level 1 complexity\": there is an extra O inside the big O notation."[[MET-NEG], [CLA-NEG], [CRT], [MIN]]