"In this paper, the authors define a simulated, multi-agent \u201ctaxi pickup\u201d task in a GridWorld environment.[[INT-NEU], [null], [SMY], [GEN]] In the task, there are multiple taxi agents that a model must learn to control.[[PDI-NEU], [null], [SMY], [GEN]] \u201cCustomers\u201d randomly appear throughout the task and the taxi agents receive reward for moving to the same square as a customer.[[PDI-NEU], [null], [SMY], [GEN]] Since there are multiple customer and taxi agents, there is a multi-agent coordination problem.[[PDI-NEU], [null], [SMY], [GEN]] Further, the taxi agents have \u201cbatteries\u201d, which starts at a positive number, ticks down by one on each time step and a large negative reward is given if this number reaches zero.[[MET-NEU], [null], [SMY], [GEN]] The battery can be \u201crecharged\u201d by moving to a \u201ccharge\u201d tile.[[MET-NEU], [null], [SMY], [GEN]] \n\nCooperative multi-agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science.[[PDI-POS], [null], [APC], [GEN]]  This paper defines and examines an interesting cooperative problem: Assignment and control of agents to move to certain squares under \u201cphysical\u201d constraints.[[PDI-POS], [EMP-POS], [APC], [MAJ]] The authors propose a centralized solution to the problem by adapting the Deep Q-learning Network model.[[PDI-POS,RES-POS], [EMP-POS], [APC], [MAJ]] I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm.[[MET-NEG], [NOV-NEG], [CRT], [MAJ]] The manuscript itself makes it difficult to assess (more on this later).[[MET-NEG], [EMP-NEG], [CRT], [MIN]] If it were novel, it would be an incremental development.[[MET-NEU], [NOV-NEU], [DIS], [MAJ]] They assess their solution quantitatively, demonstrating their model performs better than first, a simple heuristic model (I believe de-centralized Dijkstra\u2019s for each agent, but there is not enough description in the manuscript to know for sure), and then, two other baselines that I could not figure out from the manuscript (I believe it was Dijkstra\u2019s with two added rules for when to recharge).[[RWK-NEG,MET-NEG], [CMP-NEG,EMP-NEG], [CRT], [MAJ]]\n\nAlthough the manuscript has many positive aspects to it,[[OAL-POS], [null], [DIS], [MIN]] I do not believe it should be accepted for the following reasons.[[OAL-NEG], [REC-NEG], [FBK], [MAJ]]  First, the manuscript is poorly written, to the point where it has inhibited my ability to assess it.[[OAL-NEG], [CLA-NEG], [CRT], [MAJ]]  Second, given its contribution, the manuscript is better suited for a conference specific to multi-agent decision-making.[[OAL-NEG], [APR-NEG], [DIS], [MIN]]  There are a few reasons for this. 1) I was not convinced that deep Q-learning was necessary to solve this problem.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]  The manuscript would be much stronger if the authors compared their method to a more sophisticated baseline, for example having each agent be a simple Q-learner with no centralization or \u201cdeepness\u201d.[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]] This would solve another issue, which is the weakness of their baseline measure.[[RWK-NEG,MET-NEG], [CMP-NEG], [CRT], [MAJ]] There are many multi-agent techniques that can be applied to the problem that would have served as a better baseline.[[RWK-NEG,MET-NEG], [CMP-NEG], [SUG], [MAJ]] 2) Although the problem itself is interesting,[[PDI-POS], [EMP-POS], [APC], [MAJ]] it is a bit too applied and specific to the particular task they studied than is appropriate for a conference with as broad interests as ICLR.[[PDI-NEG], [APR-NEG], [CRT], [MIN]] It also is a bit simplistic (I had expected the agents to at least need to learn to move the customer to some square rather than get reward and move to the next job from just getting to the customer\u2019s square).[[MET-NEG], [EMP-NEG], [CRT], [MIN]] Can you apply this method to other multi-agent problems?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] How would it compare to other methods on those problems?[[MET-NEU], [CMP-NEU], [QSN], [MIN]] \n\nI encourage the authors to develop the problem and method further, as well as the analysis and evaluation. \n"[[MET-NEU,ANA-NEU], [SUB-NEU], [DIS], [MIN]]