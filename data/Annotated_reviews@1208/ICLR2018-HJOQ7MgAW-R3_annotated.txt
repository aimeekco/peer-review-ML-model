"Summary: the paper proposes a new insight to LSTM in which the core is an element-wise weighted sum.[[PDI-NEU], [null], [SMY], [GEN]] The paper then argues that LSTM is redundant by keeping only input and forget gates to compute the weights.[[PDI-NEU], [null], [DIS], [GEN]] Experimental results show that the simplified versions work as well as the full LSTM.[[EXP-NEU,RES-NEU], [null], [DIS], [GEN]] \n\n\nComment: I kinda like the idea and welcome this line of research.[[PDI-POS], [EMP-POS], [APC], [MAJ]] The paper is very well written and has nice visualisation of demonstrating weights.[[OAL-POS], [CLA-POS], [APC], [MAJ]] I have only one question:\n\nin the simplified versions, content(x_t) = Wx_t , which works very well (outperforming full LSTM).[[MET-POS], [EMP-POS], [APC], [MAJ]] I was wondering if the problem is from the tanh activation function (eq 2).[[PDI-NEU,MET-NEU], [null], [DIS], [GEN]] What if content(x_t) = W_1 . h_{t-1} + W_2 . x_t? "[[MET-NEU], [EMP-NEU], [QSN], [MIN]]