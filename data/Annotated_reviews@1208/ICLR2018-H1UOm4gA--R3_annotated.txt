"The paper introduces XWORLD, a 2D virtual environment with which an agent can constantly interact via navigation commands and question answering tasks.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] Agents working in this setting therefore, learn the language of the \"teacher\" and efficiently ground words to their respective concepts in the environment.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] The work also propose a neat model motivated by the environment and outperform various baselines.[[RWK-POS,MET-POS], [CMP-POS], [APC], [MAJ]] \n\nFurther, the paper evaluates the language acquisition aspect via two zero-shot learning tasks -- ZS1) A setting consisting of previously seen concepts in unseen configurations ZS2) Contains new words that did not appear in the training phase.[[EXP-NEU], [null], [SMY], [GEN]] \n\nThe robustness to navigation commands in Section 4.5 is very forced and incorrect -- randomly inserting unseen words at crucial points might lead to totally different original navigation commands right?[[EXP-NEU,MET-NEU], [EMP-NEU], [QSN], [MAJ]] As the paper says, a difference of one word can lead to completely different goals and so, the noise robustness experiments seem to test for the biases learned by the agent in some sense (which is not desirable).[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]] Is there any justification for why this method of injecting noise was chosen ?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Is it possible to use hard negatives as noisy / trick commands and evaluate against them for robustness ? [[MET-NEU], [EMP-NEU], [QSN], [MIN]]  \n\nOverall, I think the paper proposes an interesting environment and task that is of interest to the community in general.[[OAL-POS], [IMP-POS], [APC], [MAJ]]  The modes and its evaluation are relevant and intuitions can be made use for evaluating other similar tasks (in 3D, say). "[[MET-POS], [EMP-POS], [APC], [MAJ]] 