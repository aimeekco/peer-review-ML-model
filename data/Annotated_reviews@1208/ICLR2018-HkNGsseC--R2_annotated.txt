"The paper analyzes the expressivity of convolutional arithmetic circuits (ConvACs), where neighboring neurons in a single layer have overlapping receptive fields.[[RWK-NEU,EXP-NEU,MET-NEU,ANA-NEU], [EMP-NEU], [SMY], [GEN]] To compare the expressivity of overlapping networks with non-overlapping networks, the paper employs grid tensors computed from the output of the ConvACs.[[RWK-NEU,EXP-NEU,MET-NEU,RES-NEU,ANA-NEU], [CMP-NEU,EMP-NEU], [SMY,DIS], [GEN]]  The grid tensors are matricized and the ranks of the resultant matrices are compared. [[RWK-NEU,MET-NEU,ANA-NEU], [CMP-NEU], [SMY,DIS], [GEN]]The paper obtains a lower bound on the rank of the resultant grid tensors[[RWK-NEG,MET-NEG], [EMP-NEG], [DFT], [MIN]], and uses them to show that an exponentially large number of non-overlapping ConvACs are required to approximate the grid tensor of an overlapping ConvACs.[[RWK-NEG,EXP-NEG,MET-NEG,ANA-NEG], [CMP-NEG,EMP-NEG], [SUG,DFT], [MIN]] Assuming that the result carries over to ConvNets, I find this result to be very interesting.[[RWK-POS,RES-POS], [IMP-POS], [APC], [MAJ]]  While overlapped convolutional layers are almost universally used, there has been very little theoretical justification for the same[[RWK-NEG,ANA-NEG], [EMP-NEG], [DFT], [MIN]]. This paper shows that overlapped ConvACs are exponentially more powerful than their non-overlapping counterparts. "[[RWK-POS,MET-POS,ANA-POS], [IMP-POS,CMP-POS], [APC], [MAJ]]
