"This paper addresses the problem of one class classification.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] The authors suggest a few techniques to learn how to classify samples as negative (out of class) based on tweaking the GAN learning process to explore large areas of the input space which are out of the objective class.[[MET-NEU], [null], [SMY], [GEN]]\n\nThe suggested techniques are nice and show promising results.[[MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]] But I feel a lot can still be done to justify them, even just one of them.[[MET-NEU], [EMP-NEU], [SUG], [MAJ]] For instance, the authors manipulate the objective of G using a new parameter alpha_new and divide heuristically the range of its values.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] But, in the experimental section results are shown only for a  single value, alpha_new=0.9 The authors also suggest early stopping but again (as far as I understand) only a single value for the number of iterations was tested.[[EXP-NEU], [EMP-NEU], [SMY], [GEN]] \n\nThe writing of the paper is also very unclear, with several repetitions and many typos e.g.:\n\n'we first introduce you a'\n'architexture'\n'future work remain to'\n'it self'\n\nI believe there is a lot of potential in the approach(es) presented in the paper.[[OAL-NEG], [CLA-NEG], [CRT], [MAJ]] In my view a much stronger experimental section together with a clearer presentation and discussion could overcome the lack of theoretical discussion.[[EXP-NEU], [PNF-NEU,EMP-NEU], [SUG], [MAJ]]\n"