"This paper is an extension of the \u201cprototypical network\u201d which will be published in NIPS 2017.[[EXT-NEU], [CNT], [CNT], [CNT]] The classical few-shot learning has been limited to using the unlabeled data, while this paper considers employing the unlabeled examples available to help train each episode. [[RWK-NEU,DAT-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]]The paper solves a new semi-supervised situation, which is more close to the setting of the real world, with an extension of the prototype network. [[PDI-POS,EXP-POS,MET-POS], [EMP-POS], [APC], [MAJ]] Sufficient implementation detail and analysis on results.[[EXP-NEU,RES-NEU,ANA-NEU], [IMP-NEU,EMP-NEU], [SMY], [GEN]]\n\nHowever, this is definitely not the first work on semi-supervised formed few-shot learning.[[RWK-NEG], [IMP-NEG], [DFT], [MIN]] There are plenty of works on this topic [R1, R2, R3]. [[RWK-NEG], [EMP-NEG], [DFT], [MIN]]The authors are advised to do a thorough survey of the relevant works in Multimedia and computer vision community.[[RWK-NEG], [SUB-NEG,EMP-NEG], [DFT,CRT], [MIN]] \n \nAnother concern is that the novelty.[[OAL-NEU], [NOV-NEU], [SMY,FBK], [GEN]] This work is highly incremental since it is an extension of existing prototypical networks by adding the way of leveraging the unlabeled data.[[RWK-NEU,PDI-NEU], [EMP-NEU], [SMY], [GEN]] \n\nThe experiments are also not enough.[[EXP-NEG,OAL-NEG], [SUB-NEG,IMP-NEG], [DFT,CRT], [MIN]]Not only some other works such as [R1, R2, R3]; but also the other na\u00efve baselines should also be compared, such as directly nearest neighbor classifier, logistic regression, and neural network in traditional supervised learning.[[RWK-NEG,PDI-NEG,EXP-NEG,MET-NEG], [CMP-NEG,EMP-NEG], [DFT], [MIN]] Additionally, in the 5-shot non-distractor setting on tiered ImageNet, only the soft kmeans method gets a little bit advantage against the semi-supervised baseline, does it mean that these methods are not always powerful under different dataset?[[RWK-NEU,PDI-NEU,EXP-NEU], [EMP-NEU], [SMY], [GEN]]\n\n[R1] \u201cVideostory: A new multimedia embedding for few-example recognition and translation of events,\u201d in ACM MM, 2014\n\n[R2] \u201cTransductive Multi-View Zero-Shot Learning\u201d, IEEE TPAMI 2015\n\n[R3] \u201cVideo2vec embeddings recognize events when examples are scarce,\u201d IEEE TPAMI 2014\n"[[RWK-NEU,EXP-NEU,MET-NEU,BIB-NEU], [null], [SMY], [GEN]]