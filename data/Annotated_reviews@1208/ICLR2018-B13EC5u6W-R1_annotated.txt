"* This paper models images with a latent code representation, and then tries to modify the latent code to minimize changes in image space, while changing the classification label.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] As the authors indicate, it lies in the space of algorithms looking to modify the image while changing the label (e.g. LIME etc).[[MET-NEU], [null], [SMY], [GEN]]\n\n* This is quite an interesting paper with a sensible goal.[[OAL-POS], [null], [APC], [MAJ]] It seems like the method could be more informative than the other methods.[[MET-POS], [EMP-POS], [APC], [MAJ]]  However, there are quite a number of problems, as explained below.\n\n* The explanation of eqs 1 and 2 is quite poor.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] \\alpha in (1) seems to be \\gamma in Alg 1 (line 5). \"L_target is a target objective which can be a negative class probability ..\" this assumes that the example is a positive class.[[MET-NEU], [null], [SMY], [GEN]] Could we not also apply this to negative examples?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\n\"or in the case of heart failure, predicted BNP level\" -- this doesn't make sense to me -- surely it would be necessary to target an adjusted BNP level?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Also specific details should be reserved until a general explanation of the problem has been made.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n\n* The trade-off parameter \\gamma is a \"fiddle factor\" -- how was this set for the lung image and MNIST examples?[[DAT-NEU,MET-NEU], [EMP-NEU], [QSN], [MIN]] Were these values different?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\n* In typical ICLR style the authors use a deep network to learn the encoder and decoder networks.[[EXP-NEU], [null], [DIS], [GEN]] It would be v interesting (and provide a good baseline) to use a shallow network (i.e. PCA) instead, and elucidate what advantages the deep network brings.[[EXP-NEU], [null], [DIS], [GEN]]\n\n* The example of 4/9 misclassification seems very specific. Does this method also work on say 2s and 3s?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] Why have you not reported results for these kinds of tasks?[[RES-NEG], [SUB-NEG], [QSN], [MIN]]\n\n* Fig 2: better to show each original and reconstructed image close by (e.g. above below or side-by-side).[[RES-NEU], [EMP-NEU], [DIS], [GEN]]\n\nThe reconstructions show poor detail relative to the originals. [[RES-NEG], [EMP-NEG], [CRT], [MIN]] This loss of detail could be a limitation.[[RES-NEG], [EMP-NEG], [CRT], [MAJ]]\n\n* A serious problem with the method is that we are asked to evaluate it in terms of images like Fig 4 or Fig 8.[[TNF-NEG], [EMP-NEG], [CRT], [MIN]] A serious study would involve domain experts and ascertain if Fig 4 conforms with what they are looking for.[[TNF-NEU], [EMP-NEU], [DIS], [MIN]]\n\n* The references section is highly inadequate -- no venues of publication are given.[[BIB-NEG], [SUB-NEG], [CRT], [MIN]] If these are arXiv give the proper ref.[[BIB-NEU], [null], [DIS], [MIN]] Others are published in conferences etc, e.g. Goodfellow et al is in Advances in Neural Information Processing Systems 27, 2014.[[BIB-NEU], [null], [DIS], [MIN]]\n\n* Overall: the paper contains an interesting idea, but given the deficiencies raised above I judge that it falls below the ICLR threshold.[[OAL-NEG], [APR-NEG], [CRT], [MIN]]\n\n* Text:\n\nsec 2 para 4. \"reconstruction loss on the validation set was similar to the reconstruction loss on the validation set.\" ??[[RES-NEU], [EMP-NEU], [QSN], [MIN]]\n\n* p 3 bottom -- give size of dataset\n\n* p 5 AUC curve -> ROC curve\n\n* p 6 Fig 4 use text over each image to better specify the details given in the caption.\n\n\n\n"[[DAT-NEU,DAT-NEU], [SUB-NEU], [DIS], [MIN]]