"In their paper \"CausalGAN: Learning Causal implicit Generative Models with adv. training\" the authors address the following issue: Given a causal structure between \"labels\" of an image (e.g. gender, mustache, smiling, etc.), one tries to learn a causal model between these variables and the image itself from observational data.[[PDI-NEU], [null], [SMY], [GEN]] Here, the image is considered to be an effect of all the labels.[[PDI-NEU], [null], [SMY], [GEN]] Such a causal model allows us to not only sample from conditional observational distributions, but also from intervention distributions.[[PDI-NEU], [null], [SMY], [GEN]] These tasks are clearly different, as nicely shown by the authors' example of \"do(mustache = 1)\" versus \"given mustache = 1\" (a sample from the latter distribution contains only men).[[PDI-POS], [EMP-POS], [APC], [MAJ]] The paper does not aim at learning causal structure from data (as clearly stated by the authors).[[PDI-NEU], [null], [DIS], [GEN]] The example images look convincing to me.[[TNF-POS], [EMP-POS], [APC], [MAJ]]\n\nI like the idea of this paper.[[PDI-POS], [EMP-POS], [APC], [MAJ]] IMO, it is a very nice, clean, and useful approach of combining causality and the expressive power of neural networks.[[MET-POS], [EMP-POS], [APC], [MAJ]] The paper has the potential of conveying the message of causality into the ICLR community and thereby trigger other ideas in that area.[[FWK-POS,OAL-POS], [APR-POS,IMP-POS], [APC], [MAJ]] For me, it is not easy to judge the novelty of the approach, but the authors list related works, none of which seems to solve the same task.[[RWK-POS,MET-POS], [NOV-NEU,EMP-POS], [APC], [MAJ]] The presentation of the paper, however, should be improved significantly before publication.[[OAL-NEU], [PNF-NEU], [SUG], [MIN]] (In fact, because of the presentation of the paper, I was hesitating whether I should suggest acceptance.)[[OAL-NEU], [PNF-NEU], [DIS], [MIN]] Below, I give some examples (and suggest improvements), but there are many others.[[CNT], [null], [SUG], [MIN]] There is a risk that in its current state the paper will not generate much impact, and that would be a pity.[[FWK-NEG], [IMP-NEG], [CRT], [MIN]] I would therefore like to ask the authors to put a lot of effort into improving the presentation of the paper.[[OAL-NEU], [PNF-NEU], [SUG], [MIN]] \n\n\n- I believe that I understand the authors' intention of the caption of Fig. 1, but \"samples outside the dataset\" is a misleading formulation.[[DAT-NEG,TNF-NEG], [EMP-NEG], [CRT], [MIN]] Any reasonable model does more than just reproducing the data points.[[MET-NEG], [CMP-NEG], [CRT], [MIN]] I find the argumentation the authors give in Figure 6 much sharper.[[TNF-POS], [PNF-POS], [APC], [MAJ]] Even better: add the expression \"P(male = 1 | mustache = 1) = 1\".[[TNF-POS], [PNF-POS], [APC], [MAJ]]  Then, the difference is crystal clear.[[TNF-POS], [PNF-POS], [APC], [MAJ]] \n- The difference between Figures 1, 4, and 6 could be clarified. [[TNF-NEU], [EMP-NEU], [SUG], [MIN]]    \n- The list of \"prior work on learning causal graphs\" seems a bit random.[[RWK-NEG], [CMP-NEG], [CRT], [MIN]]  I would add Spirtes et al 2000, Heckermann et al 1999, Peters et al 2016, and Chickering et al 2002.[[RWK-NEU], [null], [SUG], [MIN]] \n- Male -> Bald does not make much sense causally (it should be Gender -> Baldness)... Aha, now I understand: [[CNT], [null], [DIS], [MIN]]The authors seem to switch between \"Gender\" and \"Male\" being random variables.Make this consistent, please. [[CNT], [null], [DIS], [MIN]] \n- There are many typos and comma mistakes.[[OAL-NEG], [CLA-NEG], [CRT], [MIN]]  \n- I would introduce the do-notation much earlier.[[OAL-NEU], [PNF-NEU], [DIS], [MIN]] The paragraph on p. 2 is now written without do-notation (\"intervening Mustache = 1 would not change the distribution\").[[CNT], [PNF-NEG], [CRT], [MIN]]  But this way, the statements are at least very confusing (which one is \"the distribution\"?).[[CNT], [CLA-NEG], [CRT], [MIN]] \n- I would get rid of the concept of CiGM.[[CNT], [null], [DIS], [MIN]]  To me, it seems that this is a causal model with a neural network (NN) modeling the functions that appear in the SCM.[[MET-NEU], [null], [DIS], [MIN]]  This means, it's \"just\" using NNs as a model class.[[MET-NEU], [null], [DIS], [MIN]] Instead, one could just say that one wants to learn a causal model and the proposed procedure is called CausalGAN? (This would also clarify the paper's contribution.)[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n- many realizations = one sample (not samples), I think.[[MET-NEU], [null], [DIS], [MIN]] \n- Fig 1: which model is used to generate the conditional sample? [[TNF-NEU], [EMP-NEU], [QSN], [MIN]] \n- The notation changes between E and N and Z for the noises.[[TNF-NEU], [EMP-NEU], [DIS], [MIN]] I believe that N is supposed to be the noise in the SCM, but then maybe it should not be called E at the beginning.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] \n- I believe Prop 1 (as it is stated) is wrong.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] For a reference, see Peters, Janzing, Scholkopf: Elements of Causal Inference: Foundations and Learning Algorithms (available as pdf), Definition 6.32.[[RWK-NEU], [CMP-NEU], [SUG], [MIN]] One requires the strict positivity of the densities (to properly define conditionals).[[MET-NEU], [null], [DIS], [MIN]] Also, I believe the Z should be a vector, not a set. [[MET-NEG], [EMP-NEG], [SUG,CRT], [MIN]]\n- Below eq. (1), I am not sure what the V in P_V refers to.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- The concept of data probability density function seems weird to me.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] Either it is referring to the fitted model, then it's a bad name, or it's an empirical distribution, then there is no pdf, but a pmf.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- Many subscripts are used without explanation.[[OAL-NEG], [PNF-NEG], [CRT], [MIN]] r -> real? g -> generating? G -> generating? Sometimes, no subscripts are used (e.g., Fig 4 or figures in Sec. 8.13)[[TNF-NEG,OAL-NEG], [PNF-NEG], [CRT], [MIN]]\n- I would get rid of Theorem 1 and explain it in words for the following reasons.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] (1) What is an \"informal\" theorem?[[MET-NEU], [EMP-NEU], [QSN], [MIN]](2) It refers to equations appearing much later.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] (3) It is stated again later as Theorem 2.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] \n- Also: the name P_g does not appear anywhere else in the theorem, I think.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] \n- Furthermore, I would reformulate the theorem.[[MET-NEU], [null], [DIS], [MIN]] The main point is that the intervention distributions are correct (this fact seems to be there, but is \"hidden\" in the CIGN notation in the corollary).[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- Re. the formulation in Thm 2: is it clear that there is a unique global optimum (my intuition would say there could be several), thus: better write \"_a_ global minimum\"?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n- Fig. 3 was not very clear to me.[[TNF-NEG], [EMP-NEG], [CRT], [MIN]] I suggest to put more information into its caption.[[TNF-NEU], [SUB-NEU], [SUG], [MIN]] \n- In particular, why is the dataset not used for the causal controller?[[DAT-NEU], [EMP-NEU], [QSN], [MIN]] I thought, that it should model the joint (empirical) distribution over the labels, and this is part of the dataset.[[DAT-NEU], [EMP-NEU], [DIS], [MIN]] Am I missing sth?[[DAT-NEU], [EMP-NEU], [QSN], [MIN]]\n- IMO, the structure of the paper can be improved.[[OAL-NEG], [PNF-NEG], [CRT], [MIN]] Currently, Section 3 is called \"Background\" which does not say much.[[CNT], [null], [DIS], [MIN]] Section 4 contains CIGMs, Section 5 Causal GANs, 5.1. Causal Controller, 5.2. CausalGAN, 5.2.1. Architecture (which the causal controller is part of) etc.[[MET-NEU], [null], [DIS], [MIN]] An alternative could be: \nSec 1: Introduction \nSec 1.1: Related Work\nSec 2: Causal Models\nSec 2.1: Causal Models using Generative Models (old: CIGM)\nSec 3: Causal GANs\nSec 3.1: Architecture (including controller)\nSec 3.2: loss functions \n...\nSec 4: Empricial Results (old: Sec. 6: Results)\n- \"Causal Graph 1\" is not a proper reference (it's Fig 23 I guess).[[OAL-NEU], [PNF-NEU], [DIS], [MIN]]  Also, it is quite important for the paper, I think it should be in the main part.[[OAL-NEU], [PNF-NEU], [SUG], [MIN]]  \n- There are different references to the \"Appendix\", \"Suppl. Material\", or \"Sec. 8\" -- please be consistent (and try to avoid ambiguity by being more specific -- the appendix contains ~20 pages).[[OAL-NEG], [PNF-NEG], [CRT], [MIN]] Have I missed the reference to the proof of Thm 2?[[MET-NEU], [null], [QSN], [MIN]]\n- 8.1. contains copy-paste from the main text.[[CNT], [null], [DIS], [MIN]]\n- \"proposition from Goodfellow\" -> please be more precise\n- What is Fig 8 used for?[[TNF-NEU], [PNF-NEU], [QSN], [MIN]] Is it not sufficient to have and discuss Fig 23?[[TNF-NEU], [PNF-NEU], [QSN], [MIN]] \n- IMO, Section 5.3. should be rewritten (also, maybe include another reference for BEGAN).[[CNT], [PNF-NEU], [DIS], [MIN]]\n- There is a reference to Lemma 15. However, I have not found that lemma.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- I think it's quite interesting that the framework seems to also allow answering counterfactual questions for realizations that have been sampled from the model, see Fig 16.[[MET-NEU], [EMP-NEU], [DIS], [MIN]] This is the case since for the generated realizations, the noise values are known.[[TNF-NEU], [EMP-NEU], [DIS], [MIN]] The authors may think about including a comment on that issue.[[MET-NEU], [EMP-NEU], [SUG], [MIN]]\n- Since this paper's main proposal is a methodological one, I would make the publication conditional on the fact that code is released. \n\n\n"[[OAL-NEU], [REC-NEU], [FBK], [MAJ]]