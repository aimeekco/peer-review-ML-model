"The paper proposes a method for generating images from attributes.[[PDI-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] The core idea is to learn a shared latent space for images and attributes with variational auto-encoder using paired samples[[PDI-NEU,DAT-NEU,MET-NEU], [IMP-NEU,EMP-NEU], [SMY,DIS], [GEN]], and additionally learn individual inference networks from images or attributes to the latent space using unpaired samples.[[PDI-NEU,DAT-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] During training the auto-encoder is trained on paired data (image, attribute) whereas during testing one uses the unpaired data to generate an image corresponding to an attribute or vice versa.[[PDI-NEU,DAT-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] The authors propose handling missing data using a product of experts where the product is taken over available attributes, and it sharpens the prior distribution.[[PDI-NEU,DAT-NEU], [IMP-NEU], [SMY,DIS], [GEN]] The authors evaluate their method using correctness i.e. if the generated images have the desired attributes, coverage i.e.[[PDI-NEU,DAT-NEU,MET-NEU], [EMP-NEU], [SMY,DIS], [GEN]] if the generated images sample unspecified attributes well, and compositionality i.e. if  images can be generated from unseen attributes.[[RWK-NEU,PDI-NEU,DAT-NEU], [null], [SMY], [GEN]] Although the proposed method performs slightly poor compared to JMVAE in terms of concreteness when all attributes are provided,[[RWK-NEU,MET-NEG,RES-NEG], [CMP-NEG,EMP-NEG], [DFT], [MIN]] it outperforms when some of the attributes are missing (Figure 4a).[[RES-NEG,TNF-NEG], [null], [DFT], [MIN]] It also outperforms existing methods in terms of coverage and compositionality.[[RWK-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]]\n\nMajor comments:\n\nThe paper is well written, and summarizes its contribution succinctly.[[INT-POS], [CLA-POS,SUB-POS], [APC], [MAJ]]\n\nI did not fully understand the 'retrofitting' idea. [[PDI-NEG], [null], [DFT], [MIN]]If I understood correctly, the authors first train \\theta and \\phi and then fix \\theta to train \\phi_x and \\phi_y.[[PDI-NEG,EXP-NEG], [EMP-NEG], [DFT], [MIN]] If that is true, then is \\calL(\\theta, \\phi, \\phi_x, \\phi_y) are right cost function since one does not maximize all three ELBO terms when optimizing \\theta? Please clarify?[[PDI-NEG], [EMP-NEG], [CRT], [MIN]]\n\nMinor comments:\n\n- 'in order of increasing abstraction', does the order of gender-> smiling or not -> hair color matter? Or, is male, *, blackhair a valid option?\n\n- [[RWK-NEG], [null], [QSN], [MIN]]what are the image sizes for the CelebA dataset\n\n- page 5: double the\n\n[[RWK-NEU,DAT-NEG], [null], [QSN], [GEN]]- Which multi-label classifier is used to classify images in attributes?"[[RWK-NEU,MET-NEU], [EMP-NEU], [QSN], [GEN]]
