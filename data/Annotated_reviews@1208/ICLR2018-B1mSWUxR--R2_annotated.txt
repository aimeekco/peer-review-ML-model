"This paper interprets reward augmented maximum likelihood followed by decoding with the most likely output as an approximation to the Bayes decision rule.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]]\n\nI have a few questions on the motivation and the results.[[MET-NEU,RES-NEU], [null], [DIS], [GEN]]\n- In the section \"Open Problems in RAML\", both (i) and (ii) are based on the statement that the globally optimal solution of RAML is the exponential payoff distribution q.[[EXP-NEU,MET-NEU], [null], [DIS], [GEN]] This is not true.[[EXP-NEG], [EMP-NEG], [CRT], [MAJ]] The globally optimal solution is related to both the underlying data distribution P and q, and not the same as q.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MIN]] It is given by q'(y | x, \\tau) = \\sum_{y'} P(y' | x) q(y | y', \\tau).[[MET-NEU], [null], [DIS], [GEN]]\n- Both Theorem 1 and Theorem 2 do not directly justify that RAML has similar reward as the Bayes decision rule,[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] Can anything be said about this?[[MET-NEG], [EMP-NEG], [QSN,CRT], [MIN]] Are the KL divergence small enough to guarantee similar predictive rewards?[[MET-NEG], [EMP-NEG], [QSN], [MIN]]\n- In Theorem 2, when does the exponential tail bound assumption hold?[[MET-NEG], [EMP-NEG], [QSN], [MIN]]\n- In Table 1, the differences between RAML and SQDML do not seem to support the claim that SQDML is better than RAML.[[TNF-NEG,MET-NEG], [PNF-NEG], [CRT], [MIN]] Are the differences actually significant?[[MET-NEU], [IMP-NEU], [QSN], [MIN]] Are the differences between SQDML/RAML and ML significant?[[MET-NEU], [IMP-NEU], [QSN], [MIN]] In addition, how should \\tau be chosen in these experiments?\n"[[EXP-NEU,MET-NEU], [EMP-NEG], [QSN,CRT], [MIN]]