"This paper introduces a machine learning adaptation of the active inference framework proposed by Friston (2010), and applies it to the task of image classification on MNIST through a foveated inspection of images.[[INT-NEU], [null], [SMY], [GEN]] It describes a cognitive architecture for the same, and provide analyses in terms of processing compression and \"confirmation biases\" in the model.[[MET-NEU,ANA-NEU], [null], [SMY], [GEN]]\n\u2013 Active perception, and more specifically recognition through saccades (or viewpoint selection) is an interesting biologically-inspired approach and seems like an intuitive and promising way to improve efficiency. [[MET-POS], [null], [SMY], [GEN]]The problem and its potential applications are well motivated.[[PDI-POS,FWK-POS], [IMP-POS], [APC], [MAJ]]\n\u2013 The perception-driven control formulation is well-detailed and simple to follow.[[MET-NEU], [EMP-POS], [SMY], [GEN]]\n\u2013 The achieved compression rates are significant and impressive, though additional demonstration of performance on more challenging datasets would have been more compelling[[EXP-POS,RES-POS], [EMP-POS], [APC], [MAJ]]\n\nQuestions and comments:\n\u2013 While an 85% compression rate is significant, 88% accuracy on MNIST seems poor.[[RES-NEU], [IMP-NEG], [DFT], [MAJ]] A plot demonstrating the tradeoff of \naccuracy for compression (by varying Href or other parameters) would provide a more complete picture of performance.[[TNF-NEU], [PNF-NEU], [SUG], [MIN]] Knowing baseline performance (without active inference) would help put numbers in perspective by providing a performance bound due to modeling choices.[[RWK-NEU,DAT-NEU,MET-NEU], [SUB-NEU], [SMY], [GEN]]\n\u2013\u00a0What does the distribution of number of saccades required per recognition (for a given threshold) look like over the entire dataset, i.e. how many are dead-easy vs difficult?[[DAT-NEU,EXP-NEU], [null], [QSN], [MIN]]\n\u2013 Steady state assumption: How can this be relaxed to further generalize to non-static scenes?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\u2013 Figure 3 is low resolution and difficult to read.[[TNF-NEG], [PNF-NEG], [DFT], [MIN]]\n\nPost-rebuttal comments:\n\nI have revised my score after considering comments from other reviewers and the revised paper.[[OAL-NEU], [REC-NEU], [DIS,FBK], [GEN]] While the revised version contains more experimental details,[[EXP-POS], [SUB-POS], [SMY], [GEN]] the paper in its present form lacks comparisons to other gaze selection and saliency models which are required to put results in context.[[RWK-NEU,MET-NEU], [CMP-NEG], [DFT], [MIN]] The paper also contains grammatical errors and is somewhat difficult to understand. [[OAL-NEG], [CLA-NEG], [CRT], [MIN]]Finally, while it proposes an interesting formulation of a well-studied problem[[PDI-POS,MET-POS], [EMP-POS], [APC], [MAJ]], more comparisons and analysis are required to validate the approach.[[MET-NEU,ANA-NEU], [CMP-NEU], [DFT], [MIN]]\n"