"This paper investigates the effect of adversarial training.[[MET-NEU], [null], [SMY], [GEN]] Based on experiments using CIFAR10, the authors show that adversarial training is effective in protecting against \"shared\" adversarial perturbation, in particular against universal perturbation.[[DAT-NEU,EXP-NEU], [null], [SMY], [GEN]] In contrast, it is less effective to protect against singular perturbations.[[MET-NEU], [null], [DIS], [GEN]] Then they show that singular perturbation are less robust to image transformation, meaning after image transformation those perturbations are no longer effective.[[MET-NEU,RES-NEU], [null], [SMY], [GEN]] Finally, they show that singular perturbations can be easily detected.[[MET-NEU], [EMP-NEU], [DIS], [GEN]]\n\nI like the message conveyed in this paper.[[OAL-POS], [CNT], [APC], [MAJ]] However, as the statements are mostly backed by experiments, then I think it makes sense to ask how statistically significant the present results are.[[DAT-NEU,EXP-NEU,RES-NEU], [EMP-NEU], [DIS], [MAJ]] Moreover, is CIFAR 10 experiments conclusive enough. "[[DAT-NEU], [EMP-NEU], [QSN], [MIN]]