"This paper presents a novel method for spike based learning that aims at reducing the needed computation during learning and testing when classifying temporal redundant data.[[MET-POS], [NOV-POS], [APC], [MAJ]]  This approach extends the method presented on Arxiv on Sigma delta quantized networks (Peter O\u2019Connor and Max Welling. Sigma delta quantized networks. arXiv preprint arXiv:1611.02024, 2016b.).[[RWK-NEU,MET-NEU], [null], [SMY], [GEN]]  Overall, the paper is interesting and promising;[[OAL-POS], [CNT], [APC], [MAJ]]  only a few works tackle the problem of learning with spikes showing the potential advantages of such form of computing.[[EXP-NEG], [EMP-NEG], [CRT], [MIN]]  The paper, however, is not flawless.[[OAL-NEG], [CLA-NEG,PNF-NEG], [CRT], [MIN]]  The authors demonstrate the method on just two datasets, and effectively they show results of training only for Feed-Forward Neural Nets (the authors claim that \u201cthe entire spiking network end-to-end works\u201d referring to their pre-trained VGG19, but this paper presents only training for the three top layers).[[DAT-NEG,MET-NEG], [SUB-NEG], [DFT], [MAJ]]  Furthermore, even if suitable datasets are not available, the authors could have chosen to train different architectures.[[DAT-NEU,EXP-NEU], [EMP-NEU], [DIS], [MIN]]  The first dataset is the well-known benchmark MNIST also presented in a customized Temporal-MNIST.[[DAT-NEU], [null], [DIS], [GEN]]  Although it is a common base-line, some choices are not clear: why using a FFNN instead that a CNN which performs better on this dataset; how data is presented in terms of temporal series \u2013 this applies to the Temporal MNIST too; why performances for Temporal MNIST \u2013 which should be a more suitable dataset \u2014 are worse than for the standard MNIST; what is the meaning of the right column of Figure 5 since it\u2019s just a linear combination of the GOps results.[[DAT-NEU,EXP-NEU,TNF-NEU], [EMP-NEU], [DIS], [MIN]]  For the second dataset, some points are not clear too: why the labels and the pictures seem not to match (in appendix E); why there are more training iterations with spikes w.r.t. the not-spiking case.[[DAT-NEG,EXP-NEU], [EMP-NEG], [CRT], [MIN]]  Overall, the paper is mathematically sound,[[MET-POS], [EMP-POS], [APC], [MAJ]]  except for the \u201cfuture updates\u201d meaning which probably deserves a clearer explanation.[[MET-NEG], [EMP-NEG], [DIS], [MIN]]  Moreover, I don\u2019t see why the learning rule equations (14-15) are described in the appendix, while they are referred constantly in the main text.[[CNT], [PNF-NEG], [CRT], [MIN]]  The final impression is that the problem of the dynamical range of the hidden layer activations is not fully resolved by the empirical solution described in Appendix D: perhaps this problem affects CCNs more than FFN.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]]  \nFinally, there are some minor issues here and there (the authors show quite some lack of attention for just 7 pages):[[CNT], [CNT], [CRT], [MIN]] \n-\tTwo times \u201cget\u201d in \u201cwe get get a decoding scheme\u201d in the introduction;[[INT-NEU], [null], [DIS], [GEN]] \n-\tTwo times \u201cupdate\u201d in \u201cour true update update as\u201d in Sec. 2.6;[[CNT], [null], [DIS], [GEN]]\n-\tPag3 correct the capital S in 2.3.1\[[CNT], [null], [DIS], [GEN]]n-\tPag4 Figure 1 increase font size (also for Figure2); close bracket after Equation 3; N (number of spikes) is not defined[[MET-NEG,TNF-NEG], [PNF-NEG], [CRT], [MIN]]\n-\tPag5 \u201cone-hot\u201d or \u201conehot\u201d;[[CNT], [null], [DIS], [GEN]] \n-\tin the inline equation the sum goes from n=1 to S, while in eq.(8) it goes from n=1 to N;[[MET-NEG], [PNF-NEG], [CRT], [MIN]]\n-\tEq(10)(11)(12) and some lines have a typo (a \\cdot) just before some of the ws;[[MET-NEG], [CLA-NEG], [CRT], [MIN]]\n-\tPag6 k_{beta} is not defined in the main text;[[MET-NEG], [PNF-NEG], [CRT], [MIN]]\n-\tPag7 there are two \u201cso that\u201d in 3.1; capital letter \u201cIt used 32x10^12..\u201d; beside, here, why do not report the difference in computation w.r.t. not-spiking nets?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n-\tPag7 in 3.2 \u201cdiscussed in 1\u201d is section 1?[[CNT], [EMP-NEU], [QSN], [MIN]]\n-\tPag14 Appendix E, why the labels don\u2019t match the pictures;[[CNT], [EMP-NEU], [QSN], [MIN]]\n-\tPag14 Appendix F, explain better the architecture used for this experiment."[[EXP-POS], [EMP-POS], [APC], [MAJ]]