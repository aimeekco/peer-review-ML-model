"This paper introduces two new loss functions which can be used along with the existing reconstruction and adversarial losses for language style transfer.[[PDI-NEU], [null], [SMY], [GEN]] The first one is a style discrepancy loss to enforce that the discrepancy between the learnt style representation for a source sentence and the target style representation is consistent with a pre-trained discriminator.[[PDI-NEU], [null], [SMY], [GEN]] The second one is a cycle consistency loss to make sure that the the original sentence can be recovered from the content of the transferred sentence and the style of the original sentence.[[PDI-NEU], [null], [SMY], [GEN]] The proposed method does not assume that the source sentences have only one style and allows them to have unknown styles.[[MET-NEU], [null], [SMY], [GEN]]\n\nGenerally speaking, this paper is well written and easy to follow.[[OAL-POS], [CLA-POS], [APC], [MAJ]] The ideas are straightforward and make sense given the current trends in the field.[[PDI-POS], [IMP-POS,EMP-POS], [APC], [MAJ]] This paper does not bring completely new perspectives for the task, but the contribution is valuable to the community.[[OAL-POS], [IMP-POS], [APC], [MAJ]] \n\nThe experimental results show the effectiveness of the approach.[[EXP-POS,MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]] It can be trained with source sentences having various styles and it can produce sentences in a different style without changing the content much.[[EXP-NEU,ANA-NEU], [SUB-NEU,EMP-NEU], [SUG], [MAJ]] These are pros of the approach.[[MET-POS], [EMP-POS], [APC], [MAJ]]\n\nThe cons of the approach may be the fact that it needs a pre-trained classifier for the style discrepancy loss.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] If it can be integrated into the training end-to-end, it might be better.[[EXP-NEU], [null], [SUG], [MIN]]\n\nThe experimental results show the results without the cyclic loss.[[EXP-NEU,RES-NEU], [null], [DIS], [GEN]] The experimental results could also include results without style discrepancy loss.[[EXP-NEU,RES-NEU], [EMP-NEU], [SUG], [MAJ]] \n\nIt looks that this paper denotes the style of the target domain as y^* and assume that it is shared by all samples in X_2.[[MET-NEU], [null], [DIS], [GEN]] However, y^* is also estimated by the encoder as shown in Eq. (2) and it varies depending on the input to the encoder.[[EXP-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]]  It is not very clear to me how y^* is chosen in Section 3.3. Please make that part clear.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] \n\nPlease explain the reason why STB is better than the proposed method with 100k positive samples.[[DAT-NEU,MET-NEU], [EMP-NEU], [DIS], [MIN]] \n\nThe difference between STB and the proposed method is not clear without reading the reference.[[MET-NEG], [CMP-NEG], [CRT], [MIN]]  The algoroithm of STB should be briefly explained in Section 4.2."[[MET-NEU], [PNF-NEU], [SUG], [MIN]] 