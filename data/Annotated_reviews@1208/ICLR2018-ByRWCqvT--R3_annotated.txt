"pros:\nThis is a great paper - I enjoyed reading it.[[OAL-POS], [CLA-POS], [APC], [MAJ]] The authors lay down a general method for addressing various transfer learning problems: transferring across domains and tasks and in a unsupervised fashion.[[MET-POS], [EMP-POS], [APC], [MAJ]] The paper is clearly written and easy to understand[[OAL-POS], [CLA-POS], [APC], [MAJ]]. Even though the method combines the previous general learning frameworks, the proposed algorithm for  LEARNABLE CLUSTERING OBJECTIVE (LCO) is novel, and fits very well in this framework.[[MET-POS], [NOV-POS], [APC], [MAJ]]  Experimental evaluation is performed on several benchmark datasets - the proposed approach outperforms state-of-the-art for specific tasks in most cases.[[DAT-POS,EXP-POS], [CMP-POS,EMP-POS], [APC], [MAJ]] \n\ncons/suggestions: \n- the authors should discuss in more detail the limitations of their approach: it is clear that when there is a high discrepancy between source and target domains, that the similarity prediction network can fail.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] How to deal with these cases, or better, how to detect these before deploying this method?[[MET-NEU], [EMP-NEU], [QSN], [MAJ]\n- the pair-wise similarity prediction network can become very dense: how to deal with extreme cases?"[[MET-NEU], [EMP-NEU], [QSN], [MAJ]