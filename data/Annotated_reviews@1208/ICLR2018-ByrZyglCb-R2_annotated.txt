"This paper discusses universal perturbations - perturbations that can mislead a trained classifier if added to most of input data points.[[INT-NEU], [null], [SMY], [GEN]] The main results are two-fold: if the decision boundary are flat (such as linear classifiers), then the classifiers tend to be vulnerable to universal perturbations when the decision boundaries are correlated.[[MET-NEU,RES-NEU], [null], [SMY], [GEN]] If the decision boundary are curved, then vulnerability to universal perturbations is directly resulted from existence of shared direction along with the decision boundary positively curved.[[MET-NEU,RES-NEU], [null], [SMY], [GEN]] The authors also conducted experiments to show that deep nets produces decision boundary that satisfies the curved model.[[EXP-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nThe main issue I am having is what are the applicable insight from the analysis:[[OAL-NEU], [IMP-NEU], [QSN], [MAJ]]\n\n1. Why is universal perturbation an important topic (as opposed to adversarial perturbation).[[MET-NEU], [CMP-NEU], [QSN], [MIN]]\n2. Does the result implies that we should make the decision boundary more flat, or curved but on different directions? And how to achieve that?[[MET-NEU,RES-NEU], [EMP-NEU], [QSN], [MIN]] It might be my mis-understanding but from my reading a prescriptive procedure for universal perturbation seems not attained from the results presented."[[MET-NEG,RES-NEU], [EMP-NEG], [DFT], [MAJ]]