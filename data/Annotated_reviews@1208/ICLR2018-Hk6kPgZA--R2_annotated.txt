"This paper applies recently developed ideas in the literature of robust optimization, in particular distributionally robust optimization with Wasserstein metric,[[INT-NEU,PDI-NEU], [EMP-NEU], [SMY], [GEN]] and showed that under this framework for smooth loss functions when not too much robustness is requested,[[PDI-NEG], [EMP-NEG], [DFT], [MIN]] then the resulting optimization problem is of the same difficulty level as the original one (where the adversarial attack is not concerned).[[PDI-NEG,EXP-NEG,ANA-NEG], [EMP-NEG], [DFT], [MIN]] I think the idea is intuitive and reasonable, the result is nice.[[PDI-POS,RES-POS], [IMP-POS], [APC], [MAJ]] Although it only holds when light robustness are imposed,[[PDI-NEU], [null], [DIS], [GEN]] but in practice, this seems to be more of the case than say large deviation/adversary exists.[[PDI-NEG,EXP-NEG], [EMP-NEG], [DFT], [MIN]] As adversarial training is an important topic for deep learning, I feel this work may lead to promising principled ways for adversarial training. "[[RWK-POS,MET-POS], [IMP-POS], [APC], [MAJ]]