"This paper introduces a comparison between several approaches for evaluating GANs.[[INT-NEU,RWK-NEU], [EMP-NEU], [SMY], [GEN]] The authors consider the setting of a pre-trained image models as generic representations of generated and real images to be compared.[[RWK-NEU,PDI-NEU], [EMP-NEU], [SMY], [GEN]] They compare the evaluation methods based on five criteria termed disciminability, mode collapsing and mode dropping, sample efficiency,computation efficiency, and robustness to transformation.[[RWK-NEU,PDI-NEU,ANA-NEU], [CMP-NEU], [SMY], [GEN]] This paper has some interesting insights and a few ideas of how to validate an evaluation method.[[PDI-POS,OAL-POS], [SUB-POS], [APC], [MAJ]] The topic is an important one and a very difficult one.[[OAL-NEG], [null], [SUG,FBK], [MAJ]] However, the work has some problems in rigor and justification and the conclusions are overstated in my view.[[OAL-NEG], [CLA-NEG,SUB-NEG], [DFT], [MIN]]\n\nPros\n-Several interesting ideas for evaluating evaluation metrics are proposed[[PDI-POS,EXP-POS,ANA-POS], [IMP-POS], [APC], [MAJ]]\n-The authors tackle a very challenging subject[[OAL-NEG], [SUB-NEG,IMP-NEG], [DFT], [MIN]]\n\nCons\n-It is not clear why GANs are the only generative model considered[[MET-NEG,OAL-NEG], [CLA-NEG], [DFT,CRT], [MIN]]\n-Unprecedented visual quality as compared to other generative models has brought the GAN to prominence and yet this is not really a big factor in this paper.[[RWK-NEU,PDI-NEU], [EMP-NEU], [SMY], [GEN]]\n-The evaluations rely on using a pre-trained imagenet model as a representation.[[RWK-NEU], [EMP-NEU], [SMY], [GEN]] The authors point out that different architectures yield similar results for their analysis, however it is not clear how the biases of the learned representations affect the results.[[RWK-NEU,EXP-NEU,MET-NEU,RES-NEU], [EMP-NEU], [SMY], [GEN]] The use of learned representations needs more rigorous justification[[RWK-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]]\n-The evaluation for discriminative metric, increased score when mix of real and unreal increases, is interesting but it is not convincing as the sole evaluation for \u201cdiscriminativeness\u201d and seems like something that can be gamed.[[RWK-NEU,PDI-NEU], [EMP-NEU], [SMY], [GEN]] \n- The authors implicitly contradict the argument of Theis et al against monolithic evaluation metrics for generative models, but this is not strongly supported.[[RWK-NEU], [EMP-NEU], [SMY], [GEN]]\n\nSeveral references I suggest:\nhttps://arxiv.org/abs/1706.08500 (FID score)\nhttps://arxiv.org/abs/1511.04581 (MMD as evaluation)[[EXT-NEU], [null], [SUG], [GEN]]\n"