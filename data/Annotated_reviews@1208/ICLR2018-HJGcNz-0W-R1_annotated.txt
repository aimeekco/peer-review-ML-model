"The paper is generally clear, and proposes to use a convolutional autoencoder based on 3D meshes.[[PDI-NEU,OAL-POS], [CLA-NEU], [APC], [MAJ]] The novelty here how the problem is formulated.[[PDI-NEU], [NOV-NEU], [DIS], [MAJ]]\n\nPros:\n- Interesting formulation.[[PDI-POS], [EMP-POS], [APC], [MAJ]] I have not seen this particular setup for processing meshes with neural networks in an autoencoder setting.[[PDI-POS], [EMP-POS], [APC], [MAJ]]  \n- This work collected a new dataset for 3D face expression representation, which is great (the state of 3D face databases which are available to researchers is very limited, so this is a step in the right direction).[[DAT-POS,MET-POS], [EMP-POS], [APC], [MAJ]] \n\nCons:\n- The visual depiction of the auto-encoded meshes looks a bit strange.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]]  In particular, they exhibit some high frequency artefacts.[[MET-NEU], [EMP-NEU], [DIS], [MIN]]  These do not appear in the smoother PCA version.[[MET-NEU], [EMP-NEU], [CRT], [MIN]] From a human standpoint, in those cases, the smoother meshes would in fact be preferable.[[MET-NEU], [EMP-NEU], [SUG], [MIN]] I did not see a discussion about this, given that such problems are not captured by the metrics.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- I am a bit confused by the requirement that all meshes need to have the same adjacency matrix.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] Does this mean that you need to convert the raw meshes coming from the 3D camera into a particular topology before you can use this algorithm?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] If yes, this seems like a rather large limitation.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- Regarding the evaluation, you wrote:\"In order to evaluate the interpolation capability of the autoencoder, we split the dataset in training and test samples in the ratio of 1:9.[[MET-NEU], [null], [DIS], [GEN]] The test samples are obtained by picking consecutive frames of\nlength 10 uniformly at random across the sequences. \" - To me this is very unclear.[[EXP-NEG,MET-NEG], [EMP-NEG], [CRT], [MAJ]] You have very few sequeces/subjects.[[CNT], [SUB-NEG], [DFT], [MIN]] Did  you split by *subject*? I think this is CRUCIAL, and a lot of the results hinge on this answer.[[RES-NEU], [EMP-NEU], [QSN], [MAJ]]\n\nGeneral Questions\n\nI am  wondering how come you didn't consider a geometry image representation of the meshes, and went for a slightly more general, and yet very confined alternative (the adjacency requirement, which in some sense is the same type of constraint as geometry images).[[EXP-NEU], [EMP-NEU], [DIS], [MAJ]] On geometry images, in particular it would be possible to apply standard convolutional architectures without any special processing.[[EXP-NEU], [EMP-NEU], [DIS], [MAJ]]\n\nAnother question that I had is why use a L1 loss when in the evaluation you're using L2?[[EXP-NEU,MET-NEU], [EMP-NEU], [QSN], [MIN]] It would make a lot of sense to use the same loss as the evaluation metric (not to mention the properties of PCA)."[[EXP-NEU,MET-NEU], [SUB-NEU], [SUG], [MIN]]