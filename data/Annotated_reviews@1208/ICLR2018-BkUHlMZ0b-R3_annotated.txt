"In this work, the objective is to analyze the robustness of a neural network to any sort of attack.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]]\n\nThis is measured by naturally linking the robustness of the network to the local Lipschitz properties of the network function.[[MET-NEU], [null], [SMY], [GEN]] This approach is quite standard in learning theory, I am not aware of how original this point of view is within the deep learning community.[[MET-NEU], [NOV-NEU], [DIS], [MAJ]]\n\nThis is estimated by obtaining values of the norm of the gradient (also naturally linked to the Lipschitz properties of the function) by backpropagation. This is again a natural idea.[[MET-NEU], [NOV-NEU], [CRT], [MAJ]]"