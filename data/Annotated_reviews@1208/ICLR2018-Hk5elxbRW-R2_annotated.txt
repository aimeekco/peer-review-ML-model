"This paper made some efforts in smoothing the top-k losses proposed in Lapin et al. (2015). [[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]] A family of smooth surrogate loss es was proposed, with the help of which the top-k error may be minimized directly.[[RWK-NEU,EXP-NEU], [EMP-NEU], [SMY], [GEN]] The properties of the smooth surrogate losses were studied and the computational algorithms for SVM with these losses function were also proposed.[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] \n\nPros:\n1, The paper is well presented and is easy to follow.[[OAL-POS], [CLA-POS,PNF-POS], [APC], [MAJ]]\n2, The contribution made in this paper is sound, and the mathematical analysis seems to be correct.[[OAL-POS], [SUB-POS,EMP-POS], [APC], [MAJ]] \n3, The experimental results look convincing.[[RES-POS], [IMP-POS], [APC], [MAJ]] \n\nCons:\nSome statements in this paper are not clear to me.[[RWK-NEG], [CLA-NEG], [DFT,CRT], [MIN]] For example, the authors mentioned sparse or non-sparse loss functions.[[RWK-NEU], [null], [SMY], [GEN]] This statement, in my view, could be misleading without further explanation (the non-sparse loss was mentioned in the abstract).[[ABS-NEU,OAL-NEG], [CLA-NEG,IMP-NEG,EMP-NEG], [DFT,CRT], [MIN]]\n"