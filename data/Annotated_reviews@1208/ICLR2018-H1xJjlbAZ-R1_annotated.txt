"The authors study cases where interpretation of deep learning predictions is extremely fragile.[[PDI-NEU], [null], [SMY], [GEN]]  They systematically characterize the fragility of several widely-used feature-importance interpretation methods.[[MET-NEU], [null], [SMY], [GEN]] In general, questioning the reliability of the visualization techniques is interesting.[[MET-POS], [EMP-POS], [APC], [MAJ]] Regarding the technical details, the reviewer has the following comments: \n\n- What's the limitation of this attack method?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\n- How reliable are the interpretations?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] \n\n- The authors use spearman's rank order correlation and Top-k intersection as metrics for interpretation similarity.[[EXP-NEU,MET-NEU], [null], [SMY], [GEN]] \n\n- Understanding whether influence functions provide meaningful explanations is very important and challenging problem in medical imaging applications.[[EXT-NEU], [null], [DIS], [GEN]] The authors showed that across the test images, they were able to perturb the ordering of the training image influences.[[EXP-NEU,RES-NEU], [null], [SMY], [GEN]] I am wondering how this will be used and evaluated in medical imaging setting. \n"[[EXP-NEU], [EMP-NEU], [QSN], [MIN]]