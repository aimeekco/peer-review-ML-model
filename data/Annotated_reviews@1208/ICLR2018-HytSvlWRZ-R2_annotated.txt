"The authors propose a DNN, called subspace network, for nonlinear multi-task censored regression problem.[[INT-NEU,PDI-NEU], [null], [SMY], [GEN]] The topic is important. Experiments on real data show improvements compared to several traditional approaches.[[RWK-POS,DAT-POS,EXP-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]\n\nMy major concerns are as follows.[[OAL-NEU], [null], [DIS], [MAJ]]\n\n1. The paper is not self-contained.[[OAL-NEG], [CNT], [CRT], [MAJ]] The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1.[[MET-NEU], [null], [DIS], [GEN]] However, for some key steps in the proof, they refer to other references.[[RWK-NEU,MET-NEU], [CMP-NEU], [CRT], [MIN]] If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix.[[MET-NEG], [SUB-NEG,PNF-NEG], [CRT], [MIN]]\n\n2. The experiments are unconvincing.[[EXP-NEG], [EMp-NEG], [CRT], [MAJ]] They compare the proposed SN with other traditional approaches on a very small data  set with 670 samples and 138 features.[[DAT-NEG,MET-NEG], [SUB-NEG,CMP-NEG], [DFT,CRT], [MIN]] A major merit of DNN is that it can automatically extract useful features.[[MET-NEG], [EMP-NEG], [CRT], [MAJ]] However, in this experiment, the features are handcrafted before they are fed into the models.[[EXP-NEG], [EMP-NEG], [CRT], [MIN]] Thus, I would like to see a comparison between SN with vanilla DNN. "[[MET-NEU], [CMP-NEU], [DIS], [MIN]]