"This paper proposes a new reading comprehension model for multi-choice questions and the main motivation is that some options should be eliminated first to infer better passage/question representations.[[INT-NEU,RWK-NEU], [null], [SMY], [GEN]]\n\nIt is a well-written paper,[[OAL-POS], [CLA-POS], [APC], [MAJ]] however, I am not very convinced by its motivation, the proposed model and the experimental results.[[PDI-NEG,EXP-NEG,MET-NEG,RES-NEG], [EMP-NEG], [CRT], [MAJ]] \n\nFirst of all, the improvement is rather limited.[[RES-NEG], [null], [CRT], [MAJ]] It is only 0.4 improvement overall on the RACE dataset;[[DAT-NEG,RES-NEG], [SUB-NEG], [CRT], [MAJ]] although it outperforms GAR on 7 out of 13 categories;[[MET-POS], [EMP-POS], [APC], [MAJ]] but why is it worse on the other 6 categories?[[DAT-NEG,MET-NEG], [EMP-NEG], [QSN,CRT], [MAJ]] I don\u2019t see any convincing explanations here.[[ANA-NEG], [EMP-NEG], [CRT], [MAJ]]\n\nSecondly, in terms of the development of reading comprehension models, I don\u2019t see why we need to care about eliminating the irrelevant options.[[MET-NEG], [EMP-NEG], [CRT], [MIN]] It is hard to generalize to any other RC/QA tasks.[[RWK-NEG], [CMP-NEG], [CRT], [MAJ]] If the point is that the options can add useful information to induce better representations for passage/question, there should be some simple baselines in the middle that this paper should compare to. [[RWK-NEG], [CMP-NEG], [SUG,DFT], [MAJ]]The two baselines SAR and GAR both only induce a representation from paragraph/question, and finally compare to the representation of each option.[[MET-NEG], [SUB-NEG,EMP-NEG], [DFT], [MAJ]] Maybe a simple baseline is to merge the question and all the options and see if a better document representation can be defined.[[EXP-NEU], [CNT], [DIS], [MIN]] \n\nSome visualizations/motivational examples could be also useful to understand how some options are eliminated and how the document representation has been changed based on that.\n"[[ANA-NEG], [SUB-NEU], [SUG], [MIN]]