"This paper considers a new way to incorporate episodic memory with shallow-neural-nets RL using reservoir sampling.[[INT-POS], [null], [SMY], [GEN]] The authors propose a reservoir sampling algorithm for drawing samples from the memory.[[MET-NEU], [null], [SMY], [GEN]] Some theoretical guarantees for the efficiency of reservoir sampling are provided.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] The whole algorithm is tested on a toy problem with 3 repeats.[[EXP-NEU], [null], [SMY], [GEN]] The comparisons between this episodic approach and recurrent neural net with basic GRU memory show the advantage of proposed algorithm.[[MET-NEU], [CMP-POS], [APC], [MAJ]]\n\nThe paper is well written and easy to understand.[[OAL-POS], [CLA-POS], [APC], [MAJ]] Typos didn't influence reading.[[OAL-NEU], [CLA-NEU], [DIS], [MAJ]] It is a novel setup to consider reservoir sampling for episodic memory.[[PDI-POS], [NOV-POS], [APC], [MAJ]] The theory part focuses on effectiveness of drawing samples from the reservoir.[[MET-NEU], [null], [SMY], [GEN]] Physical meanings of Theorem 1 are not well represented.[[MET-NEG], [EMP-NEG], [DFT], [MAJ]] What are the theoretical advantages of using reservoir sampling?[[MET-NEU], [EMP-NEU], [QSN], [MAJ]] \n\nFour simple, shallow neural nets are built as query, write, value, and policy networks.[[MET-NEU], [null], [SMY], [GEN]] The proposed architecture is only compared with a recurrent baseline with 10-unit GRU network.[[RWK-NEU], [SUB-NEU,CMP-NEU], [SMY], [MAJ]] It is not clear the better performance comes from reservoir sampling or other differences.[[MET-NEU], [EMP-NEU], [DFT], [MAJ]] Moreover, the hyperparameters are not optimized on different architectures. It is hard to justify the empirically better performance without hyperparameter tuning.[[MET-NEG], [SUB-NEU,EMP-NEU], [DFT], [MAJ]] The authors mentioned that the experiments are done on a toy problem, only three repeats for each experiment.The technically soundness of this work is weakened by the experiments.[[EXP-NEU], [SUB-NEG,EMP-NEG], [DFT], [MAJ]] \n"