"The paper is interesting,[[OAL-POS], [null], [APC], [MAJ]] but needs more work, and should provide clear and fair comparisons.[[OAL-NEG], [SUB-NEG,CMP-NEG], [CRT], [MIN]] Per se, the model is incrementally new,[[MET-POS], [NOV-POS], [APC], [MAJ]] but it is not clear what the strengths are, and the presentations needs to be done more carefully.[[OAL-NEG], [PNF-NEG], [SUG,CRT], [MAJ]]\n\nIn detail:\n- please fix several typos throughout the manuscript, and have a native speaker (and preferably an ASR expert) proofread the paper[[OAL-NEG], [CLA-NEG], [CRT], [MIN]]\n\nIntroduction\n- please define HMM/GMM model (and other abbreviations that will be introduced later), it cannot be assumed that the reader is familiar with all of them (\"ASG\" is used before it is defined, ...)[[INT-NEG], [PNF-NEG], [CRT], [MAJ]]\n- The standard units that most ASR systems use can be called \"senones\", and they are context dependent sub-phonetic units (see http://ssli.ee.washington.edu/~mhwang/), not phonetic states.[[CNT], [null], [DIS], [MIN]] Also the units that generate the alignment and the units that are trained on an alignment can be different (I can use a system with 10000 states to write alignments for a system with 3000 states) - this needs to be corrected.[[MET-NEG], [EMP-NEG], [CRT], [MIN]]\n- When introducing CNNs, please also cite Waibel and TDNNs - they are *the same* as 1-d CNNs, and predate them.[[MET-NEU], [EMP-NEU], [SUG], [MIN]] They have been extended to 2-d later on (Spatio-temporal TDNNs)[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- The most influential deep learning paper here might be Seide, Li, Yu Interspeech 2011 on CD-DNN-HMMs, rather than overview articles[[EXT-NEU], [null], [DIS], [GEN]]\n- Many papers get rid of the HMM pipeline, I would add https://arxiv.org/abs/1408.2873, which predates Deep Speech[[RWK-NEU], [null], [DIS], [MIN]]\n- What is a \"sequence-level variant of CTC\"?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] CTC is a sequence training criterion[[MET-NEU], [EMP-NEU], [DIS], [MIN]]\n- The reason that Deep Speech 2 is better on noisy test sets is not only the fact they trained on more data, but they also trained on \"noisy\" (matched) data[[EXP-NEU], [EMP-NEU], [QSN], [MIN]]\n- how is this an end-to-end approach if you are using an n-gram language model for decoding?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] \n\nArchitecture\n- MFSC are log Filterbanks ...[[MET-NEU], [null], [DIS], [MIN]]\n- 1D CNNs would be TDNNs[[MET-NEU], [null], [DIS], [MIN]]\n- Figure 2: can you plot the various transition types (normalized, un-normalized, ...) in the plots?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] not sure if it would help, but it might[[MET-NEU], [null], [DIS], [MIN]]\n- Maybe provide a reference for HMM/GMM and EM (forward backward training)[[BIB-NEU], [null], [SUG], [MIN]]\n- MMI was also widely used in HMM/GMM systems, not just NN systems[[MET-NEU], [null], [DIS], [MIN]]\n- the \"blank\" states do *not* model \"garbage\" frames, if one wants to interpret them, they might be said to model \"non-stationary\" frames between CTC \"peaks\", but these are different from silence, garbage, noise, ...[[MET-NEU], [null], [DIS], [MIN]]\n- what is the relationship of the presented ASG criterion to MMI?[[MET-NEU], [EMP-NEU], [QSN], [MIN]] the form of equation (3) looks like an MMI criterion to me?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nExperiments\n- Many of the previous comments still hold, please proofread[[EXP-POS], [EMP-POS], [APC], [MAJ]]\n- you say there is no \"complexity\" incrase when using \"logadd\" - how do you measure this? number of operations? is there an implementation of \"logadd\" that is (absolutely) as fast as \"add\"?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n- There is discussion as to what i-vectors model (speaker or environment information) - I would leave out this discussion entirely here, it is enough to mention that other systems use adaptation, and maybe re-run an unadapted baselien for comparsion[[RWK-NEU], [CMP-NEU], [SUG], [MIN]]\n- There are techniques for incremental adaptation and a constrained MLLR (feature adaptation) approaches that are very eficient, if one wnats to get into this[[MET-NEU], [null], [DIS], [MIN]]\n- it may also be interesting to discuss the role of the language model to see which factors influence system performance[[MET-NEU], [null], [SUG], [MIN]]\n- some of the other papers might use data augmentation, which would increase noise robustness (did not check, but this might explain some of the results in table 4)[[MET-NEU,RES-NEU,TNF-NEU], [EMP-NEU], [DIS], [MIN]]\n- I am confused by the references in the caption of Table 3 - surely the Waibel reference is meant to be for TDNNs (and should appear earlier in the paper), while p-norm came later (Povey used it first for ASR, I think) and is related to Maxout[[MET-NEG,TNF-NEG], [EMP-NEG], [CRT], [MIN]]\n- can you also compare the training times?[[EXP-NEU], [CMP-NEU], [QSN], [MIN]] \n\nConculsion\n- can you show how your approach is not so computationally expensive as RNN based approaches? either in terms of FLOPS or measured times\n"[[MET-NEU], [CMP-NEU], [QSN], [MIN]]