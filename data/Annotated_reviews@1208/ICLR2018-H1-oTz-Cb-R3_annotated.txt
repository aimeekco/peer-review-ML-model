"This paper wants to probe the non-linear invariances learnt by CNNs. This is attempted by selecting a particular layer, and modelling the space of filters that result in activations that are indistinguishable from activations generated by the real filters (using a GAN). [[INT-NEU], [null], [SMY], [GEN]]For a GAN noise vector a plausible filter set is created, and for a data sample a set of plausible activations are computed. [[DAT-NEU,MET-NEU], [SUB-NEU], [SMY], [GEN]]If the noise vector is perturbed and a new plausible filter set is created, the input data can be optimised to find the input that produces the same set of activations.[[MET-NEU], [EMP-NEU], [SMY], [GEN]] The claim is that the found input represents the non-linear transformations that the layer is invariant to[[MET-NEU], [EMP-NEU], [SMY], [GEN]].\n\nThis is a really interesting perspective on probing invariances and should be explored more.[[RES-POS,ANA-POS], [EMP-POS], [SUG], [MIN]] I am not convinced that this particular method is showing much information or highlighting anything particularly interesting, but could be refined in the future to do so.[[MET-NEG], [EMP-NEG], [DFT], [MAJ]]\n\nIt seems that the generated images are not actually plausible images at all and so not many conclusions can be drawn from this method.[[TNF-NEG], [EMP-NEG], [DFT], [MAJ]] Instead of performing the optimisation to find x' have you tried visualising the real data sample that gives the closest activations?[[MET-NEU], [EMP-NEU], [QSN], [MIN]]\n\nI think you may want to consider minimising ||a(x'|z) - a(x|z_k)|| instead to show that moving from x -> x' is the same as is invariant under the transformation z -> z_k  (and thus the corresponding movement in filter space).[[MET-NEU], [EMP-NEU], [SUG], [MIN]] This (the space between x and x') I think is more interpretable as the invariance corresponding to the space between z and z_k. Have you tried that?[[MET-NEU], [EMP-NEU], [DIS,QSN], [MIN]]\n\nThere is no notion of class invariance, so the GAN can find the space of filters that transform layer inputs into other classes, which may not be desirable. Have you tried conditioning the GAN on class?[[MET-NEU], [EMP-NEU], [DIS,QSN], [MIN]]\n\nOverall I think this method is inventive and shows promise for probing invariances.[[MET-POS], [NOV-POS], [APC], [MAJ]] I'm not convinced the current incarnation is showing anything insightful or useful.[[MET-NEG], [EMP-NEG], [DFT], [MAJ]] It also should be shown on more than a single dataset and for a single network, at the moment this is more of a workshop level paper in terms of breadth and depth of results."[[DAT-NEG,EXP-NEU], [SUB-NEG], [SUG], [MIN]]