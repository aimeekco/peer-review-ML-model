"The paper addresses the problem of tensor decomposition which is relevant and interesting.[[PDI-POS], [EMP-POS], [APC], [MAJ]] The paper proposes Tensor Ring (TR) decomposition which improves over and bases on the Tensor Train (TT) decomposition method.[[PDI-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] TT decomposes a tensor in to a sequences of latent tensors where the first and last tensors are a 2D matrices. [[RWK-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nThe proposed TR method generalizes TT in that the first and last tensors are also 3rd-order tensors instead of 2nd-order.[[PDI-NEU], [null], [SMY], [GEN]] I think such generalization is interesting but the innovation seems to be very limited.[[RWK-POS], [NOV-NEG], [DFT,CRT], [GEN]] \n\nThe paper develops three different kinds of solvers for TR decomposition, i.e., SVD, ALS and SGD.[[PDI-NEU,MET-NEU], [EMP-NEU], [SMY], [GEN]] All of these are well known methods.[[MET-POS,OAL-POS], [IMP-POS,EMP-POS], [APC], [MAJ]] \n\nFinally, the paper provides experimental results on synthetic data (3 oscillated functions) and image data (few sampled images). [[PDI-NEU,EXP-NEU,RES-NEU], [EMP-NEU], [SMY], [GEN]]I think the paper could be greatly improved by providing more experiments and ablations to validate the benefits of the proposed methods.[[PDI-NEU,EXP-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nPlease refer to below for more comments and questions.[[EXT-NEU], [null], [DIS], [GEN]]\n\n-- The rating has been updated.[[OAL-POS], [REC-POS], [APC], [MAJ]]\n\nPros:\n1. The topic is interesting.[[OAL-POS], [IMP-POS], [APC], [MAJ]]\n2. The generalization over TT makes sense.[[RWK-NEU], [null], [SMY], [GEN]]\n\nCons:\n1. The writing of the paper could be improved and more clear: the conclusions on inner product and F-norm can be integrated into \"Theorem 5\".[[OAL-NEG], [CLA-NEG], [CRT], [MIN]] And those \"theorems\" in section 4 are just some properties from previous definitions; they are not theorems.[[RWK-NEG], [PNF-NEG,EMP-NEG], [DFT,CRT], [MIN]] \n2. The property of TR decomposition is that the tensors can be shifted (circular invariance).[[RWK-NEU], [null], [SMY], [GEN]] This is an interesting property and it seems to be the major strength of TR over TT. [[OAL-POS], [IMP-POS], [APC], [MAJ]]I think the paper could be significantly improved by providing more applications of this property in both theory and experiments.[[RWK-NEG,EXP-NEG], [IMP-NEG], [DFT], [MIN]]\n3. As the number of latent tensors increase, the ALS method becomes much worse approximation of the original optimization.[[RWK-NEU,MET-NEG], [IMP-NEG], [DFT], [MIN]] Any insights or results on the optimization performance vs. the number of latent tensors?[[RWK-NEU,RES-NEU], [null], [SMY], [GEN]]\n4. Also, the paper mentions Eq. 5 (ALS) is optimized by solving d subproblems alternatively. [[RWK-NEU,BIB-NEU], [null], [SMY], [GEN]]I think this only contains a single round of optimization.[[RWK-NEU], [null], [SMY], [GEN]] Should ALS be applied repeated (each round solves d problems) until convergence?[[RWK-NEU], [EMP-NEU], [SMY], [GEN]]\n5. What is the memory consumption for different solvers?[[RWK-NEU], [null], [SMY,QSN], [GEN]]\n6. SGD also needs to update at least d times for all d latent tensors.[[RWK-NEU,MET-NEG], [EMP-NEG], [DFT], [MIN]] Why is the complexity O(r^3) independent of the parameter d?[[RWK-NEU], [null], [QSN], [GEN]]\n7. The ALS is so slow (if looking at the results in section 5.1), which becomes not practical.[[RWK-NEG,RES-NEG,TNF-NEG], [IMP-NEG,PNF-NEG], [DFT], [MIN]] The experimental part could be improved by providing more results and description about a guidance on how to choose from different solvers.[[RWK-NEG,RES-NEG], [IMP-NEG,EMP-NEG], [DFT], [MIN]]\n8. What does \"iteration\" mean in experimental results such as table 2?[[RWK-NEU,EXP-NEU,RES-NEU,TNF-NEU], [null], [SMY,QSN], [GEN]] Different algorithms have different cost for \"each iteration\" so comparing that seems not fair.[[RWK-NEG,MET-NEG], [CLA-NEG,CMP-NEG], [DFT], [MIN]] The results could make more sense by providing total time consumptions and time cost per iteration.[[RES-NEG,OAL-NEG], [IMP-NEG], [DFT,CRT], [GEN]] also applies to table 4.[[RWK-NEU,TNF-NEU], [PNF-NEU], [SMY], [GEN]]\n9. Why is the \\epsion in table 3 not consistent?[[RWK-NEG,TNF-NEG], [null], [SMY], [GEN]] Why not choose \\epsion = 9e-4 and \\epsilon=2e-15 for tensorization?[[RWK-NEG], [EMP-NEG], [DFT], [MIN]]\n10. Also, table 3 could be greatly improved by providing more ablations such as results for (n=16, d=8), (n=4, d=4), etc.[[RWK-NEU,TNF-NEU,OAL-NEU], [EMP-NEU], [SMY], [GEN]] That could help readers to better understand the effect of TR.[[RWK-NEU], [null], [SUG], [GEN]]\n11. Section 5.3 could be improved by providing a curve (compression vs. error) instead of just providing a table of sampled operating points.[[RWK-NEG,TNF-NEG], [EMP-NEG], [DFT,CRT], [MIN]]\n12. The paper mentions the application of image representation but only experiment on 32x32 images.[[RWK-NEG], [SUB-NEG], [DFT], [MIN]] How does the proposed method handle large images?[[PDI-NEU], [null], [QSN], [GEN]] Otherwise, it does not seem to be a practical application.[[RWK-NEG], [IMP-NEG,EMP-NEG], [DFT], [MIN]]\n13. Figure 5: Are the RSE measures computed over the whole CIFAR-10 dataset or the displayed images?[[DAT-NEU,EXP-NEU,ANA-NEU,TNF-NEU], [EMP-NEU], [SMY,QSN], [GEN]]\n\nMinor:\n- Typo: Page 4 Line 7 \"Note that this algorithm use the similar strategy\": use -> uses"[[RWK-NEU], [null], [SMY], [GEN]]