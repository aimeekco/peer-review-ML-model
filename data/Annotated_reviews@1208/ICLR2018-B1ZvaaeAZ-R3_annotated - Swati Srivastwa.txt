"This paper presents an simple and interesting idea to improve the performance for neural nets.[[PDI-POS], [EMP-NEU], [APC], [MAJ]] The idea is we can reduce the precision for activations and increase the number of filters, and is able to achieve better memory usage (reduced).[[PDI-POS,RES-POS], [EMP-NEU], [APC], [MAJ]] The paper is aiming to solve a practical problem, and has done some solid research work to validate that.[[PDI-POS,ANA-POS], [EMP-NEU], [APC], [MAJ]]  In particular, this paper has also presented a indepth study on AlexNet with very comprehensive results and has validated the usefulness of this approach.[[MET-POS,RES-POS], [CMP-POS,EMP-POS], [APC], [MAJ]]   \n\nIn addition, in their experiments, they have demonstrated pretty solid experimental results, on AlexNet and even deeper nets such as the state of the art Resnet.[[DAT-POS,EXP-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The results are convincing to me.[[RES-POS], [EMP-POS], [APC], [MAJ]] \n\nOn the other side, the idea of this paper does not seem extremely interesting to me, especially many decisions are quite natural to me, and it looks more like a very empirical practical study.[[PDI-NEG], [EMP-NEG], [CRT], [MAJ]] So the novelty is limited.[[PDI-NEG], [NOV-NEG], [CRT], [MAJ]]\n\nSo overall given limited novelty [[PDI-NEG], [NOV-NEG], [CRT], [MAJ]]but the paper presents useful results,[[RES-POS], [EMP-NEU], [APC], [MAJ]] I would recommend borderline leaning towards reject."[[OAL-NEG], [REC-NEG], [FBK], [MAJ]]